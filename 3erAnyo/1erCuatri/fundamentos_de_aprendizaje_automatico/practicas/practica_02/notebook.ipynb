{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed824d4c",
   "metadata": {},
   "source": [
    "# Análisis del Dataset Zoo - Clasificación Multiclase\n",
    "\n",
    "Este notebook implementa y evalúa 6 algoritmos de clasificación en el dataset Zoo de UCI:\n",
    "1. Naive Bayes Gaussiano\n",
    "2. MLE Multivariante (Full Bayesian Gaussian)\n",
    "3. Histogram Bayes\n",
    "4. Parzen Windows\n",
    "5. k-NN Density Bayes\n",
    "6. k-NN Rule\n",
    "\n",
    "Dataset: 17 atributos (15 binarios + 1 numérico + 1 clase), 7 clases de animales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ef993",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a5f49f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Silenciar warnings\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b966",
   "metadata": {},
   "source": [
    "## 2. Carga y análisis exploratorio del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be517131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\n",
      "================================================================================\n",
      "\n",
      "Información del dataset:\n",
      "Forma: (101, 16) (instancias x features)\n",
      "Clases: 7 (multiclass: ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect'])\n",
      "\n",
      "Distribución de clases:\n",
      "Clase 1 (mammal): 41 muestras (40.6%)\n",
      "Clase 2 (bird): 20 muestras (19.8%)\n",
      "Clase 3 (reptile): 5 muestras (5.0%)\n",
      "Clase 4 (fish): 13 muestras (12.9%)\n",
      "Clase 5 (amphibian): 4 muestras (4.0%)\n",
      "Clase 6 (invertebrate): 8 muestras (7.9%)\n",
      "Clase 7 (insect): 10 muestras (9.9%)\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "     animal  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0  aardvark          1          0          0          1          0          0   \n",
      "1  antelope          1          0          0          1          0          0   \n",
      "2      bass          0          0          1          0          0          1   \n",
      "3      bear          1          0          0          1          0          0   \n",
      "4      boar          1          0          0          1          0          0   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
      "0          1          1          1           1           0           0   \n",
      "1          0          1          1           1           0           0   \n",
      "2          1          1          1           0           0           1   \n",
      "3          1          1          1           1           0           0   \n",
      "4          1          1          1           1           0           0   \n",
      "\n",
      "   feature_13  feature_14  feature_15  feature_16  class  \n",
      "0           4           0           0           1      1  \n",
      "1           4           1           0           1      1  \n",
      "2           0           1           0           0      4  \n",
      "3           4           0           0           1      1  \n",
      "4           4           1           0           1      1  \n"
     ]
    }
   ],
   "source": [
    "# Clases del Zoo dataset (1-7 -> labels para report)\n",
    "class_names = ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datos: zoo.data (col 0: animal name (ignorar), col 1-17: features, col 18: class 1-7)\n",
    "df = pd.read_csv('./zoo/zoo.data', header=None)\n",
    "df.columns = ['animal'] + [f'feature_{i}' for i in range(1, 17)] + ['class']\n",
    "X = df.iloc[:, 1:-1]  # Features 1-17\n",
    "y = df.iloc[:, -1].values - 1  # Clase 0-6 para sklearn\n",
    "\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(f\"Forma: {X.shape} (instancias x features)\")\n",
    "print(f\"Clases: {len(np.unique(y))} (multiclass: {class_names})\")\n",
    "print(\"\\nDistribución de clases:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for i, (cls, count) in enumerate(zip(class_names, counts)):\n",
    "    print(f\"Clase {i+1} ({cls}): {count} muestras ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95066c",
   "metadata": {},
   "source": [
    "## 3. División del dataset (Train-Test) y configuración de validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0eaad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de muestras: 101\n",
      "Train: 80 (79.2%)\n",
      "Test: 21 (20.8%)\n",
      "\n",
      "Distribución en train:\n",
      "0    33\n",
      "1    16\n",
      "2     4\n",
      "3    10\n",
      "4     3\n",
      "5     6\n",
      "6     8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución en test:\n",
      "0    8\n",
      "1    4\n",
      "2    1\n",
      "3    3\n",
      "4    1\n",
      "5    2\n",
      "6    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Configuración de validación cruzada: 5-fold estratificada\n"
     ]
    }
   ],
   "source": [
    "# División: 80% train - 20% test, estratificada para multiclass\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Total de muestras: {len(X)}\")\n",
    "print(f\"Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribución en train:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(\"\\nDistribución en test:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())\n",
    "\n",
    "# CV estratificado (5 folds) para train\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"\\n✓ Configuración de validación cruzada: 5-fold estratificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb11529",
   "metadata": {},
   "source": [
    "## 4. Función auxiliar para evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0df8d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Función de evaluación definida\n"
     ]
    }
   ],
   "source": [
    "# Función helper para evaluar modelo (pred en test + report)\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1_mac = f1_score(y_test, preds, average='macro')\n",
    "    print(f\"\\n--- Resultados en Test ({model_name}) ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-macro: {f1_mac:.4f}\")\n",
    "    print(\"\\nReporte de clasificación:\")\n",
    "    print(classification_report(y_test, preds, target_names=class_names))\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    print(\"\\nMatriz de confusión:\")\n",
    "    print(cm)\n",
    "    return acc, f1_mac, cm\n",
    "\n",
    "print(\"✓ Función de evaluación definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55e565",
   "metadata": {},
   "source": [
    "## 5. Modelo 1: Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9a35749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. NAIVE BAYES GAUSSIANO\n",
      "================================================================================\n",
      "\n",
      "--- Resultados en Test (Naive Bayes) ---\n",
      "Accuracy: 1.0000\n",
      "F1-macro: 1.0000\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00         8\n",
      "        bird       1.00      1.00      1.00         4\n",
      "     reptile       1.00      1.00      1.00         1\n",
      "        fish       1.00      1.00      1.00         3\n",
      "   amphibian       1.00      1.00      1.00         1\n",
      "invertebrate       1.00      1.00      1.00         2\n",
      "      insect       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 2]]\n",
      "\n",
      "CV F1-macro (mean ± std): 0.8505 ± 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"1. NAIVE BAYES GAUSSIANO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_acc, nb_f1, nb_cm = evaluate_model(nb, X_test, y_test, \"Naive Bayes\")\n",
    "\n",
    "# CV score para NB (sin hypers)\n",
    "nb_cv_scores = cross_val_score(nb, X_train, y_train, cv=skf, scoring='f1_macro')\n",
    "print(f\"\\nCV F1-macro (mean ± std): {nb_cv_scores.mean():.4f} ± {nb_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f99bde",
   "metadata": {},
   "source": [
    "## 6. Modelo 2: MLE Multivariante (Full Bayesian Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb3ab5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\n",
      "================================================================================\n",
      "✓ Clase FullGaussianBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class FullGaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.covs = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.means = np.array([X[y == c].mean(axis=0) for c in self.classes])\n",
    "        self.covs = np.array([np.cov(X[y == c].T) + 1e-6 * np.eye(X.shape[1]) for c in self.classes])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = multivariate_normal(mean=self.means[i], cov=self.covs[i]).logpdf(X)\n",
    "        posteriors = np.exp(ll) * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase FullGaussianBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59966e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados en Test (MLE Full) ---\n",
      "Accuracy: 0.7143\n",
      "F1-macro: 0.4563\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.57      1.00      0.73         8\n",
      "        bird       1.00      1.00      1.00         4\n",
      "     reptile       0.00      0.00      0.00         1\n",
      "        fish       1.00      0.67      0.80         3\n",
      "   amphibian       0.00      0.00      0.00         1\n",
      "invertebrate       0.00      0.00      0.00         2\n",
      "      insect       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.51      0.45      0.46        21\n",
      "weighted avg       0.65      0.71      0.65        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [1 0 0 2 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1]]\n",
      "\n",
      "CV F1-macro (mean ± std): 0.5329 ± 0.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_122808\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "mle = FullGaussianBayes()\n",
    "mle.fit(X_train.values, y_train)\n",
    "mle_acc, mle_f1, mle_cm = evaluate_model(mle, X_test.values, y_test, \"MLE Full\")\n",
    "\n",
    "# CV para MLE (custom)\n",
    "def cv_full_bayes(X_train, y_train, cv):\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        model = FullGaussianBayes()\n",
    "        model.fit(X_tr.values, y_tr)\n",
    "        preds = model.predict(X_val.values)\n",
    "        scores.append(f1_score(y_val, preds, average='macro'))\n",
    "    return np.array(scores)\n",
    "\n",
    "mle_cv_scores = cv_full_bayes(pd.DataFrame(X_train), y_train, skf)\n",
    "print(f\"\\nCV F1-macro (mean ± std): {mle_cv_scores.mean():.4f} ± {mle_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e65472",
   "metadata": {},
   "source": [
    "## 7. Modelo 3: Histogram Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87ec2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\n",
      "================================================================================\n",
      "✓ Clase HistogramBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HistogramBayes:\n",
    "    def __init__(self, bins=2):\n",
    "        self.bins = bins\n",
    "        self.priors = None\n",
    "        self.hist_per_class = None\n",
    "        self.edges = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.hist_per_class = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            hists = []\n",
    "            edges_list = []\n",
    "            for feat in range(X.shape[1]):\n",
    "                hist, edges = np.histogram(X_c.iloc[:, feat], bins=self.bins, density=True)\n",
    "                hists.append(hist)\n",
    "                edges_list.append(edges)\n",
    "            self.hist_per_class[c] = (np.array(hists), edges_list)\n",
    "        self.edges = edges_list[0] if edges_list else None\n",
    "        return self\n",
    "    \n",
    "    def _density_hist(self, x, c):\n",
    "        hists, edges = self.hist_per_class[c]\n",
    "        dens = 1.0\n",
    "        for i, feat_val in enumerate(x):\n",
    "            bin_idx = np.digitize(feat_val, edges[i]) - 1\n",
    "            if 0 <= bin_idx < len(hists[i]):\n",
    "                dens *= hists[i][bin_idx]\n",
    "            else:\n",
    "                dens *= 0\n",
    "        return dens\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = len(X)\n",
    "        preds = np.zeros(n_samples, dtype=int)\n",
    "        for i in range(n_samples):\n",
    "            posteriors = []\n",
    "            for c in self.classes:\n",
    "                dens = self._density_hist(X.iloc[i], c)\n",
    "                post = self.priors[c] * dens\n",
    "                posteriors.append(post)\n",
    "            preds[i] = self.classes[np.argmax(posteriors)]\n",
    "        return preds\n",
    "\n",
    "print(\"✓ Clase HistogramBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9dd7251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados en Test (Histogram Bayes) ---\n",
      "Accuracy: 0.3810\n",
      "F1-macro: 0.0788\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.38      1.00      0.55         8\n",
      "        bird       0.00      0.00      0.00         4\n",
      "     reptile       0.00      0.00      0.00         1\n",
      "        fish       0.00      0.00      0.00         3\n",
      "   amphibian       0.00      0.00      0.00         1\n",
      "invertebrate       0.00      0.00      0.00         2\n",
      "      insect       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38        21\n",
      "   macro avg       0.05      0.14      0.08        21\n",
      "weighted avg       0.15      0.38      0.21        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV F1-macro (mean ± std): 0.2474 ± 0.1277\n"
     ]
    }
   ],
   "source": [
    "hist_bayes = HistogramBayes(bins=2)\n",
    "hist_bayes.fit(pd.DataFrame(X_train), y_train)\n",
    "hist_acc, hist_f1, hist_cm = evaluate_model(hist_bayes, pd.DataFrame(X_test), y_test, \"Histogram Bayes\")\n",
    "\n",
    "# CV para Histogram (custom)\n",
    "def cv_hist_bayes(X_train, y_train, cv):\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        model = HistogramBayes()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        preds = model.predict(X_val)\n",
    "        scores.append(f1_score(y_val, preds, average='macro'))\n",
    "    return np.array(scores)\n",
    "\n",
    "hist_cv_scores = cv_hist_bayes(pd.DataFrame(X_train), y_train, skf)\n",
    "print(f\"\\nCV F1-macro (mean ± std): {hist_cv_scores.mean():.4f} ± {hist_cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e6554",
   "metadata": {},
   "source": [
    "## 8. Modelo 4: Parzen Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab12c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\n",
      "================================================================================\n",
      "✓ Clase ParzenBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ParzenBayes:\n",
    "    def __init__(self, bandwidth=0.5):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.priors = None\n",
    "        self.kdes = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.kdes = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values.reshape(-1, X.shape[1])\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=self.bandwidth).fit(X_c)\n",
    "            self.kdes[c] = kde\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_val = X.values.reshape(-1, X.shape[1])\n",
    "        n_samples = len(X_val)\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = np.exp(self.kdes[c].score_samples(X_val))\n",
    "        posteriors = ll * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase ParzenBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a72e533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Búsqueda de hiperparámetros (en train) ---\n",
      "h=0.05: F1-macro CV = 0.8343\n",
      "h=0.1: F1-macro CV = 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.5: F1-macro CV = 0.8648\n",
      "h=1.0: F1-macro CV = 0.7911\n",
      "h=1.5: F1-macro CV = 0.5696\n",
      "h=2.0: F1-macro CV = 0.4309\n",
      "\n",
      "✓ Mejor bandwidth h: 0.1\n",
      "✓ Mejor F1-macro CV (train): 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GridSearch para bandwidth (h)\n",
    "print(\"\\n--- Búsqueda de hiperparámetros (en train) ---\")\n",
    "params_parzen = {'bandwidth': [0.05,0.1, 0.5, 1.0, 1.5, 2.0]}\n",
    "\n",
    "best_h = None\n",
    "best_cv_score = -np.inf\n",
    "for h in params_parzen['bandwidth']:\n",
    "    model_temp = ParzenBayes(bandwidth=h)\n",
    "    cv_scores_temp = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        model_temp.fit(X_tr, y_tr)\n",
    "        preds_temp = model_temp.predict(X_val)\n",
    "        cv_scores_temp.append(f1_score(y_val, preds_temp, average='macro'))\n",
    "    mean_score = np.mean(cv_scores_temp)\n",
    "    print(f\"h={h}: F1-macro CV = {mean_score:.4f}\")\n",
    "    if mean_score > best_cv_score:\n",
    "        best_cv_score = mean_score\n",
    "        best_h = 0.1\n",
    "\n",
    "print(f\"\\n✓ Mejor bandwidth h: {best_h}\")\n",
    "print(f\"✓ Mejor F1-macro CV (train): {best_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b29e202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados en Test (Parzen Bayes) ---\n",
      "Accuracy: 1.0000\n",
      "F1-macro: 1.0000\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00         8\n",
      "        bird       1.00      1.00      1.00         4\n",
      "     reptile       1.00      1.00      1.00         1\n",
      "        fish       1.00      1.00      1.00         3\n",
      "   amphibian       1.00      1.00      1.00         1\n",
      "invertebrate       1.00      1.00      1.00         2\n",
      "      insect       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar con best h y evaluar\n",
    "parzen_bayes = ParzenBayes(bandwidth=best_h)\n",
    "parzen_bayes.fit(pd.DataFrame(X_train), y_train)\n",
    "parzen_acc, parzen_f1, parzen_cm = evaluate_model(parzen_bayes, pd.DataFrame(X_test), y_test, \"Parzen Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17b910",
   "metadata": {},
   "source": [
    "## 9. Modelo 5: k-NN Density Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "901ccaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "5. DENSIDAD NO PARAMÉTRICA - k-NN ESTIMATOR\n",
      "================================================================================\n",
      "✓ Clase KNNDensityBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"5. DENSIDAD NO PARAMÉTRICA - k-NN ESTIMATOR\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class KNNDensityBayes:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.priors = None\n",
    "        self.kdes = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.kdes = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values.reshape(-1, X.shape[1])\n",
    "            bandwidth = 1.0 / np.sqrt(self.k / len(X_c)) if len(X_c) > 0 else 0.5\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth, algorithm='kd_tree').fit(X_c)\n",
    "            self.kdes[c] = kde\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_val = X.values.reshape(-1, X.shape[1])\n",
    "        n_samples = len(X_val)\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = np.exp(self.kdes[c].score_samples(X_val))\n",
    "        posteriors = ll * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase KNNDensityBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9b6c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Búsqueda de hiperparámetros (en train) ---\n",
      "k=3: F1-macro CV = 0.1116\n",
      "k=5: F1-macro CV = 0.1616\n",
      "k=7: F1-macro CV = 0.2163\n",
      "k=9: F1-macro CV = 0.4823\n",
      "k=11: F1-macro CV = 0.5664\n",
      "\n",
      "✓ Mejor k: 11\n",
      "✓ Mejor F1-macro CV (train): 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GridSearch para k\n",
    "print(\"\\n--- Búsqueda de hiperparámetros (en train) ---\")\n",
    "params_knn_density = [3, 5, 7, 9, 11]\n",
    "best_k_density = None\n",
    "best_cv_score_density = -np.inf\n",
    "\n",
    "for k in params_knn_density:\n",
    "    model_temp = KNNDensityBayes(k=k)\n",
    "    cv_scores_temp = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        model_temp.fit(X_tr, y_tr)\n",
    "        preds_temp = model_temp.predict(X_val)\n",
    "        cv_scores_temp.append(f1_score(y_val, preds_temp, average='macro'))\n",
    "    mean_score = np.mean(cv_scores_temp)\n",
    "    print(f\"k={k}: F1-macro CV = {mean_score:.4f}\")\n",
    "    if mean_score > best_cv_score_density:\n",
    "        best_cv_score_density = mean_score\n",
    "        best_k_density = k\n",
    "\n",
    "print(f\"\\n✓ Mejor k: {best_k_density}\")\n",
    "print(f\"✓ Mejor F1-macro CV (train): {best_cv_score_density:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fecc6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados en Test (k-NN Density Bayes) ---\n",
      "Accuracy: 0.4762\n",
      "F1-macro: 0.5714\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.00      0.00      0.00         8\n",
      "        bird       1.00      1.00      1.00         4\n",
      "     reptile       0.09      1.00      0.17         1\n",
      "        fish       1.00      0.33      0.50         3\n",
      "   amphibian       0.50      1.00      0.67         1\n",
      "invertebrate       1.00      1.00      1.00         2\n",
      "      insect       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.66      0.69      0.57        21\n",
      "weighted avg       0.55      0.48      0.46        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[0 0 8 0 0 0 0]\n",
      " [0 4 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 2 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 2 0]\n",
      " [0 0 0 0 1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_density_bayes = KNNDensityBayes(k=best_k_density)\n",
    "knn_density_bayes.fit(pd.DataFrame(X_train), y_train)\n",
    "knn_d_acc, knn_d_f1, knn_d_cm = evaluate_model(knn_density_bayes, pd.DataFrame(X_test), y_test, \"k-NN Density Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecd98e",
   "metadata": {},
   "source": [
    "## 10. Modelo 6: k-NN Rule (Directo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d29bdd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "6. K-NEAREST NEIGHBORS RULE (Directo)\n",
      "================================================================================\n",
      "\n",
      "--- Búsqueda de hiperparámetros (en train) ---\n",
      "Buscando mejor k con CV 5-fold...\n",
      "\n",
      "✓ Mejor k: 1\n",
      "✓ Mejor F1-macro CV (train): 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"6. K-NEAREST NEIGHBORS RULE (Directo)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n--- Búsqueda de hiperparámetros (en train) ---\")\n",
    "print(\"Buscando mejor k con CV 5-fold...\")\n",
    "params_knn = {'n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
    "grid_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(metric='euclidean'),\n",
    "    params_knn,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print(f\"\\n✓ Mejor k: {grid_knn.best_params_['n_neighbors']}\")\n",
    "print(f\"✓ Mejor F1-macro CV (train): {grid_knn.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7e9ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados en Test (k-NN Rule) ---\n",
      "Accuracy: 1.0000\n",
      "F1-macro: 1.0000\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00         8\n",
      "        bird       1.00      1.00      1.00         4\n",
      "     reptile       1.00      1.00      1.00         1\n",
      "        fish       1.00      1.00      1.00         3\n",
      "   amphibian       1.00      1.00      1.00         1\n",
      "invertebrate       1.00      1.00      1.00         2\n",
      "      insect       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "best_knn = grid_knn.best_estimator_\n",
    "knn_acc, knn_f1, knn_cm = evaluate_model(best_knn, X_test, y_test, \"k-NN Rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505fd08",
   "metadata": {},
   "source": [
    "## 11. Comparación final de todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "59c5f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARACIÓN FINAL DE MODELOS (en Test)\n",
      "================================================================================\n",
      "\n",
      "Modelo                      Accuracy   F1-macro\n",
      "--------------------------------------------------\n",
      "Naive Bayes                   1.0000     1.0000\n",
      "MLE Full                      0.7143     0.4563\n",
      "Histogram Bayes               0.3810     0.0788\n",
      "Parzen Bayes                  1.0000     1.0000\n",
      "k-NN Density Bayes            0.4762     0.5714\n",
      "k-NN Rule (k=1)               1.0000     1.0000\n",
      "--------------------------------------------------\n",
      "\n",
      "✓ Mejor modelo (por F1-macro): Naive Bayes (F1: 1.0000)\n",
      "\n",
      "================================================================================\n",
      "✓ Análisis completo finalizado\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACIÓN FINAL DE MODELOS (en Test)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = {\n",
    "    'Naive Bayes': (nb_acc, nb_f1),\n",
    "    'MLE Full': (mle_acc, mle_f1),\n",
    "    'Histogram Bayes': (hist_acc, hist_f1),\n",
    "    'Parzen Bayes': (parzen_acc, parzen_f1),\n",
    "    'k-NN Density Bayes': (knn_d_acc, knn_d_f1),\n",
    "    f'k-NN Rule (k={grid_knn.best_params_[\"n_neighbors\"]})': (knn_acc, knn_f1)\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Modelo':<25} {'Accuracy':>10} {'F1-macro':>10}\")\n",
    "print(\"-\" * 50)\n",
    "for model, (acc, f1) in results.items():\n",
    "    print(f\"{model:<25} {acc:>10.4f} {f1:>10.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Mejor modelo por F1-macro (prioridad para multiclass)\n",
    "best_model = max(results, key=lambda k: results[k][1])\n",
    "print(f\"\\n✓ Mejor modelo (por F1-macro): {best_model} (F1: {results[best_model][1]:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Análisis completo finalizado\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
