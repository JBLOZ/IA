{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed824d4c",
   "metadata": {},
   "source": [
    "# Análisis del Dataset Zoo - Clasificación Multiclase\n",
    "\n",
    "Este notebook implementa y evalúa 6 algoritmos de clasificación en el dataset Zoo de UCI:\n",
    "1. Naive Bayes Gaussiano\n",
    "2. MLE Multivariante (Full Bayesian Gaussian)\n",
    "3. Histogram Bayes\n",
    "4. Parzen Windows\n",
    "5. k-NN Density Bayes\n",
    "6. k-NN Rule\n",
    "\n",
    "Dataset: 17 atributos (15 binarios + 1 numérico + 1 clase), 7 clases de animales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ef993",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f49f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Silenciar warnings\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b966",
   "metadata": {},
   "source": [
    "## 2. Carga y análisis exploratorio del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be517131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\n",
      "================================================================================\n",
      "\n",
      "Información del dataset:\n",
      "Forma: (287, 16) (instancias x features)\n",
      "Clases: 7 (multiclass: ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect'])\n",
      "\n",
      "Distribución de clases:\n",
      "Clase 1 (mammal): 41 muestras (14.3%)\n",
      "Clase 2 (bird): 41 muestras (14.3%)\n",
      "Clase 3 (reptile): 41 muestras (14.3%)\n",
      "Clase 4 (fish): 41 muestras (14.3%)\n",
      "Clase 5 (amphibian): 41 muestras (14.3%)\n",
      "Clase 6 (invertebrate): 41 muestras (14.3%)\n",
      "Clase 7 (insect): 41 muestras (14.3%)\n",
      "\n",
      "Primeras 5 filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buffalo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     animal  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  aardvark          1          0          0          1          0          0   \n",
       "1  antelope          1          0          0          1          0          0   \n",
       "2      bear          1          0          0          1          0          0   \n",
       "3      boar          1          0          0          1          0          0   \n",
       "4   buffalo          1          0          0          1          0          0   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
       "0          1          1          1           1           0           0   \n",
       "1          0          1          1           1           0           0   \n",
       "2          1          1          1           1           0           0   \n",
       "3          1          1          1           1           0           0   \n",
       "4          0          1          1           1           0           0   \n",
       "\n",
       "   feature_13  feature_14  feature_15  feature_16  class  \n",
       "0           4           0           0           1      1  \n",
       "1           4           1           0           1      1  \n",
       "2           4           0           0           1      1  \n",
       "3           4           1           0           1      1  \n",
       "4           4           1           0           1      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clases del Zoo dataset (1-7 -> labels para report)\n",
    "class_names = ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datos: zoo.data (col 0: animal name (ignorar), col 1-17: features, col 18: class 1-7)\n",
    "df = pd.read_csv('./data_zoo/zoo_balanced.csv')\n",
    "# df = pd.read_csv('./data_zoo/zoo.csv')\n",
    "df.columns = ['animal'] + [f'feature_{i}' for i in range(1, 17)] + ['class']\n",
    "X = df.iloc[:, 1:-1]  # Features 1-17\n",
    "y = df.iloc[:, -1].values - 1  # Clase 0-6 para sklearn\n",
    "\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(f\"Forma: {X.shape} (instancias x features)\")\n",
    "print(f\"Clases: {len(np.unique(y))} (multiclass: {class_names})\")\n",
    "print(\"\\nDistribución de clases:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for i, (cls, count) in enumerate(zip(class_names, counts)):\n",
    "    print(f\"Clase {i+1} ({cls}): {count} muestras ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95066c",
   "metadata": {},
   "source": [
    "## 3. Configuración de validación cruzada\n",
    "\n",
    "**Estrategia:** Usamos validación cruzada 5-fold estratificada sobre **todo el conjunto de datos**. En cada fold:\n",
    "- Se divide en Train+Val (80%) y Test (20%)\n",
    "- El conjunto Train+Val se subdivide para selección de hiperparámetros (validación interna)\n",
    "- El Test de cada fold se usa para evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0eaad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de muestras: 287\n",
      "Estrategia: Cross-Validation 5-fold sobre todo el conjunto\n",
      "Cada fold: ~230 train+val (~80%), ~57 test (~20%)\n",
      "\n",
      "Distribución de clases en el conjunto completo:\n",
      "0    41\n",
      "1    41\n",
      "2    41\n",
      "3    41\n",
      "4    41\n",
      "5    41\n",
      "6    41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Configuración de validación cruzada: 5-fold estratificada sobre todo el dataset\n"
     ]
    }
   ],
   "source": [
    "# Configuración: CV estratificado 5-fold sobre TODO el dataset\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "\n",
    "print(f\"Total de muestras: {len(X)}\")\n",
    "print(f\"Estrategia: Cross-Validation 5-fold sobre todo el conjunto\")\n",
    "print(f\"Cada fold: ~{len(X)*0.8:.0f} train+val (~80%), ~{len(X)*0.2:.0f} test (~20%)\")\n",
    "print(\"\\nDistribución de clases en el conjunto completo:\")\n",
    "print(pd.Series(y).value_counts().sort_index())\n",
    "\n",
    "print(\"\\n✓ Configuración de validación cruzada: 5-fold estratificada sobre todo el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb11529",
   "metadata": {},
   "source": [
    "## 4. Funciones auxiliares para evaluación con CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df8d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de evaluación definidas\n"
     ]
    }
   ],
   "source": [
    "# Función para evaluar modelo en un fold específico\n",
    "def evaluate_fold(model, X_test, y_test, fold_num):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de test del fold\"\"\"\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1_mac = f1_score(y_test, preds, average='macro')\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    return acc, f1_mac, cm, preds\n",
    "\n",
    "# Función para imprimir resultados agregados de CV\n",
    "def print_cv_results(model_name, accuracies, f1_scores, all_preds, all_true):\n",
    "    \"\"\"Imprime resultados agregados de cross-validation\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTADOS CV: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAccuracy por fold: {[f'{acc:.4f}' for acc in accuracies]}\")\n",
    "    print(f\"Accuracy promedio: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "    print(f\"\\nF1-macro por fold: {[f'{f1:.4f}' for f1 in f1_scores]}\")\n",
    "    print(f\"F1-macro promedio: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "    \n",
    "    # Reporte global (concatenando todas las predicciones)\n",
    "    print(f\"\\n--- Reporte de clasificación global (todos los folds) ---\")\n",
    "    print(classification_report(all_true, all_preds, target_names=class_names))\n",
    "    \n",
    "    # Matriz de confusión global\n",
    "    cm_global = confusion_matrix(all_true, all_preds)\n",
    "    print(f\"\\nMatriz de confusión global:\")\n",
    "    print(cm_global)\n",
    "    \n",
    "    return np.mean(accuracies), np.mean(f1_scores)\n",
    "\n",
    "print(\"✓ Funciones de evaluación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55e565",
   "metadata": {},
   "source": [
    "## 5. Modelo 1: Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9a35749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. NAIVE BAYES GAUSSIANO\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Accuracy: 0.8793, F1-macro: 0.8741\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 0.9483, F1-macro: 0.9462\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.9649, F1-macro: 0.9653\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.7895, F1-macro: 0.7688\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.8246, F1-macro: 0.7892\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Naive Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.8793', '0.9483', '0.9649', '0.7895', '0.8246']\n",
      "Accuracy promedio: 0.8813 ± 0.0680\n",
      "\n",
      "F1-macro por fold: ['0.8741', '0.9462', '0.9653', '0.7688', '0.7892']\n",
      "F1-macro promedio: 0.8687 ± 0.0796\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      0.98      0.99        41\n",
      "        bird       1.00      1.00      1.00        41\n",
      "     reptile       0.69      0.66      0.68        41\n",
      "        fish       0.97      0.95      0.96        41\n",
      "   amphibian       0.69      0.71      0.70        41\n",
      "invertebrate       0.93      1.00      0.96        41\n",
      "      insect       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.88       287\n",
      "   macro avg       0.88      0.88      0.88       287\n",
      "weighted avg       0.88      0.88      0.88       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[40  0  0  0  0  0  1]\n",
      " [ 0 41  0  0  0  0  0]\n",
      " [ 0  0 27  0 13  0  1]\n",
      " [ 0  0  0 39  0  0  2]\n",
      " [ 0  0 11  0 29  0  1]\n",
      " [ 0  0  0  0  0 41  0]\n",
      " [ 0  0  1  1  0  3 36]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"1. NAIVE BAYES GAUSSIANO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "nb_accuracies = []\n",
    "nb_f1_scores = []\n",
    "nb_all_preds = []\n",
    "nb_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar Naive Bayes (sin hiperparámetros)\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(nb, X_test_fold, y_test_fold, fold)\n",
    "    nb_accuracies.append(acc)\n",
    "    nb_f1_scores.append(f1)\n",
    "    nb_all_preds.extend(preds)\n",
    "    nb_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "nb_mean_acc, nb_mean_f1 = print_cv_results(\"Naive Bayes\", nb_accuracies, nb_f1_scores, \n",
    "                                            nb_all_preds, nb_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f99bde",
   "metadata": {},
   "source": [
    "## 6. Modelo 2: MLE Multivariante (Full Bayesian Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb3ab5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\n",
      "================================================================================\n",
      "✓ Clase FullGaussianBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class FullGaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.covs = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.means = np.array([X[y == c].mean(axis=0) for c in self.classes])\n",
    "        self.covs = np.array([np.cov(X[y == c].T) + 1e-6 * np.eye(X.shape[1]) for c in self.classes])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = multivariate_normal(mean=self.means[i], cov=self.covs[i]).logpdf(X)\n",
    "        posteriors = np.exp(ll) * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase FullGaussianBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59966e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Accuracy: 0.8793, F1-macro: 0.8741\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 0.9310, F1-macro: 0.9306\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.9474, F1-macro: 0.9474\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.8070, F1-macro: 0.8053\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.8947, F1-macro: 0.8953\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: MLE Full Gaussian\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.8793', '0.9310', '0.9474', '0.8070', '0.8947']\n",
      "Accuracy promedio: 0.8919 ± 0.0489\n",
      "\n",
      "F1-macro por fold: ['0.8741', '0.9306', '0.9474', '0.8053', '0.8953']\n",
      "F1-macro promedio: 0.8905 ± 0.0498\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.82      1.00      0.90        41\n",
      "        bird       1.00      1.00      1.00        41\n",
      "     reptile       0.84      0.76      0.79        41\n",
      "        fish       0.97      0.95      0.96        41\n",
      "   amphibian       0.78      0.78      0.78        41\n",
      "invertebrate       0.93      1.00      0.96        41\n",
      "      insect       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.89       287\n",
      "   macro avg       0.89      0.89      0.89       287\n",
      "weighted avg       0.89      0.89      0.89       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0]\n",
      " [ 0  0 31  0  9  0  1]\n",
      " [ 0  0  0 39  0  0  2]\n",
      " [ 3  0  6  0 32  0  0]\n",
      " [ 0  0  0  0  0 41  0]\n",
      " [ 6  0  0  1  0  3 31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_130428\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_130428\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_130428\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_130428\\2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "mle_accuracies = []\n",
    "mle_f1_scores = []\n",
    "mle_all_preds = []\n",
    "mle_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar MLE Full\n",
    "    mle = FullGaussianBayes()\n",
    "    mle.fit(X_train_val.values, y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(mle, X_test_fold.values, y_test_fold, fold)\n",
    "    mle_accuracies.append(acc)\n",
    "    mle_f1_scores.append(f1)\n",
    "    mle_all_preds.extend(preds)\n",
    "    mle_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "mle_mean_acc, mle_mean_f1 = print_cv_results(\"MLE Full Gaussian\", mle_accuracies, mle_f1_scores,\n",
    "                                              mle_all_preds, mle_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e65472",
   "metadata": {},
   "source": [
    "## 7. Modelo 3: Histogram Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87ec2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\n",
      "================================================================================\n",
      "✓ Clase HistogramBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HistogramBayes:\n",
    "    def __init__(self, bins=2):\n",
    "        self.bins = bins\n",
    "        self.priors = None\n",
    "        self.hist_per_class = None\n",
    "        self.edges = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.hist_per_class = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            hists = []\n",
    "            edges_list = []\n",
    "            for feat in range(X.shape[1]):\n",
    "                hist, edges = np.histogram(X_c.iloc[:, feat], bins=self.bins, density=True)\n",
    "                hists.append(hist)\n",
    "                edges_list.append(edges)\n",
    "            self.hist_per_class[c] = (np.array(hists), edges_list)\n",
    "        self.edges = edges_list[0] if edges_list else None\n",
    "        return self\n",
    "    \n",
    "    def _density_hist(self, x, c):\n",
    "        hists, edges = self.hist_per_class[c]\n",
    "        dens = 1.0\n",
    "        for i, feat_val in enumerate(x):\n",
    "            bin_idx = np.digitize(feat_val, edges[i]) - 1\n",
    "            if 0 <= bin_idx < len(hists[i]):\n",
    "                dens *= hists[i][bin_idx]\n",
    "            else:\n",
    "                dens *= 0\n",
    "        return dens\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = len(X)\n",
    "        preds = np.zeros(n_samples, dtype=int)\n",
    "        for i in range(n_samples):\n",
    "            posteriors = []\n",
    "            for c in self.classes:\n",
    "                dens = self._density_hist(X.iloc[i], c)\n",
    "                post = self.priors[c] * dens\n",
    "                posteriors.append(post)\n",
    "            preds[i] = self.classes[np.argmax(posteriors)]\n",
    "        return preds\n",
    "\n",
    "print(\"✓ Clase HistogramBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dd7251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Accuracy: 0.1724, F1-macro: 0.0707\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 0.1379, F1-macro: 0.0346\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.1579, F1-macro: 0.0680\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.1404, F1-macro: 0.0352\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.1579, F1-macro: 0.0675\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Histogram Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.1724', '0.1379', '0.1579', '0.1404', '0.1579']\n",
      "Accuracy promedio: 0.1533 ± 0.0127\n",
      "\n",
      "F1-macro por fold: ['0.0707', '0.0346', '0.0680', '0.0352', '0.0675']\n",
      "F1-macro promedio: 0.0552 ± 0.0166\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.14      1.00      0.25        41\n",
      "        bird       1.00      0.02      0.05        41\n",
      "     reptile       0.00      0.00      0.00        41\n",
      "        fish       0.00      0.00      0.00        41\n",
      "   amphibian       0.00      0.00      0.00        41\n",
      "invertebrate       1.00      0.05      0.09        41\n",
      "      insect       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.15       287\n",
      "   macro avg       0.31      0.15      0.06       287\n",
      "weighted avg       0.31      0.15      0.06       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [40  1  0  0  0  0  0]\n",
      " [41  0  0  0  0  0  0]\n",
      " [41  0  0  0  0  0  0]\n",
      " [41  0  0  0  0  0  0]\n",
      " [39  0  0  0  0  2  0]\n",
      " [40  0  0  1  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "hist_accuracies = []\n",
    "hist_f1_scores = []\n",
    "hist_all_preds = []\n",
    "hist_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar Histogram Bayes (bins=2 fijo para datos binarios)\n",
    "    hist_bayes = HistogramBayes(bins=2)\n",
    "    hist_bayes.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(hist_bayes, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "    hist_accuracies.append(acc)\n",
    "    hist_f1_scores.append(f1)\n",
    "    hist_all_preds.extend(preds)\n",
    "    hist_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "hist_mean_acc, hist_mean_f1 = print_cv_results(\"Histogram Bayes\", hist_accuracies, hist_f1_scores,\n",
    "                                                hist_all_preds, hist_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e6554",
   "metadata": {},
   "source": [
    "## 8. Modelo 4: Parzen Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fe81d",
   "metadata": {},
   "source": [
    "**Nota sobre selección de hiperparámetros:** \n",
    "- Se evalúan todos los hiperparámetros en cada uno de los 5 folds\n",
    "- Se obtiene una matriz de resultados (hiperparámetros × folds)\n",
    "- Se selecciona el hiperparámetro con mejor promedio de F1-macro\n",
    "- Se reportan los resultados del mejor hiperparámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab12c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\n",
      "================================================================================\n",
      "✓ Clase ParzenBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ParzenBayes:\n",
    "    def __init__(self, bandwidth=0.5):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.priors = None\n",
    "        self.kdes = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.kdes = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values.reshape(-1, X.shape[1])\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=self.bandwidth).fit(X_c)\n",
    "            self.kdes[c] = kde\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_val = X.values.reshape(-1, X.shape[1])\n",
    "        n_samples = len(X_val)\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = np.exp(self.kdes[c].score_samples(X_val))\n",
    "        posteriors = ll * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase ParzenBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72e533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  h=0.05: Accuracy=0.9138, F1-macro=0.9056\n",
      "  h=0.1: Accuracy=0.9138, F1-macro=0.9056\n",
      "  h=0.5: Accuracy=0.9138, F1-macro=0.9056\n",
      "  h=1.0: Accuracy=0.8621, F1-macro=0.8474\n",
      "  h=1.5: Accuracy=0.7931, F1-macro=0.7265\n",
      "  h=2.0: Accuracy=0.7069, F1-macro=0.5971\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  h=0.05: Accuracy=0.9655, F1-macro=0.9643\n",
      "  h=0.1: Accuracy=0.9655, F1-macro=0.9643\n",
      "  h=0.5: Accuracy=0.9655, F1-macro=0.9643\n",
      "  h=1.0: Accuracy=0.8621, F1-macro=0.8593\n",
      "  h=1.5: Accuracy=0.7931, F1-macro=0.7802\n",
      "  h=2.0: Accuracy=0.6724, F1-macro=0.5903\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  h=0.05: Accuracy=0.8947, F1-macro=0.8934\n",
      "  h=0.1: Accuracy=0.8947, F1-macro=0.8934\n",
      "  h=0.5: Accuracy=0.8947, F1-macro=0.8964\n",
      "  h=1.0: Accuracy=0.7368, F1-macro=0.7069\n",
      "  h=1.5: Accuracy=0.7193, F1-macro=0.6749\n",
      "  h=2.0: Accuracy=0.6842, F1-macro=0.6031\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  h=0.05: Accuracy=0.9298, F1-macro=0.9291\n",
      "  h=0.1: Accuracy=0.9474, F1-macro=0.9469\n",
      "  h=0.5: Accuracy=0.9649, F1-macro=0.9637\n",
      "  h=1.0: Accuracy=0.8772, F1-macro=0.8695\n",
      "  h=1.5: Accuracy=0.8421, F1-macro=0.8302\n",
      "  h=2.0: Accuracy=0.7018, F1-macro=0.6023\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  h=0.05: Accuracy=0.9474, F1-macro=0.9489\n",
      "  h=0.1: Accuracy=0.9474, F1-macro=0.9489\n",
      "  h=0.5: Accuracy=0.9298, F1-macro=0.9313\n",
      "  h=1.0: Accuracy=0.9298, F1-macro=0.9296\n",
      "  h=1.5: Accuracy=0.8070, F1-macro=0.7802\n",
      "  h=2.0: Accuracy=0.6842, F1-macro=0.5844\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "h=0.05:\n",
      "  Accuracy por fold: ['0.9138', '0.9655', '0.8947', '0.9298', '0.9474']\n",
      "  Accuracy: 0.9302 ± 0.0248\n",
      "  F1-macro por fold: ['0.9056', '0.9643', '0.8934', '0.9291', '0.9489']\n",
      "  F1-macro: 0.9282 ± 0.0263\n",
      "\n",
      "h=0.1:\n",
      "  Accuracy por fold: ['0.9138', '0.9655', '0.8947', '0.9474', '0.9474']\n",
      "  Accuracy: 0.9338 ± 0.0257\n",
      "  F1-macro por fold: ['0.9056', '0.9643', '0.8934', '0.9469', '0.9489']\n",
      "  F1-macro: 0.9318 ± 0.0273\n",
      "\n",
      "h=0.5:\n",
      "  Accuracy por fold: ['0.9138', '0.9655', '0.8947', '0.9649', '0.9298']\n",
      "  Accuracy: 0.9338 ± 0.0280\n",
      "  F1-macro por fold: ['0.9056', '0.9643', '0.8964', '0.9637', '0.9313']\n",
      "  F1-macro: 0.9323 ± 0.0283\n",
      "\n",
      "h=1.0:\n",
      "  Accuracy por fold: ['0.8621', '0.8621', '0.7368', '0.8772', '0.9298']\n",
      "  Accuracy: 0.8536 ± 0.0635\n",
      "  F1-macro por fold: ['0.8474', '0.8593', '0.7069', '0.8695', '0.9296']\n",
      "  F1-macro: 0.8425 ± 0.0735\n",
      "\n",
      "h=1.5:\n",
      "  Accuracy por fold: ['0.7931', '0.7931', '0.7193', '0.8421', '0.8070']\n",
      "  Accuracy: 0.7909 ± 0.0400\n",
      "  F1-macro por fold: ['0.7265', '0.7802', '0.6749', '0.8302', '0.7802']\n",
      "  F1-macro: 0.7584 ± 0.0531\n",
      "\n",
      "h=2.0:\n",
      "  Accuracy por fold: ['0.7069', '0.6724', '0.6842', '0.7018', '0.6842']\n",
      "  Accuracy: 0.6899 ± 0.0126\n",
      "  F1-macro por fold: ['0.5971', '0.5903', '0.6031', '0.6023', '0.5844']\n",
      "  F1-macro: 0.5954 ± 0.0072\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: h=0.5\n",
      "  F1-macro: 0.9323 ± 0.0283\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Parzen Windows (h=0.5)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.9138', '0.9655', '0.8947', '0.9649', '0.9298']\n",
      "Accuracy promedio: 0.9338 ± 0.0280\n",
      "\n",
      "F1-macro por fold: ['0.9056', '0.9643', '0.8964', '0.9637', '0.9313']\n",
      "F1-macro promedio: 0.9323 ± 0.0283\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        41\n",
      "     reptile       0.89      0.83      0.86        41\n",
      "        fish       0.91      1.00      0.95        41\n",
      "   amphibian       0.84      0.88      0.86        41\n",
      "invertebrate       0.93      0.98      0.95        41\n",
      "      insect       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.93       287\n",
      "   macro avg       0.94      0.93      0.93       287\n",
      "weighted avg       0.94      0.93      0.93       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0]\n",
      " [ 0  0 34  1  6  0  0]\n",
      " [ 0  0  0 41  0  0  0]\n",
      " [ 0  0  4  1 36  0  0]\n",
      " [ 0  0  0  0  0 40  1]\n",
      " [ 0  0  0  2  1  3 35]]\n"
     ]
    }
   ],
   "source": [
    "params_parzen = [0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "parzen_results = {h: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "                  for h in params_parzen}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for h in params_parzen:\n",
    "        # Entrenar con este h\n",
    "        parzen = ParzenBayes(bandwidth=h)\n",
    "        parzen.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(parzen, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        parzen_results[h]['accuracies'].append(acc)\n",
    "        parzen_results[h]['f1_scores'].append(f1)\n",
    "        parzen_results[h]['all_preds'].extend(preds)\n",
    "        parzen_results[h]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  h={h}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_h = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for h in params_parzen:\n",
    "    acc_mean = np.mean(parzen_results[h]['accuracies'])\n",
    "    acc_std = np.std(parzen_results[h]['accuracies'])\n",
    "    f1_mean = np.mean(parzen_results[h]['f1_scores'])\n",
    "    f1_std = np.std(parzen_results[h]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nh={h}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in parzen_results[h]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in parzen_results[h]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_h = h\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: h={best_h}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(parzen_results[best_h]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "parzen_accuracies = parzen_results[best_h]['accuracies']\n",
    "parzen_f1_scores = parzen_results[best_h]['f1_scores']\n",
    "parzen_all_preds = parzen_results[best_h]['all_preds']\n",
    "parzen_all_true = parzen_results[best_h]['all_true']\n",
    "\n",
    "parzen_mean_acc, parzen_mean_f1 = print_cv_results(f\"Parzen Windows (h={best_h})\", \n",
    "                                                    parzen_accuracies, parzen_f1_scores,\n",
    "                                                    parzen_all_preds, parzen_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17b910",
   "metadata": {},
   "source": [
    "## 9. Modelo 5: k-NN Density Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "901ccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "class KNNDensityBayes:\n",
    "    \"\"\"\n",
    "    Clasificador Bayesiano usando estimación de densidad k-NN.\n",
    "    \n",
    "    La densidad se estima como:\n",
    "        p(x|ω) = k / (|D_ω| * V_k(x))\n",
    "    \n",
    "    donde V_k(x) es el volumen de la hiper-esfera que contiene\n",
    "    los k vecinos más cercanos de x en la clase ω.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.priors = None\n",
    "        self.nn_models = {}  # Un modelo de vecinos por clase\n",
    "        self.classes = None\n",
    "        self.class_data = {}  # Datos de entrenamiento por clase\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el modelo guardando los datos de cada clase.\"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        \n",
    "        # Para cada clase, guardamos sus datos y entrenamos un NearestNeighbors\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values if hasattr(X, 'values') else X[y == c]\n",
    "            self.class_data[c] = X_c\n",
    "            \n",
    "            # Crear modelo de vecinos más cercanos para esta clase\n",
    "            nn_model = NearestNeighbors(n_neighbors=min(self.k, len(X_c)), \n",
    "                                        algorithm='auto', \n",
    "                                        metric='euclidean')\n",
    "            nn_model.fit(X_c)\n",
    "            self.nn_models[c] = nn_model\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _estimate_density(self, X_val, class_idx):\n",
    "        \"\"\"\n",
    "        Estima p(x|ω) para cada muestra en X_val usando k-NN density.\n",
    "        \n",
    "        p(x|ω) = k / (N_ω * V_k(x))\n",
    "        donde V_k(x) es el volumen de la hiper-esfera de radio r_k(x)\n",
    "        (distancia al k-ésimo vecino más cercano).\n",
    "        \"\"\"\n",
    "        nn_model = self.nn_models[class_idx]\n",
    "        N_class = len(self.class_data[class_idx])\n",
    "        d = X_val.shape[1]  # dimensionalidad\n",
    "        \n",
    "        # Obtener distancias a los k vecinos más cercanos\n",
    "        distances, _ = nn_model.kneighbors(X_val)\n",
    "        \n",
    "        # La distancia al k-ésimo vecino más cercano define el radio\n",
    "        r_k = distances[:, -1]  # última columna = k-ésimo vecino\n",
    "        \n",
    "        # Volumen de hiper-esfera en d dimensiones: V_d(r) = π^(d/2) / Γ(d/2 + 1) * r^d\n",
    "        # Para simplificar usamos solo r^d (la constante π^(d/2)/Γ(d/2+1) se cancela en el ratio)\n",
    "        V_k = r_k ** d\n",
    "        \n",
    "        # Evitar divisiones por cero\n",
    "        V_k = np.maximum(V_k, 1e-10)\n",
    "        \n",
    "        # Densidad: k / (N_class * V_k)\n",
    "        density = self.k / (N_class * V_k)\n",
    "        \n",
    "        return density\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predice las clases usando la regla de Bayes.\"\"\"\n",
    "        X_val = X.values if hasattr(X, 'values') else X\n",
    "        n_samples = len(X_val)\n",
    "        \n",
    "        # Calcular p(x|ω) * P(ω) para cada clase\n",
    "        posteriors = np.zeros((n_samples, len(self.classes)))\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            likelihood = self._estimate_density(X_val, c)\n",
    "            posteriors[:, i] = likelihood * self.priors[c]\n",
    "        \n",
    "        # Normalizar (aunque no es necesario para argmax)\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        \n",
    "        return np.argmax(posteriors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9b6c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  k=1: Accuracy=0.8966, F1-macro=0.8873\n",
      "  k=3: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=5: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=7: Accuracy=0.8966, F1-macro=0.8888\n",
      "  k=9: Accuracy=0.8966, F1-macro=0.8888\n",
      "  k=11: Accuracy=0.8793, F1-macro=0.8705\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  k=1: Accuracy=0.9828, F1-macro=0.9821\n",
      "  k=3: Accuracy=0.9483, F1-macro=0.9458\n",
      "  k=5: Accuracy=0.9310, F1-macro=0.9283\n",
      "  k=7: Accuracy=0.9310, F1-macro=0.9290\n",
      "  k=9: Accuracy=0.9138, F1-macro=0.9130\n",
      "  k=11: Accuracy=0.9138, F1-macro=0.9130\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  k=1: Accuracy=0.8947, F1-macro=0.8946\n",
      "  k=3: Accuracy=0.8772, F1-macro=0.8748\n",
      "  k=5: Accuracy=0.7719, F1-macro=0.7536\n",
      "  k=7: Accuracy=0.7895, F1-macro=0.7752\n",
      "  k=9: Accuracy=0.8070, F1-macro=0.7933\n",
      "  k=11: Accuracy=0.7368, F1-macro=0.7072\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  k=1: Accuracy=0.9474, F1-macro=0.9475\n",
      "  k=3: Accuracy=0.9298, F1-macro=0.9296\n",
      "  k=5: Accuracy=0.9298, F1-macro=0.9287\n",
      "  k=7: Accuracy=0.8947, F1-macro=0.8932\n",
      "  k=9: Accuracy=0.9123, F1-macro=0.9111\n",
      "  k=11: Accuracy=0.8772, F1-macro=0.8738\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=0.9474, F1-macro=0.9489\n",
      "  k=3: Accuracy=0.9298, F1-macro=0.9309\n",
      "  k=5: Accuracy=0.8596, F1-macro=0.8576\n",
      "  k=7: Accuracy=0.8947, F1-macro=0.8905\n",
      "  k=9: Accuracy=0.8947, F1-macro=0.8874\n",
      "  k=11: Accuracy=0.8070, F1-macro=0.7966\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['0.8966', '0.9828', '0.8947', '0.9474', '0.9474']\n",
      "  Accuracy: 0.9338 ± 0.0337\n",
      "  F1-macro por fold: ['0.8873', '0.9821', '0.8946', '0.9475', '0.9489']\n",
      "  F1-macro: 0.9321 ± 0.0359\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['0.9138', '0.9483', '0.8772', '0.9298', '0.9298']\n",
      "  Accuracy: 0.9198 ± 0.0239\n",
      "  F1-macro por fold: ['0.9056', '0.9458', '0.8748', '0.9296', '0.9309']\n",
      "  F1-macro: 0.9173 ± 0.0249\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.9138', '0.9310', '0.7719', '0.9298', '0.8596']\n",
      "  Accuracy: 0.8812 ± 0.0605\n",
      "  F1-macro por fold: ['0.9056', '0.9283', '0.7536', '0.9287', '0.8576']\n",
      "  F1-macro: 0.8748 ± 0.0659\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.8966', '0.9310', '0.7895', '0.8947', '0.8947']\n",
      "  Accuracy: 0.8813 ± 0.0480\n",
      "  F1-macro por fold: ['0.8888', '0.9290', '0.7752', '0.8932', '0.8905']\n",
      "  F1-macro: 0.8753 ± 0.0522\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.8966', '0.9138', '0.8070', '0.9123', '0.8947']\n",
      "  Accuracy: 0.8849 ± 0.0397\n",
      "  F1-macro por fold: ['0.8888', '0.9130', '0.7933', '0.9111', '0.8874']\n",
      "  F1-macro: 0.8787 ± 0.0440\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.8793', '0.9138', '0.7368', '0.8772', '0.8070']\n",
      "  Accuracy: 0.8428 ± 0.0633\n",
      "  F1-macro por fold: ['0.8705', '0.9130', '0.7072', '0.8738', '0.7966']\n",
      "  F1-macro: 0.8322 ± 0.0730\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=1\n",
      "  F1-macro: 0.9321 ± 0.0359\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Density Bayes (k=1)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.8966', '0.9828', '0.8947', '0.9474', '0.9474']\n",
      "Accuracy promedio: 0.9338 ± 0.0337\n",
      "\n",
      "F1-macro por fold: ['0.8873', '0.9821', '0.8946', '0.9475', '0.9489']\n",
      "F1-macro promedio: 0.9321 ± 0.0359\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        41\n",
      "     reptile       0.78      0.98      0.87        41\n",
      "        fish       0.95      0.98      0.96        41\n",
      "   amphibian       0.97      0.76      0.85        41\n",
      "invertebrate       0.93      0.98      0.95        41\n",
      "      insect       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.93       287\n",
      "   macro avg       0.94      0.93      0.93       287\n",
      "weighted avg       0.94      0.93      0.93       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0]\n",
      " [ 0  0 40  0  1  0  0]\n",
      " [ 0  0  0 40  0  0  1]\n",
      " [ 0  0 10  0 31  0  0]\n",
      " [ 0  0  0  0  0 40  1]\n",
      " [ 0  0  1  2  0  3 35]]\n"
     ]
    }
   ],
   "source": [
    "params_knn_density = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "knn_d_results = {k: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "                 for k in params_knn_density}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for k in params_knn_density:\n",
    "        # Entrenar con este k\n",
    "        knn_density = KNNDensityBayes(k=k)\n",
    "        knn_density.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(knn_density, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        knn_d_results[k]['accuracies'].append(acc)\n",
    "        knn_d_results[k]['f1_scores'].append(f1)\n",
    "        knn_d_results[k]['all_preds'].extend(preds)\n",
    "        knn_d_results[k]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  k={k}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_k_density = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for k in params_knn_density:\n",
    "    acc_mean = np.mean(knn_d_results[k]['accuracies'])\n",
    "    acc_std = np.std(knn_d_results[k]['accuracies'])\n",
    "    f1_mean = np.mean(knn_d_results[k]['f1_scores'])\n",
    "    f1_std = np.std(knn_d_results[k]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in knn_d_results[k]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in knn_d_results[k]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_k_density = k\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: k={best_k_density}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(knn_d_results[best_k_density]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "knn_d_accuracies = knn_d_results[best_k_density]['accuracies']\n",
    "knn_d_f1_scores = knn_d_results[best_k_density]['f1_scores']\n",
    "knn_d_all_preds = knn_d_results[best_k_density]['all_preds']\n",
    "knn_d_all_true = knn_d_results[best_k_density]['all_true']\n",
    "\n",
    "knn_d_mean_acc, knn_d_mean_f1 = print_cv_results(f\"k-NN Density Bayes (k={best_k_density})\", \n",
    "                                                  knn_d_accuracies, knn_d_f1_scores,\n",
    "                                                  knn_d_all_preds, knn_d_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecd98e",
   "metadata": {},
   "source": [
    "## 10. Modelo 6: k-NN Rule (Directo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d29bdd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "6. K-NEAREST NEIGHBORS RULE (Directo)\n",
      "================================================================================\n",
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  k=1: Accuracy=0.8966, F1-macro=0.8873\n",
      "  k=3: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=5: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=7: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=9: Accuracy=0.9138, F1-macro=0.9056\n",
      "  k=11: Accuracy=0.9138, F1-macro=0.9056\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  k=1: Accuracy=0.9828, F1-macro=0.9821\n",
      "  k=3: Accuracy=0.9655, F1-macro=0.9637\n",
      "  k=5: Accuracy=0.9655, F1-macro=0.9637\n",
      "  k=7: Accuracy=0.9138, F1-macro=0.9103\n",
      "  k=9: Accuracy=0.9138, F1-macro=0.9103\n",
      "  k=11: Accuracy=0.9310, F1-macro=0.9290\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  k=1: Accuracy=0.8421, F1-macro=0.8355\n",
      "  k=3: Accuracy=0.8246, F1-macro=0.8202\n",
      "  k=5: Accuracy=0.8596, F1-macro=0.8571\n",
      "  k=7: Accuracy=0.8596, F1-macro=0.8538\n",
      "  k=9: Accuracy=0.8246, F1-macro=0.8186\n",
      "  k=11: Accuracy=0.8070, F1-macro=0.7908\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  k=1: Accuracy=0.9474, F1-macro=0.9475\n",
      "  k=3: Accuracy=0.9649, F1-macro=0.9643\n",
      "  k=5: Accuracy=0.9298, F1-macro=0.9296\n",
      "  k=7: Accuracy=0.9474, F1-macro=0.9474\n",
      "  k=9: Accuracy=0.9474, F1-macro=0.9467\n",
      "  k=11: Accuracy=0.9298, F1-macro=0.9292\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=0.9123, F1-macro=0.9127\n",
      "  k=3: Accuracy=0.9123, F1-macro=0.9132\n",
      "  k=5: Accuracy=0.8947, F1-macro=0.8962\n",
      "  k=7: Accuracy=0.8772, F1-macro=0.8814\n",
      "  k=9: Accuracy=0.8772, F1-macro=0.8814\n",
      "  k=11: Accuracy=0.8772, F1-macro=0.8769\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['0.8966', '0.9828', '0.8421', '0.9474', '0.9123']\n",
      "  Accuracy: 0.9162 ± 0.0475\n",
      "  F1-macro por fold: ['0.8873', '0.9821', '0.8355', '0.9475', '0.9127']\n",
      "  F1-macro: 0.9130 ± 0.0502\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['0.9138', '0.9655', '0.8246', '0.9649', '0.9123']\n",
      "  Accuracy: 0.9162 ± 0.0514\n",
      "  F1-macro por fold: ['0.9056', '0.9637', '0.8202', '0.9643', '0.9132']\n",
      "  F1-macro: 0.9134 ± 0.0527\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.9138', '0.9655', '0.8596', '0.9298', '0.8947']\n",
      "  Accuracy: 0.9127 ± 0.0353\n",
      "  F1-macro por fold: ['0.9056', '0.9637', '0.8571', '0.9296', '0.8962']\n",
      "  F1-macro: 0.9104 ± 0.0354\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.9138', '0.9138', '0.8596', '0.9474', '0.8772']\n",
      "  Accuracy: 0.9024 ± 0.0308\n",
      "  F1-macro por fold: ['0.9056', '0.9103', '0.8538', '0.9474', '0.8814']\n",
      "  F1-macro: 0.8997 ± 0.0312\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.9138', '0.9138', '0.8246', '0.9474', '0.8772']\n",
      "  Accuracy: 0.8953 ± 0.0418\n",
      "  F1-macro por fold: ['0.9056', '0.9103', '0.8186', '0.9467', '0.8814']\n",
      "  F1-macro: 0.8925 ± 0.0425\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.9138', '0.9310', '0.8070', '0.9298', '0.8772']\n",
      "  Accuracy: 0.8918 ± 0.0466\n",
      "  F1-macro por fold: ['0.9056', '0.9290', '0.7908', '0.9292', '0.8769']\n",
      "  F1-macro: 0.8863 ± 0.0514\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=3\n",
      "  F1-macro: 0.9134 ± 0.0527\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Rule (k=3)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.9138', '0.9655', '0.8246', '0.9649', '0.9123']\n",
      "Accuracy promedio: 0.9162 ± 0.0514\n",
      "\n",
      "F1-macro por fold: ['0.9056', '0.9637', '0.8202', '0.9643', '0.9132']\n",
      "F1-macro promedio: 0.9134 ± 0.0527\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        41\n",
      "     reptile       0.76      0.93      0.84        41\n",
      "        fish       0.91      1.00      0.95        41\n",
      "   amphibian       0.94      0.71      0.81        41\n",
      "invertebrate       0.93      0.93      0.93        41\n",
      "      insect       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.92       287\n",
      "   macro avg       0.92      0.92      0.92       287\n",
      "weighted avg       0.92      0.92      0.92       287\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0]\n",
      " [ 0  0 38  1  2  0  0]\n",
      " [ 0  0  0 41  0  0  0]\n",
      " [ 0  0 11  1 29  0  0]\n",
      " [ 0  0  0  0  0 38  3]\n",
      " [ 0  0  1  2  0  3 35]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"6. K-NEAREST NEIGHBORS RULE (Directo)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "params_knn = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "knn_results = {k: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "               for k in params_knn}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for k in params_knn:\n",
    "        # Entrenar con este k\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "        knn.fit(X_train_val, y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(knn, X_test_fold, y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        knn_results[k]['accuracies'].append(acc)\n",
    "        knn_results[k]['f1_scores'].append(f1)\n",
    "        knn_results[k]['all_preds'].extend(preds)\n",
    "        knn_results[k]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  k={k}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_k_knn = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for k in params_knn:\n",
    "    acc_mean = np.mean(knn_results[k]['accuracies'])\n",
    "    acc_std = np.std(knn_results[k]['accuracies'])\n",
    "    f1_mean = np.mean(knn_results[k]['f1_scores'])\n",
    "    f1_std = np.std(knn_results[k]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in knn_results[k]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in knn_results[k]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_k_knn = k\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: k={best_k_knn}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(knn_results[best_k_knn]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "knn_accuracies = knn_results[best_k_knn]['accuracies']\n",
    "knn_f1_scores = knn_results[best_k_knn]['f1_scores']\n",
    "knn_all_preds = knn_results[best_k_knn]['all_preds']\n",
    "knn_all_true = knn_results[best_k_knn]['all_true']\n",
    "\n",
    "knn_mean_acc, knn_mean_f1 = print_cv_results(f\"k-NN Rule (k={best_k_knn})\", \n",
    "                                              knn_accuracies, knn_f1_scores,\n",
    "                                              knn_all_preds, knn_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505fd08",
   "metadata": {},
   "source": [
    "## 11. Comparación final de todos los modelos\n",
    "\n",
    "Resultados de validación cruzada 5-fold sobre todo el conjunto de datos. Cada modelo se evaluó en 5 tests diferentes (uno por fold), y se reportan las métricas promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "230c2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARACIÓN FINAL DE MODELOS - CROSS VALIDATION 5-FOLD\n",
      "================================================================================\n",
      "\n",
      "Modelo                          Accuracy (mean±std)       F1-macro (mean±std)\n",
      "--------------------------------------------------------------------------------\n",
      "Naive Bayes                         0.8813 ± 0.0680           0.8687 ± 0.0796\n",
      "MLE Full                            0.8919 ± 0.0489           0.8905 ± 0.0498\n",
      "Histogram Bayes                     0.1533 ± 0.0127           0.0552 ± 0.0166\n",
      "Parzen Windows                      0.9338 ± 0.0280           0.9323 ± 0.0283\n",
      "k-NN Density Bayes                  0.9338 ± 0.0337           0.9321 ± 0.0359\n",
      "k-NN Rule                           0.9162 ± 0.0514           0.9134 ± 0.0527\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Mejor modelo (por F1-macro promedio): Parzen Windows\n",
      "  F1-macro: 0.9323 ± 0.0283\n",
      "\n",
      "================================================================================\n",
      "✓ Análisis completo finalizado con Cross-Validation 5-fold\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACIÓN FINAL DE MODELOS - CROSS VALIDATION 5-FOLD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compilar todos los resultados\n",
    "results = {\n",
    "    'Naive Bayes': {\n",
    "        'acc_mean': np.mean(nb_accuracies),\n",
    "        'acc_std': np.std(nb_accuracies),\n",
    "        'f1_mean': np.mean(nb_f1_scores),\n",
    "        'f1_std': np.std(nb_f1_scores)\n",
    "    },\n",
    "    'MLE Full': {\n",
    "        'acc_mean': np.mean(mle_accuracies),\n",
    "        'acc_std': np.std(mle_accuracies),\n",
    "        'f1_mean': np.mean(mle_f1_scores),\n",
    "        'f1_std': np.std(mle_f1_scores)\n",
    "    },\n",
    "    'Histogram Bayes': {\n",
    "        'acc_mean': np.mean(hist_accuracies),\n",
    "        'acc_std': np.std(hist_accuracies),\n",
    "        'f1_mean': np.mean(hist_f1_scores),\n",
    "        'f1_std': np.std(hist_f1_scores)\n",
    "    },\n",
    "    'Parzen Windows': {\n",
    "        'acc_mean': np.mean(parzen_accuracies),\n",
    "        'acc_std': np.std(parzen_accuracies),\n",
    "        'f1_mean': np.mean(parzen_f1_scores),\n",
    "        'f1_std': np.std(parzen_f1_scores)\n",
    "    },\n",
    "    'k-NN Density Bayes': {\n",
    "        'acc_mean': np.mean(knn_d_accuracies),\n",
    "        'acc_std': np.std(knn_d_accuracies),\n",
    "        'f1_mean': np.mean(knn_d_f1_scores),\n",
    "        'f1_std': np.std(knn_d_f1_scores)\n",
    "    },\n",
    "    'k-NN Rule': {\n",
    "        'acc_mean': np.mean(knn_accuracies),\n",
    "        'acc_std': np.std(knn_accuracies),\n",
    "        'f1_mean': np.mean(knn_f1_scores),\n",
    "        'f1_std': np.std(knn_f1_scores)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Modelo':<25} {'Accuracy (mean±std)':>25} {'F1-macro (mean±std)':>25}\")\n",
    "print(\"-\" * 80)\n",
    "for model, metrics in results.items():\n",
    "    acc_str = f\"{metrics['acc_mean']:.4f} ± {metrics['acc_std']:.4f}\"\n",
    "    f1_str = f\"{metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\"\n",
    "    print(f\"{model:<25} {acc_str:>25} {f1_str:>25}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Mejor modelo por F1-macro (prioridad para multiclass)\n",
    "best_model = max(results, key=lambda k: results[k]['f1_mean'])\n",
    "print(f\"\\n✓ Mejor modelo (por F1-macro promedio): {best_model}\")\n",
    "print(f\"  F1-macro: {results[best_model]['f1_mean']:.4f} ± {results[best_model]['f1_std']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Análisis completo finalizado con Cross-Validation 5-fold\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
