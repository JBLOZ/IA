{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed824d4c",
   "metadata": {},
   "source": [
    "# Análisis del Dataset Zoo - Clasificación Multiclase\n",
    "\n",
    "Este notebook implementa y evalúa 6 algoritmos de clasificación en el dataset Zoo de UCI:\n",
    "1. Naive Bayes Gaussiano\n",
    "2. MLE Multivariante (Full Bayesian Gaussian)\n",
    "3. Histogram Bayes\n",
    "4. Parzen Windows\n",
    "5. k-NN Density Bayes\n",
    "6. k-NN Rule\n",
    "\n",
    "Dataset: 17 atributos (15 binarios + 1 numérico + 1 clase), 7 clases de animales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ef993",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5f49f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Silenciar warnings\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='joblib')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b966",
   "metadata": {},
   "source": [
    "## 2. Carga y análisis exploratorio del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be517131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\n",
      "================================================================================\n",
      "\n",
      "Información del dataset:\n",
      "Forma: (101, 16) (instancias x features)\n",
      "Clases: 7 (multiclass: ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect'])\n",
      "\n",
      "Distribución de clases:\n",
      "Clase 1 (mammal): 41 muestras (40.6%)\n",
      "Clase 2 (bird): 20 muestras (19.8%)\n",
      "Clase 3 (reptile): 5 muestras (5.0%)\n",
      "Clase 4 (fish): 13 muestras (12.9%)\n",
      "Clase 5 (amphibian): 4 muestras (4.0%)\n",
      "Clase 6 (invertebrate): 8 muestras (7.9%)\n",
      "Clase 7 (insect): 10 muestras (9.9%)\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "     animal  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0  aardvark          1          0          0          1          0          0   \n",
      "1  antelope          1          0          0          1          0          0   \n",
      "2      bass          0          0          1          0          0          1   \n",
      "3      bear          1          0          0          1          0          0   \n",
      "4      boar          1          0          0          1          0          0   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  feature_11  feature_12  \\\n",
      "0          1          1          1           1           0           0   \n",
      "1          0          1          1           1           0           0   \n",
      "2          1          1          1           0           0           1   \n",
      "3          1          1          1           1           0           0   \n",
      "4          1          1          1           1           0           0   \n",
      "\n",
      "   feature_13  feature_14  feature_15  feature_16  class  \n",
      "0           4           0           0           1      1  \n",
      "1           4           1           0           1      1  \n",
      "2           0           1           0           0      4  \n",
      "3           4           0           0           1      1  \n",
      "4           4           1           0           1      1  \n"
     ]
    }
   ],
   "source": [
    "# Clases del Zoo dataset (1-7 -> labels para report)\n",
    "class_names = ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'invertebrate', 'insect']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANÁLISIS DEL DATASET ZOO (Multiclass Classification)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datos: zoo.data (col 0: animal name (ignorar), col 1-17: features, col 18: class 1-7)\n",
    "df = pd.read_csv('./data_zoo/zoo.csv')\n",
    "# df = pd.read_csv('./data_zoo/zoo.csv')\n",
    "df.columns = ['animal'] + [f'feature_{i}' for i in range(1, 17)] + ['class']\n",
    "X = df.iloc[:, 1:-1]  # Features 1-17\n",
    "y = df.iloc[:, -1].values - 1  # Clase 0-6 para sklearn\n",
    "\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(f\"Forma: {X.shape} (instancias x features)\")\n",
    "print(f\"Clases: {len(np.unique(y))} (multiclass: {class_names})\")\n",
    "print(\"\\nDistribución de clases:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for i, (cls, count) in enumerate(zip(class_names, counts)):\n",
    "    print(f\"Clase {i+1} ({cls}): {count} muestras ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95066c",
   "metadata": {},
   "source": [
    "## 3. Configuración de validación cruzada\n",
    "\n",
    "**Estrategia:** Usamos validación cruzada 5-fold estratificada sobre **todo el conjunto de datos**. En cada fold:\n",
    "- Se divide en Train+Val (80%) y Test (20%)\n",
    "- El conjunto Train+Val se subdivide para selección de hiperparámetros (validación interna)\n",
    "- El Test de cada fold se usa para evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c0eaad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de muestras: 101\n",
      "Estrategia: Cross-Validation 5-fold sobre todo el conjunto\n",
      "Cada fold: ~81 train+val (~80%), ~20 test (~20%)\n",
      "\n",
      "Distribución de clases en el conjunto completo:\n",
      "0    41\n",
      "1    20\n",
      "2     5\n",
      "3    13\n",
      "4     4\n",
      "5     8\n",
      "6    10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Configuración de validación cruzada: 5-fold estratificada sobre todo el dataset\n"
     ]
    }
   ],
   "source": [
    "# Configuración: CV estratificado 5-fold sobre TODO el dataset\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "\n",
    "print(f\"Total de muestras: {len(X)}\")\n",
    "print(f\"Estrategia: Cross-Validation 5-fold sobre todo el conjunto\")\n",
    "print(f\"Cada fold: ~{len(X)*0.8:.0f} train+val (~80%), ~{len(X)*0.2:.0f} test (~20%)\")\n",
    "print(\"\\nDistribución de clases en el conjunto completo:\")\n",
    "print(pd.Series(y).value_counts().sort_index())\n",
    "\n",
    "print(\"\\n✓ Configuración de validación cruzada: 5-fold estratificada sobre todo el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb11529",
   "metadata": {},
   "source": [
    "## 4. Funciones auxiliares para evaluación con CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0df8d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Funciones de evaluación definidas\n"
     ]
    }
   ],
   "source": [
    "# Función para evaluar modelo en un fold específico\n",
    "def evaluate_fold(model, X_test, y_test, fold_num):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de test del fold\"\"\"\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1_mac = f1_score(y_test, preds, average='macro')\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    return acc, f1_mac, cm, preds\n",
    "\n",
    "# Función para imprimir resultados agregados de CV\n",
    "def print_cv_results(model_name, accuracies, f1_scores, all_preds, all_true):\n",
    "    \"\"\"Imprime resultados agregados de cross-validation\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTADOS CV: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAccuracy por fold: {[f'{acc:.4f}' for acc in accuracies]}\")\n",
    "    print(f\"Accuracy promedio: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "    print(f\"\\nF1-macro por fold: {[f'{f1:.4f}' for f1 in f1_scores]}\")\n",
    "    print(f\"F1-macro promedio: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "    \n",
    "    # Reporte global (concatenando todas las predicciones)\n",
    "    print(f\"\\n--- Reporte de clasificación global (todos los folds) ---\")\n",
    "    print(classification_report(all_true, all_preds, target_names=class_names))\n",
    "    \n",
    "    # Matriz de confusión global\n",
    "    cm_global = confusion_matrix(all_true, all_preds)\n",
    "    print(f\"\\nMatriz de confusión global:\")\n",
    "    print(cm_global)\n",
    "    \n",
    "    return np.mean(accuracies), np.mean(f1_scores)\n",
    "\n",
    "print(\"✓ Funciones de evaluación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55e565",
   "metadata": {},
   "source": [
    "## 5. Modelo 1: Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9a35749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. NAIVE BAYES GAUSSIANO\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Accuracy: 1.0000, F1-macro: 1.0000\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 1.0000, F1-macro: 1.0000\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 1.0000, F1-macro: 1.0000\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.9500, F1-macro: 0.8367\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.8500, F1-macro: 0.6583\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Naive Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '1.0000', '1.0000', '0.9500', '0.8500']\n",
      "Accuracy promedio: 0.9600 ± 0.0583\n",
      "\n",
      "F1-macro por fold: ['1.0000', '1.0000', '1.0000', '0.8367', '0.6583']\n",
      "F1-macro promedio: 0.8990 ± 0.1360\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.98      1.00      0.99        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       0.60      0.60      0.60         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       1.00      0.75      0.86         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.96       101\n",
      "   macro avg       0.93      0.89      0.91       101\n",
      "weighted avg       0.96      0.96      0.96       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 1  0  3  1  0  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  1  0  3  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  1  0  0  0  9]]\n",
      "Accuracy: 1.0000, F1-macro: 1.0000\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.9500, F1-macro: 0.8367\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.8500, F1-macro: 0.6583\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Naive Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '1.0000', '1.0000', '0.9500', '0.8500']\n",
      "Accuracy promedio: 0.9600 ± 0.0583\n",
      "\n",
      "F1-macro por fold: ['1.0000', '1.0000', '1.0000', '0.8367', '0.6583']\n",
      "F1-macro promedio: 0.8990 ± 0.1360\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.98      1.00      0.99        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       0.60      0.60      0.60         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       1.00      0.75      0.86         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.96       101\n",
      "   macro avg       0.93      0.89      0.91       101\n",
      "weighted avg       0.96      0.96      0.96       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 1  0  3  1  0  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  1  0  3  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  1  0  0  0  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"1. NAIVE BAYES GAUSSIANO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "nb_accuracies = []\n",
    "nb_f1_scores = []\n",
    "nb_all_preds = []\n",
    "nb_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar Naive Bayes (sin hiperparámetros)\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(nb, X_test_fold, y_test_fold, fold)\n",
    "    nb_accuracies.append(acc)\n",
    "    nb_f1_scores.append(f1)\n",
    "    nb_all_preds.extend(preds)\n",
    "    nb_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "nb_mean_acc, nb_mean_f1 = print_cv_results(\"Naive Bayes\", nb_accuracies, nb_f1_scores, \n",
    "                                            nb_all_preds, nb_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f99bde",
   "metadata": {},
   "source": [
    "## 6. Modelo 2: MLE Multivariante (Full Bayesian Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb3ab5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\n",
      "================================================================================\n",
      "✓ Clase FullGaussianBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"2. MLE MULTIVARIANTE (Full Bayesian Gaussian)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class FullGaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.covs = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.means = np.array([X[y == c].mean(axis=0) for c in self.classes])\n",
    "        self.covs = np.array([np.cov(X[y == c].T) + 1e-6 * np.eye(X.shape[1]) for c in self.classes])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = multivariate_normal(mean=self.means[i], cov=self.covs[i]).logpdf(X)\n",
    "        posteriors = np.exp(ll) * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase FullGaussianBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59966e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Accuracy: 0.8571, F1-macro: 0.6463\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 0.8000, F1-macro: 0.5778\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.8000, F1-macro: 0.5778\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.8500, F1-macro: 0.6441\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.8000, F1-macro: 0.5143\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.8500, F1-macro: 0.6441\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.8000, F1-macro: 0.5143\n",
      "\n",
      "--- Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/var/folders/0m/q5gmrh695pvc0bcq9s0zmcqh0000gr/T/ipykernel_2848/2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "/var/folders/0m/q5gmrh695pvc0bcq9s0zmcqh0000gr/T/ipykernel_2848/2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "/var/folders/0m/q5gmrh695pvc0bcq9s0zmcqh0000gr/T/ipykernel_2848/2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "/var/folders/0m/q5gmrh695pvc0bcq9s0zmcqh0000gr/T/ipykernel_2848/2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n",
      "/var/folders/0m/q5gmrh695pvc0bcq9s0zmcqh0000gr/T/ipykernel_2848/2355046959.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  posteriors /= posteriors.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7500, F1-macro: 0.5374\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: MLE Full Gaussian\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.7500']\n",
      "Accuracy promedio: 0.8114 ± 0.0390\n",
      "\n",
      "F1-macro por fold: ['0.6463', '0.5778', '0.6441', '0.5143', '0.5374']\n",
      "F1-macro promedio: 0.5840 ± 0.0540\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.68      1.00      0.81        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       0.00      0.00      0.00         5\n",
      "        fish       1.00      0.85      0.92        13\n",
      "   amphibian       0.00      0.00      0.00         4\n",
      "invertebrate       1.00      0.50      0.67         8\n",
      "      insect       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.81       101\n",
      "   macro avg       0.67      0.56      0.59       101\n",
      "weighted avg       0.78      0.81      0.77       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 2  0  0 11  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  4  0]\n",
      " [ 4  0  0  0  0  0  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "mle_accuracies = []\n",
    "mle_f1_scores = []\n",
    "mle_all_preds = []\n",
    "mle_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar MLE Full\n",
    "    mle = FullGaussianBayes()\n",
    "    mle.fit(X_train_val.values, y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(mle, X_test_fold.values, y_test_fold, fold)\n",
    "    mle_accuracies.append(acc)\n",
    "    mle_f1_scores.append(f1)\n",
    "    mle_all_preds.extend(preds)\n",
    "    mle_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "mle_mean_acc, mle_mean_f1 = print_cv_results(\"MLE Full Gaussian\", mle_accuracies, mle_f1_scores,\n",
    "                                              mle_all_preds, mle_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e65472",
   "metadata": {},
   "source": [
    "## 7. Modelo 3: Histogram Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87ec2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\n",
      "================================================================================\n",
      "✓ Clase HistogramBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"3. DENSIDAD NO PARAMÉTRICA - HISTOGRAMA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HistogramBayes:\n",
    "    def __init__(self, bins=2):\n",
    "        self.bins = bins\n",
    "        self.priors = None\n",
    "        self.hist_per_class = None\n",
    "        self.edges = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.hist_per_class = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            hists = []\n",
    "            edges_list = []\n",
    "            for feat in range(X.shape[1]):\n",
    "                hist, edges = np.histogram(X_c.iloc[:, feat], bins=self.bins, density=True)\n",
    "                hists.append(hist)\n",
    "                edges_list.append(edges)\n",
    "            self.hist_per_class[c] = (np.array(hists), edges_list)\n",
    "        self.edges = edges_list[0] if edges_list else None\n",
    "        return self\n",
    "    \n",
    "    def _density_hist(self, x, c):\n",
    "        hists, edges = self.hist_per_class[c]\n",
    "        dens = 1.0\n",
    "        for i, feat_val in enumerate(x):\n",
    "            bin_idx = np.digitize(feat_val, edges[i]) - 1\n",
    "            if 0 <= bin_idx < len(hists[i]):\n",
    "                dens *= hists[i][bin_idx]\n",
    "            else:\n",
    "                dens *= 0\n",
    "        return dens\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = len(X)\n",
    "        preds = np.zeros(n_samples, dtype=int)\n",
    "        for i in range(n_samples):\n",
    "            posteriors = []\n",
    "            for c in self.classes:\n",
    "                dens = self._density_hist(X.iloc[i], c)\n",
    "                post = self.priors[c] * dens\n",
    "                posteriors.append(post)\n",
    "            preds[i] = self.classes[np.argmax(posteriors)]\n",
    "        return preds\n",
    "\n",
    "print(\"✓ Clase HistogramBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9dd7251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4762, F1-macro: 0.1839\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Accuracy: 0.4000, F1-macro: 0.0952\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.4000, F1-macro: 0.0952\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Accuracy: 0.5500, F1-macro: 0.3486\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.5500, F1-macro: 0.3486\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Accuracy: 0.4500, F1-macro: 0.1561\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.4000, F1-macro: 0.0816\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Histogram Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.4762', '0.4000', '0.5500', '0.4500', '0.4000']\n",
      "Accuracy promedio: 0.4552 ± 0.0558\n",
      "\n",
      "F1-macro por fold: ['0.1839', '0.0952', '0.3486', '0.1561', '0.0816']\n",
      "F1-macro promedio: 0.1731 ± 0.0955\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.43      1.00      0.60        41\n",
      "        bird       0.00      0.00      0.00        20\n",
      "     reptile       0.00      0.00      0.00         5\n",
      "        fish       1.00      0.23      0.38        13\n",
      "   amphibian       0.00      0.00      0.00         4\n",
      "invertebrate       1.00      0.25      0.40         8\n",
      "      insect       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.46       101\n",
      "   macro avg       0.35      0.21      0.20       101\n",
      "weighted avg       0.38      0.46      0.32       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [20  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [10  0  0  3  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  2  0]\n",
      " [10  0  0  0  0  0  0]]\n",
      "Accuracy: 0.4500, F1-macro: 0.1561\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Accuracy: 0.4000, F1-macro: 0.0816\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Histogram Bayes\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['0.4762', '0.4000', '0.5500', '0.4500', '0.4000']\n",
      "Accuracy promedio: 0.4552 ± 0.0558\n",
      "\n",
      "F1-macro por fold: ['0.1839', '0.0952', '0.3486', '0.1561', '0.0816']\n",
      "F1-macro promedio: 0.1731 ± 0.0955\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       0.43      1.00      0.60        41\n",
      "        bird       0.00      0.00      0.00        20\n",
      "     reptile       0.00      0.00      0.00         5\n",
      "        fish       1.00      0.23      0.38        13\n",
      "   amphibian       0.00      0.00      0.00         4\n",
      "invertebrate       1.00      0.25      0.40         8\n",
      "      insect       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.46       101\n",
      "   macro avg       0.35      0.21      0.20       101\n",
      "weighted avg       0.38      0.46      0.32       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [20  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [10  0  0  3  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  2  0]\n",
      " [10  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "hist_accuracies = []\n",
    "hist_f1_scores = []\n",
    "hist_all_preds = []\n",
    "hist_all_true = []\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar Histogram Bayes (bins=2 fijo para datos binarios)\n",
    "    hist_bayes = HistogramBayes(bins=2)\n",
    "    hist_bayes.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "    \n",
    "    # Evaluar en test del fold\n",
    "    acc, f1, cm, preds = evaluate_fold(hist_bayes, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "    hist_accuracies.append(acc)\n",
    "    hist_f1_scores.append(f1)\n",
    "    hist_all_preds.extend(preds)\n",
    "    hist_all_true.extend(y_test_fold)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1-macro: {f1:.4f}\")\n",
    "\n",
    "# Resultados agregados\n",
    "hist_mean_acc, hist_mean_f1 = print_cv_results(\"Histogram Bayes\", hist_accuracies, hist_f1_scores,\n",
    "                                                hist_all_preds, hist_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e6554",
   "metadata": {},
   "source": [
    "## 8. Modelo 4: Parzen Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fe81d",
   "metadata": {},
   "source": [
    "**Nota sobre selección de hiperparámetros:** \n",
    "- Se evalúan todos los hiperparámetros en cada uno de los 5 folds\n",
    "- Se obtiene una matriz de resultados (hiperparámetros × folds)\n",
    "- Se selecciona el hiperparámetro con mejor promedio de F1-macro\n",
    "- Se reportan los resultados del mejor hiperparámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab12c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\n",
      "================================================================================\n",
      "✓ Clase ParzenBayes definida\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"4. DENSIDAD NO PARAMÉTRICA - PARZEN WINDOWS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ParzenBayes:\n",
    "    def __init__(self, bandwidth=0.5):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.priors = None\n",
    "        self.kdes = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        self.kdes = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values.reshape(-1, X.shape[1])\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=self.bandwidth).fit(X_c)\n",
    "            self.kdes[c] = kde\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_val = X.values.reshape(-1, X.shape[1])\n",
    "        n_samples = len(X_val)\n",
    "        ll = np.zeros((n_samples, len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            ll[:, i] = np.exp(self.kdes[c].score_samples(X_val))\n",
    "        posteriors = ll * self.priors\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "\n",
    "print(\"✓ Clase ParzenBayes definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a72e533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  h=0.05: Accuracy=1.0000, F1-macro=1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  h=0.1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=0.5: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=1.0: Accuracy=0.9048, F1-macro=0.7619\n",
      "  h=1.5: Accuracy=0.8095, F1-macro=0.5095\n",
      "  h=2.0: Accuracy=0.7143, F1-macro=0.3550\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.7143\n",
      "  h=0.1: Accuracy=0.9500, F1-macro=0.7143\n",
      "  h=0.5: Accuracy=0.9500, F1-macro=0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  h=1.0: Accuracy=0.9500, F1-macro=0.8235\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.5856\n",
      "  h=2.0: Accuracy=0.7500, F1-macro=0.4314\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.9440\n",
      "  h=0.1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=0.5: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=1.0: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.4712\n",
      "  h=0.1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=0.5: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=1.0: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.4712\n",
      "  h=2.0: Accuracy=0.7500, F1-macro=0.3856\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=0.1: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=0.5: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.0: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.5193\n",
      "  h=2.0: Accuracy=0.7500, F1-macro=0.3697\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.9440\n",
      "  h=0.1: Accuracy=0.9500, F1-macro=0.8095\n",
      "  h=0.5: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=1.0: Accuracy=0.8000, F1-macro=0.5843\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.5843\n",
      "  h=2.0: Accuracy=0.6500, F1-macro=0.3571\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "h=0.05:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '0.9500', '0.9500', '0.9500']\n",
      "  Accuracy: 0.9600 ± 0.0200\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '0.9440', '0.8367', '0.9440']\n",
      "  F1-macro: 0.8878 ± 0.1016\n",
      "\n",
      "h=0.1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '0.9500']\n",
      "  Accuracy: 0.9700 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '0.8095']\n",
      "  F1-macro: 0.8721 ± 0.1121\n",
      "\n",
      "h=0.5:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "\n",
      "h=1.0:\n",
      "  Accuracy por fold: ['0.9048', '0.9500', '0.9500', '0.9500', '0.8000']\n",
      "  Accuracy: 0.9110 ± 0.0582\n",
      "  F1-macro por fold: ['0.7619', '0.8235', '0.8367', '0.8367', '0.5843']\n",
      "  F1-macro: 0.7686 ± 0.0962\n",
      "\n",
      "h=1.5:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8000', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8019 ± 0.0038\n",
      "  F1-macro por fold: ['0.5095', '0.5856', '0.4712', '0.5193', '0.5843']\n",
      "  F1-macro: 0.5340 ± 0.0446\n",
      "\n",
      "h=2.0:\n",
      "  Accuracy por fold: ['0.7143', '0.7500', '0.7500', '0.7500', '0.6500']\n",
      "  Accuracy: 0.7229 ± 0.0390\n",
      "  F1-macro por fold: ['0.3550', '0.4314', '0.3856', '0.3697', '0.3571']\n",
      "  F1-macro: 0.3798 ± 0.0280\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: h=0.5\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Parzen Windows (h=0.5)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "F1-macro promedio: 0.9102 ± 0.1166\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       1.00      0.60      0.75         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       0.80      1.00      0.89         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.96      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  3  1  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n",
      "  h=2.0: Accuracy=0.7500, F1-macro=0.3856\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=0.1: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=0.5: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.0: Accuracy=0.9500, F1-macro=0.8367\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.5193\n",
      "  h=2.0: Accuracy=0.7500, F1-macro=0.3697\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  h=0.05: Accuracy=0.9500, F1-macro=0.9440\n",
      "  h=0.1: Accuracy=0.9500, F1-macro=0.8095\n",
      "  h=0.5: Accuracy=1.0000, F1-macro=1.0000\n",
      "  h=1.0: Accuracy=0.8000, F1-macro=0.5843\n",
      "  h=1.5: Accuracy=0.8000, F1-macro=0.5843\n",
      "  h=2.0: Accuracy=0.6500, F1-macro=0.3571\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "h=0.05:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '0.9500', '0.9500', '0.9500']\n",
      "  Accuracy: 0.9600 ± 0.0200\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '0.9440', '0.8367', '0.9440']\n",
      "  F1-macro: 0.8878 ± 0.1016\n",
      "\n",
      "h=0.1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '0.9500']\n",
      "  Accuracy: 0.9700 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '0.8095']\n",
      "  F1-macro: 0.8721 ± 0.1121\n",
      "\n",
      "h=0.5:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "\n",
      "h=1.0:\n",
      "  Accuracy por fold: ['0.9048', '0.9500', '0.9500', '0.9500', '0.8000']\n",
      "  Accuracy: 0.9110 ± 0.0582\n",
      "  F1-macro por fold: ['0.7619', '0.8235', '0.8367', '0.8367', '0.5843']\n",
      "  F1-macro: 0.7686 ± 0.0962\n",
      "\n",
      "h=1.5:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8000', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8019 ± 0.0038\n",
      "  F1-macro por fold: ['0.5095', '0.5856', '0.4712', '0.5193', '0.5843']\n",
      "  F1-macro: 0.5340 ± 0.0446\n",
      "\n",
      "h=2.0:\n",
      "  Accuracy por fold: ['0.7143', '0.7500', '0.7500', '0.7500', '0.6500']\n",
      "  Accuracy: 0.7229 ± 0.0390\n",
      "  F1-macro por fold: ['0.3550', '0.4314', '0.3856', '0.3697', '0.3571']\n",
      "  F1-macro: 0.3798 ± 0.0280\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: h=0.5\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: Parzen Windows (h=0.5)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "F1-macro promedio: 0.9102 ± 0.1166\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       1.00      0.60      0.75         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       0.80      1.00      0.89         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.96      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  3  1  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "params_parzen = [0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "parzen_results = {h: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "                  for h in params_parzen}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for h in params_parzen:\n",
    "        # Entrenar con este h\n",
    "        parzen = ParzenBayes(bandwidth=h)\n",
    "        parzen.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(parzen, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        parzen_results[h]['accuracies'].append(acc)\n",
    "        parzen_results[h]['f1_scores'].append(f1)\n",
    "        parzen_results[h]['all_preds'].extend(preds)\n",
    "        parzen_results[h]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  h={h}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_h = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for h in params_parzen:\n",
    "    acc_mean = np.mean(parzen_results[h]['accuracies'])\n",
    "    acc_std = np.std(parzen_results[h]['accuracies'])\n",
    "    f1_mean = np.mean(parzen_results[h]['f1_scores'])\n",
    "    f1_std = np.std(parzen_results[h]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nh={h}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in parzen_results[h]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in parzen_results[h]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_h = h\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: h={best_h}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(parzen_results[best_h]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "parzen_accuracies = parzen_results[best_h]['accuracies']\n",
    "parzen_f1_scores = parzen_results[best_h]['f1_scores']\n",
    "parzen_all_preds = parzen_results[best_h]['all_preds']\n",
    "parzen_all_true = parzen_results[best_h]['all_true']\n",
    "\n",
    "parzen_mean_acc, parzen_mean_f1 = print_cv_results(f\"Parzen Windows (h={best_h})\", \n",
    "                                                    parzen_accuracies, parzen_f1_scores,\n",
    "                                                    parzen_all_preds, parzen_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17b910",
   "metadata": {},
   "source": [
    "## 9. Modelo 5: k-NN Density Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "901ccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "class KNNDensityBayes:\n",
    "    \"\"\"\n",
    "    Clasificador Bayesiano usando estimación de densidad k-NN.\n",
    "    \n",
    "    La densidad se estima como:\n",
    "        p(x|ω) = k / (|D_ω| * V_k(x))\n",
    "    \n",
    "    donde V_k(x) es el volumen de la hiper-esfera que contiene\n",
    "    los k vecinos más cercanos de x en la clase ω.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.priors = None\n",
    "        self.nn_models = {}  # Un modelo de vecinos por clase\n",
    "        self.classes = None\n",
    "        self.class_data = {}  # Datos de entrenamiento por clase\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el modelo guardando los datos de cada clase.\"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = np.bincount(y) / len(y)\n",
    "        \n",
    "        # Para cada clase, guardamos sus datos y entrenamos un NearestNeighbors\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c].values if hasattr(X, 'values') else X[y == c]\n",
    "            self.class_data[c] = X_c\n",
    "            \n",
    "            # Crear modelo de vecinos más cercanos para esta clase\n",
    "            nn_model = NearestNeighbors(n_neighbors=min(self.k, len(X_c)), \n",
    "                                        algorithm='auto', \n",
    "                                        metric='euclidean')\n",
    "            nn_model.fit(X_c)\n",
    "            self.nn_models[c] = nn_model\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _estimate_density(self, X_val, class_idx):\n",
    "        \"\"\"\n",
    "        Estima p(x|ω) para cada muestra en X_val usando k-NN density.\n",
    "        \n",
    "        p(x|ω) = k / (N_ω * V_k(x))\n",
    "        donde V_k(x) es el volumen de la hiper-esfera de radio r_k(x)\n",
    "        (distancia al k-ésimo vecino más cercano).\n",
    "        \"\"\"\n",
    "        nn_model = self.nn_models[class_idx]\n",
    "        N_class = len(self.class_data[class_idx])\n",
    "        d = X_val.shape[1]  # dimensionalidad\n",
    "        \n",
    "        # Obtener distancias a los k vecinos más cercanos\n",
    "        distances, _ = nn_model.kneighbors(X_val)\n",
    "        \n",
    "        # La distancia al k-ésimo vecino más cercano define el radio\n",
    "        r_k = distances[:, -1]  # última columna = k-ésimo vecino\n",
    "        \n",
    "        # Volumen de hiper-esfera en d dimensiones: V_d(r) = π^(d/2) / Γ(d/2 + 1) * r^d\n",
    "        # Para simplificar usamos solo r^d (la constante π^(d/2)/Γ(d/2+1) se cancela en el ratio)\n",
    "        V_k = r_k ** d\n",
    "        \n",
    "        # Evitar divisiones por cero\n",
    "        V_k = np.maximum(V_k, 1e-10)\n",
    "        \n",
    "        # Densidad: k / (N_class * V_k)\n",
    "        density = self.k / (N_class * V_k)\n",
    "        \n",
    "        return density\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predice las clases usando la regla de Bayes.\"\"\"\n",
    "        X_val = X.values if hasattr(X, 'values') else X\n",
    "        n_samples = len(X_val)\n",
    "        \n",
    "        # Calcular p(x|ω) * P(ω) para cada clase\n",
    "        posteriors = np.zeros((n_samples, len(self.classes)))\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            likelihood = self._estimate_density(X_val, c)\n",
    "            posteriors[:, i] = likelihood * self.priors[c]\n",
    "        \n",
    "        # Normalizar (aunque no es necesario para argmax)\n",
    "        posteriors /= posteriors.sum(axis=1, keepdims=True) + 1e-10\n",
    "        \n",
    "        return np.argmax(posteriors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9b6c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.9524, F1-macro=0.8286\n",
      "  k=5: Accuracy=0.8571, F1-macro=0.6190\n",
      "  k=7: Accuracy=0.8571, F1-macro=0.6190\n",
      "  k=9: Accuracy=0.8571, F1-macro=0.6190\n",
      "  k=11: Accuracy=0.8571, F1-macro=0.6190\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.7143\n",
      "  k=3: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.5143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=9: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.5103\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.8500, F1-macro=0.6224\n",
      "  k=5: Accuracy=0.8500, F1-macro=0.6224\n",
      "  k=7: Accuracy=0.8500, F1-macro=0.6224\n",
      "  k=9: Accuracy=0.8500, F1-macro=0.6224\n",
      "  k=11: Accuracy=0.8500, F1-macro=0.6224\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.9000, F1-macro=0.7415\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=3: Accuracy=0.9000, F1-macro=0.7415\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=9: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.6056\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.8095\n",
      "  k=3: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=9: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.6202\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '1.0000', '0.9500']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '1.0000', '0.8095']\n",
      "  F1-macro: 0.9048 ± 0.1205\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['0.9524', '0.8000', '0.8500', '0.9000', '0.8000']\n",
      "  Accuracy: 0.8605 ± 0.0590\n",
      "  F1-macro por fold: ['0.8286', '0.5143', '0.6224', '0.7415', '0.6202']\n",
      "  F1-macro: 0.6654 ± 0.1088\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5103', '0.6224', '0.6056', '0.6202']\n",
      "  F1-macro: 0.5955 ± 0.0430\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=1\n",
      "  F1-macro: 0.9048 ± 0.1205\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Density Bayes (k=1)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '1.0000', '0.9500']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '1.0000', '0.8095']\n",
      "F1-macro promedio: 0.9048 ± 0.1205\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       0.80      0.80      0.80         5\n",
      "        fish       1.00      1.00      1.00        13\n",
      "   amphibian       0.75      0.75      0.75         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.94      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  4  0  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  1  0  3  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=9: Accuracy=0.8000, F1-macro=0.6095\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.6056\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.8095\n",
      "  k=3: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=9: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.6202\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '1.0000', '0.9500']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '1.0000', '0.8095']\n",
      "  F1-macro: 0.9048 ± 0.1205\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['0.9524', '0.8000', '0.8500', '0.9000', '0.8000']\n",
      "  Accuracy: 0.8605 ± 0.0590\n",
      "  F1-macro por fold: ['0.8286', '0.5143', '0.6224', '0.7415', '0.6202']\n",
      "  F1-macro: 0.6654 ± 0.1088\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5143', '0.6224', '0.6095', '0.6202']\n",
      "  F1-macro: 0.5971 ± 0.0416\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.8571', '0.8000', '0.8500', '0.8000', '0.8000']\n",
      "  Accuracy: 0.8214 ± 0.0263\n",
      "  F1-macro por fold: ['0.6190', '0.5103', '0.6224', '0.6056', '0.6202']\n",
      "  F1-macro: 0.5955 ± 0.0430\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=1\n",
      "  F1-macro: 0.9048 ± 0.1205\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Density Bayes (k=1)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '1.0000', '0.9500']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '1.0000', '0.8095']\n",
      "F1-macro promedio: 0.9048 ± 0.1205\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       0.80      0.80      0.80         5\n",
      "        fish       1.00      1.00      1.00        13\n",
      "   amphibian       0.75      0.75      0.75         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.94      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  4  0  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  1  0  3  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "params_knn_density = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "knn_d_results = {k: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "                 for k in params_knn_density}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for k in params_knn_density:\n",
    "        # Entrenar con este k\n",
    "        knn_density = KNNDensityBayes(k=k)\n",
    "        knn_density.fit(pd.DataFrame(X_train_val), y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(knn_density, pd.DataFrame(X_test_fold), y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        knn_d_results[k]['accuracies'].append(acc)\n",
    "        knn_d_results[k]['f1_scores'].append(f1)\n",
    "        knn_d_results[k]['all_preds'].extend(preds)\n",
    "        knn_d_results[k]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  k={k}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_k_density = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for k in params_knn_density:\n",
    "    acc_mean = np.mean(knn_d_results[k]['accuracies'])\n",
    "    acc_std = np.std(knn_d_results[k]['accuracies'])\n",
    "    f1_mean = np.mean(knn_d_results[k]['f1_scores'])\n",
    "    f1_std = np.std(knn_d_results[k]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in knn_d_results[k]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in knn_d_results[k]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_k_density = k\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: k={best_k_density}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(knn_d_results[best_k_density]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "knn_d_accuracies = knn_d_results[best_k_density]['accuracies']\n",
    "knn_d_f1_scores = knn_d_results[best_k_density]['f1_scores']\n",
    "knn_d_all_preds = knn_d_results[best_k_density]['all_preds']\n",
    "knn_d_all_true = knn_d_results[best_k_density]['all_true']\n",
    "\n",
    "knn_d_mean_acc, knn_d_mean_f1 = print_cv_results(f\"k-NN Density Bayes (k={best_k_density})\", \n",
    "                                                  knn_d_accuracies, knn_d_f1_scores,\n",
    "                                                  knn_d_all_preds, knn_d_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecd98e",
   "metadata": {},
   "source": [
    "## 10. Modelo 6: k-NN Rule (Directo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d29bdd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "6. K-NEAREST NEIGHBORS RULE (Directo)\n",
      "================================================================================\n",
      "Evaluando todos los hiperparámetros en cada fold...\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=3: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=5: Accuracy=0.9524, F1-macro=0.8286\n",
      "  k=7: Accuracy=0.9048, F1-macro=0.7619\n",
      "  k=9: Accuracy=0.8095, F1-macro=0.5163\n",
      "  k=11: Accuracy=0.8095, F1-macro=0.4877\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.7143\n",
      "  k=3: Accuracy=0.9500, F1-macro=0.7143\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.5415\n",
      "  k=7: Accuracy=0.8000, F1-macro=0.5143\n",
      "  k=9: Accuracy=0.8000, F1-macro=0.5903\n",
      "  k=11: Accuracy=0.8000, F1-macro=0.5903\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.9500, F1-macro=0.8367\n",
      "  k=5: Accuracy=0.9000, F1-macro=0.7415\n",
      "  k=7: Accuracy=0.8500, F1-macro=0.6224\n",
      "  k=9: Accuracy=0.8500, F1-macro=0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  k=11: Accuracy=0.8000, F1-macro=0.4712\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.8367\n",
      "  k=3: Accuracy=0.9500, F1-macro=0.8367\n",
      "  k=5: Accuracy=0.8500, F1-macro=0.7167\n",
      "  k=7: Accuracy=0.8500, F1-macro=0.7167\n",
      "  k=9: Accuracy=0.7500, F1-macro=0.5060\n",
      "  k=11: Accuracy=0.7500, F1-macro=0.5060\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.9000, F1-macro=0.7725\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=7: Accuracy=0.7500, F1-macro=0.4700\n",
      "  k=9: Accuracy=0.7500, F1-macro=0.4700\n",
      "  k=11: Accuracy=0.7500, F1-macro=0.4700\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '0.9500', '0.9500', '0.9000']\n",
      "  Accuracy: 0.9500 ± 0.0316\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '0.8367', '0.8367', '0.7725']\n",
      "  F1-macro: 0.8321 ± 0.0956\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.9524', '0.8000', '0.9000', '0.8500', '0.8000']\n",
      "  Accuracy: 0.8605 ± 0.0590\n",
      "  F1-macro por fold: ['0.8286', '0.5415', '0.7415', '0.7167', '0.6202']\n",
      "  F1-macro: 0.6897 ± 0.0995\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.9048', '0.8000', '0.8500', '0.8500', '0.7500']\n",
      "  Accuracy: 0.8310 ± 0.0523\n",
      "  F1-macro por fold: ['0.7619', '0.5143', '0.6224', '0.7167', '0.4700']\n",
      "  F1-macro: 0.6171 ± 0.1123\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8500', '0.7500', '0.7500']\n",
      "  Accuracy: 0.7919 ± 0.0381\n",
      "  F1-macro por fold: ['0.5163', '0.5903', '0.6224', '0.5060', '0.4700']\n",
      "  F1-macro: 0.5410 ± 0.0565\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8000', '0.7500', '0.7500']\n",
      "  Accuracy: 0.7819 ± 0.0263\n",
      "  F1-macro por fold: ['0.4877', '0.5903', '0.4712', '0.5060', '0.4700']\n",
      "  F1-macro: 0.5050 ± 0.0446\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=1\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Rule (k=1)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "F1-macro promedio: 0.9102 ± 0.1166\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       1.00      0.60      0.75         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       0.80      1.00      0.89         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.96      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  3  1  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n",
      "  k=1: Accuracy=0.9500, F1-macro=0.8367\n",
      "  k=3: Accuracy=0.9500, F1-macro=0.8367\n",
      "  k=5: Accuracy=0.8500, F1-macro=0.7167\n",
      "  k=7: Accuracy=0.8500, F1-macro=0.7167\n",
      "  k=9: Accuracy=0.7500, F1-macro=0.5060\n",
      "  k=11: Accuracy=0.7500, F1-macro=0.5060\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "  k=1: Accuracy=1.0000, F1-macro=1.0000\n",
      "  k=3: Accuracy=0.9000, F1-macro=0.7725\n",
      "  k=5: Accuracy=0.8000, F1-macro=0.6202\n",
      "  k=7: Accuracy=0.7500, F1-macro=0.4700\n",
      "  k=9: Accuracy=0.7500, F1-macro=0.4700\n",
      "  k=11: Accuracy=0.7500, F1-macro=0.4700\n",
      "\n",
      "================================================================================\n",
      "RESUMEN POR HIPERPARÁMETRO:\n",
      "================================================================================\n",
      "\n",
      "k=1:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "  Accuracy: 0.9800 ± 0.0245\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "\n",
      "k=3:\n",
      "  Accuracy por fold: ['1.0000', '0.9500', '0.9500', '0.9500', '0.9000']\n",
      "  Accuracy: 0.9500 ± 0.0316\n",
      "  F1-macro por fold: ['1.0000', '0.7143', '0.8367', '0.8367', '0.7725']\n",
      "  F1-macro: 0.8321 ± 0.0956\n",
      "\n",
      "k=5:\n",
      "  Accuracy por fold: ['0.9524', '0.8000', '0.9000', '0.8500', '0.8000']\n",
      "  Accuracy: 0.8605 ± 0.0590\n",
      "  F1-macro por fold: ['0.8286', '0.5415', '0.7415', '0.7167', '0.6202']\n",
      "  F1-macro: 0.6897 ± 0.0995\n",
      "\n",
      "k=7:\n",
      "  Accuracy por fold: ['0.9048', '0.8000', '0.8500', '0.8500', '0.7500']\n",
      "  Accuracy: 0.8310 ± 0.0523\n",
      "  F1-macro por fold: ['0.7619', '0.5143', '0.6224', '0.7167', '0.4700']\n",
      "  F1-macro: 0.6171 ± 0.1123\n",
      "\n",
      "k=9:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8500', '0.7500', '0.7500']\n",
      "  Accuracy: 0.7919 ± 0.0381\n",
      "  F1-macro por fold: ['0.5163', '0.5903', '0.6224', '0.5060', '0.4700']\n",
      "  F1-macro: 0.5410 ± 0.0565\n",
      "\n",
      "k=11:\n",
      "  Accuracy por fold: ['0.8095', '0.8000', '0.8000', '0.7500', '0.7500']\n",
      "  Accuracy: 0.7819 ± 0.0263\n",
      "  F1-macro por fold: ['0.4877', '0.5903', '0.4712', '0.5060', '0.4700']\n",
      "  F1-macro: 0.5050 ± 0.0446\n",
      "\n",
      "================================================================================\n",
      "✓ MEJOR HIPERPARÁMETRO: k=1\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS CV: k-NN Rule (k=1)\n",
      "================================================================================\n",
      "\n",
      "Accuracy por fold: ['1.0000', '0.9500', '1.0000', '0.9500', '1.0000']\n",
      "Accuracy promedio: 0.9800 ± 0.0245\n",
      "\n",
      "F1-macro por fold: ['1.0000', '0.7143', '1.0000', '0.8367', '1.0000']\n",
      "F1-macro promedio: 0.9102 ± 0.1166\n",
      "\n",
      "--- Reporte de clasificación global (todos los folds) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      mammal       1.00      1.00      1.00        41\n",
      "        bird       1.00      1.00      1.00        20\n",
      "     reptile       1.00      0.60      0.75         5\n",
      "        fish       0.93      1.00      0.96        13\n",
      "   amphibian       0.80      1.00      0.89         4\n",
      "invertebrate       1.00      1.00      1.00         8\n",
      "      insect       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.96      0.94      0.94       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "\n",
      "Matriz de confusión global:\n",
      "[[41  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0  3  1  1  0  0]\n",
      " [ 0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"6. K-NEAREST NEIGHBORS RULE (Directo)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "params_knn = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Matriz para almacenar resultados: [hiperparámetro][fold] = (acc, f1, preds)\n",
    "knn_results = {k: {'accuracies': [], 'f1_scores': [], 'all_preds': [], 'all_true': []} \n",
    "               for k in params_knn}\n",
    "\n",
    "print(\"Evaluando todos los hiperparámetros en cada fold...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Para cada fold, evaluar todos los hiperparámetros\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n--- Fold {fold}/5 ---\")\n",
    "    \n",
    "    # Dividir en train+val y test\n",
    "    X_train_val, X_test_fold = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test_fold = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    # Evaluar cada hiperparámetro en este fold\n",
    "    for k in params_knn:\n",
    "        # Entrenar con este k\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "        knn.fit(X_train_val, y_train_val)\n",
    "        \n",
    "        # Evaluar en test del fold\n",
    "        acc, f1, cm, preds = evaluate_fold(knn, X_test_fold, y_test_fold, fold)\n",
    "        \n",
    "        # Guardar resultados para este hiperparámetro y fold\n",
    "        knn_results[k]['accuracies'].append(acc)\n",
    "        knn_results[k]['f1_scores'].append(f1)\n",
    "        knn_results[k]['all_preds'].extend(preds)\n",
    "        knn_results[k]['all_true'].extend(y_test_fold)\n",
    "        \n",
    "        print(f\"  k={k}: Accuracy={acc:.4f}, F1-macro={f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN POR HIPERPARÁMETRO:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedios y encontrar el mejor\n",
    "best_k_knn = None\n",
    "best_f1_mean = -np.inf\n",
    "\n",
    "for k in params_knn:\n",
    "    acc_mean = np.mean(knn_results[k]['accuracies'])\n",
    "    acc_std = np.std(knn_results[k]['accuracies'])\n",
    "    f1_mean = np.mean(knn_results[k]['f1_scores'])\n",
    "    f1_std = np.std(knn_results[k]['f1_scores'])\n",
    "    \n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Accuracy por fold: {[f'{a:.4f}' for a in knn_results[k]['accuracies']]}\")\n",
    "    print(f\"  Accuracy: {acc_mean:.4f} ± {acc_std:.4f}\")\n",
    "    print(f\"  F1-macro por fold: {[f'{f:.4f}' for f in knn_results[k]['f1_scores']]}\")\n",
    "    print(f\"  F1-macro: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    if f1_mean > best_f1_mean:\n",
    "        best_f1_mean = f1_mean\n",
    "        best_k_knn = k\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ MEJOR HIPERPARÁMETRO: k={best_k_knn}\")\n",
    "print(f\"  F1-macro: {best_f1_mean:.4f} ± {np.std(knn_results[best_k_knn]['f1_scores']):.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Usar los resultados del mejor hiperparámetro para el reporte final\n",
    "knn_accuracies = knn_results[best_k_knn]['accuracies']\n",
    "knn_f1_scores = knn_results[best_k_knn]['f1_scores']\n",
    "knn_all_preds = knn_results[best_k_knn]['all_preds']\n",
    "knn_all_true = knn_results[best_k_knn]['all_true']\n",
    "\n",
    "knn_mean_acc, knn_mean_f1 = print_cv_results(f\"k-NN Rule (k={best_k_knn})\", \n",
    "                                              knn_accuracies, knn_f1_scores,\n",
    "                                              knn_all_preds, knn_all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505fd08",
   "metadata": {},
   "source": [
    "## 11. Comparación final de todos los modelos\n",
    "\n",
    "Resultados de validación cruzada 5-fold sobre todo el conjunto de datos. Cada modelo se evaluó en 5 tests diferentes (uno por fold), y se reportan las métricas promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "230c2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARACIÓN FINAL DE MODELOS - CROSS VALIDATION 5-FOLD\n",
      "================================================================================\n",
      "\n",
      "Modelo                          Accuracy (mean±std)       F1-macro (mean±std)\n",
      "--------------------------------------------------------------------------------\n",
      "Naive Bayes                         0.9600 ± 0.0583           0.8990 ± 0.1360\n",
      "MLE Full                            0.8114 ± 0.0390           0.5840 ± 0.0540\n",
      "Histogram Bayes                     0.4552 ± 0.0558           0.1731 ± 0.0955\n",
      "Parzen Windows                      0.9800 ± 0.0245           0.9102 ± 0.1166\n",
      "k-NN Density Bayes                  0.9800 ± 0.0245           0.9048 ± 0.1205\n",
      "k-NN Rule                           0.9800 ± 0.0245           0.9102 ± 0.1166\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Mejor modelo (por F1-macro promedio): Parzen Windows\n",
      "  F1-macro: 0.9102 ± 0.1166\n",
      "\n",
      "================================================================================\n",
      "✓ Análisis completo finalizado con Cross-Validation 5-fold\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACIÓN FINAL DE MODELOS - CROSS VALIDATION 5-FOLD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compilar todos los resultados\n",
    "results = {\n",
    "    'Naive Bayes': {\n",
    "        'acc_mean': np.mean(nb_accuracies),\n",
    "        'acc_std': np.std(nb_accuracies),\n",
    "        'f1_mean': np.mean(nb_f1_scores),\n",
    "        'f1_std': np.std(nb_f1_scores)\n",
    "    },\n",
    "    'MLE Full': {\n",
    "        'acc_mean': np.mean(mle_accuracies),\n",
    "        'acc_std': np.std(mle_accuracies),\n",
    "        'f1_mean': np.mean(mle_f1_scores),\n",
    "        'f1_std': np.std(mle_f1_scores)\n",
    "    },\n",
    "    'Histogram Bayes': {\n",
    "        'acc_mean': np.mean(hist_accuracies),\n",
    "        'acc_std': np.std(hist_accuracies),\n",
    "        'f1_mean': np.mean(hist_f1_scores),\n",
    "        'f1_std': np.std(hist_f1_scores)\n",
    "    },\n",
    "    'Parzen Windows': {\n",
    "        'acc_mean': np.mean(parzen_accuracies),\n",
    "        'acc_std': np.std(parzen_accuracies),\n",
    "        'f1_mean': np.mean(parzen_f1_scores),\n",
    "        'f1_std': np.std(parzen_f1_scores)\n",
    "    },\n",
    "    'k-NN Density Bayes': {\n",
    "        'acc_mean': np.mean(knn_d_accuracies),\n",
    "        'acc_std': np.std(knn_d_accuracies),\n",
    "        'f1_mean': np.mean(knn_d_f1_scores),\n",
    "        'f1_std': np.std(knn_d_f1_scores)\n",
    "    },\n",
    "    'k-NN Rule': {\n",
    "        'acc_mean': np.mean(knn_accuracies),\n",
    "        'acc_std': np.std(knn_accuracies),\n",
    "        'f1_mean': np.mean(knn_f1_scores),\n",
    "        'f1_std': np.std(knn_f1_scores)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Modelo':<25} {'Accuracy (mean±std)':>25} {'F1-macro (mean±std)':>25}\")\n",
    "print(\"-\" * 80)\n",
    "for model, metrics in results.items():\n",
    "    acc_str = f\"{metrics['acc_mean']:.4f} ± {metrics['acc_std']:.4f}\"\n",
    "    f1_str = f\"{metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\"\n",
    "    print(f\"{model:<25} {acc_str:>25} {f1_str:>25}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Mejor modelo por F1-macro (prioridad para multiclass)\n",
    "best_model = max(results, key=lambda k: results[k]['f1_mean'])\n",
    "print(f\"\\n✓ Mejor modelo (por F1-macro promedio): {best_model}\")\n",
    "print(f\"  F1-macro: {results[best_model]['f1_mean']:.4f} ± {results[best_model]['f1_std']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Análisis completo finalizado con Cross-Validation 5-fold\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
