# Fundamentos del Aprendizaje Automático

**November 24, 2025**  
**Assignment 3**  
**Fundamentos del Aprendizaje Automático**  
**Curso 2025-2026**

Esta tercera práctica del curso tiene como objetivo ampliar y aclarar los conceptos introducidos durante todo el curso, principalmente de T3 a T7. Deberás seguir este guion para desarrollar los programas y experimentos requeridos, y finalmente entregar un informe resumiendo las principales ideas y conclusiones obtenidas.

## Objetivos

- Entender mejor la metodología de evaluación de métodos de aprendizaje automático mediante la introducción de pruebas de hipótesis.
- Aplicar técnicas de reducción de dimensionalidad para eliminar redundancias en los conjuntos de datos.
- Implementar esquemas neuronales básicos.
- Explicar y justificar las razones detrás de las decisiones tomadas.
- Aprender a reportar resultados e ideas de forma científica.

## Tareas

### T1. Dataset

Considerando el conjunto de datos inicial desarrollado para la Asignación 2, obtén dos versiones alternativas:

1. Una versión reducida con PCA con, al menos, el 60% de la Varianza Acumulada. Para esto puedes usar el método PCA de la colección `decomposition` en la librería sklearn.
2. Una versión reducida con un Autoencoder neuronal que obtenga la mitad del número inicial de características. Para esto puedes usar el método `MLPRegressor` de la colección `neuralnetwork` en la librería sklearn. Nota que, aunque estas arquitecturas contienen varios parámetros para optimizar, enfócate exclusivamente en estos tres:
   - `hiddenlayersizes`: Número de neuronas por capa oculta.
   - `activation`: Activación usada en la capa oculta.
   - `maxiter`: Número máximo de iteraciones de entrenamiento.

### T2. Recolección de datos

Comparte con tus compañeros las tres versiones (original, PCA y Autoencoder) del conjunto de datos que hayas preparado en T1. Deberás obtener, al menos, cuatro conjuntos adicionales de tus compañeros para completar el resto de la asignación.

### T3. Clasificadores

Considerarás dos clasificadores para esta asignación:

1. Clasificador k-Vecinos Cercanos (kNN) presentado en T4. Para la optimización del clasificador, enfócate exclusivamente en el parámetro `k`.
2. Perceptrón Multicapa (MLP), un modelo neuronal como el presentado en T5. Para esto puedes usar el método `MLPClassifier` de la colección `neuralnetwork` en sklearn. Para la optimización del modelo, enfócate en los tres parámetros estudiados para el Autoencoder: `hiddenlayersizes`, `activation` y `maxiter`.

**Nota:** Para el proceso de optimización, deberás considerar el mismo enfoque que en la Asignación 2: considerando un esquema de validación cruzada, obtén tres particiones de datos disjuntas (entrenamiento, validación y prueba) para usar las dos primeras para optimizar el modelo y la última para reportar el rendimiento del clasificador.

### T4. Resultados

Mantén los resultados obtenidos para cada combinación de conjunto de datos, clasificador y partición de validación cruzada para la etapa final de Análisis. Además, proporciona las puntuaciones de rendimiento agregadas en términos de los indicadores de media y desviación estándar para cada combinación de conjunto de datos y clasificador.

### T5. Análisis

Debes considerar los métodos presentados en el último módulo del curso. Dado que estos conceptos aún no han sido introducidos, los detalles precisos se proporcionarán en la próxima versión de la asignación.

## Formato del informe

- Debe usar la plantilla ICML.
- Debe indicar claramente la asignación, tu nombre y detalles de identificación (ID y correo electrónico).
- El informe debe tener un máximo de 3 páginas, en doble columna.
- Las preguntas del informe se definirán en la próxima versión de la asignación.

## Entrega

- Envía un solo archivo ZIP por Moodle.
- Debe incluir el informe y puede incluir el código desarrollado.
- Fecha de entrega: 23 de diciembre de 2025.

## Consejos y sugerencias

- La calidad del código no es un requisito, pero sí las conclusiones obtenidas.
- Un Jupyter Notebook o similar puede ser adecuado para la tarea.