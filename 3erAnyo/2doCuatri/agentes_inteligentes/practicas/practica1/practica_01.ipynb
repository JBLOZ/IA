{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0de109",
   "metadata": {},
   "source": [
    "# Práctica 1: Experimentación con Graph Neural Networks\n",
    "\n",
    "**Autor:** Jordi Blasco Lozano  \n",
    "**Universidad:** Universidad de Alicante  \n",
    "**Curso:** Agentes Inteligentes  \n",
    "\n",
    "## Objetivos de la Práctica\n",
    "\n",
    "1. Crear un dataset sintético custom con estructura de grafos\n",
    "2. Implementar y comparar MLPs vs GCNs para clasificación de nodos\n",
    "3. Realizar experimentación sistemática con hiperparámetros\n",
    "4. Analizar rendimiento en datasets benchmark (Cora y Citeseer)\n",
    "5. Comprender el impacto de la estructura del grafo en el aprendizaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb437fc",
   "metadata": {},
   "source": [
    "## 0. Configuración e Imports\n",
    "\n",
    "Instalación de dependencias y configuración del entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9110530c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Planetoid\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"✓ Setup completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aac05a",
   "metadata": {},
   "source": [
    "## 1. Ejercicio 1: Dataset Sintético Custom\n",
    "\n",
    "### 1.1 Generación del Grafo con Stochastic Block Model\n",
    "\n",
    "**Decisión de Diseño:**  \n",
    "- **Método**: Stochastic Block Model (SBM)\n",
    "- **Justificación**: Genera grafos con estructura de comunidades clara, ideal para demostrar el poder de GNNs\n",
    "- **Nodos**: 2000 (escala suficiente para experimentación)\n",
    "- **Clases**: 4 (balance entre complejidad y claridad)\n",
    "- **Probabilidades**: p_intra=0.02, p_inter=0.002 (ratio 10:1 para comunidades distinguibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8368d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del dataset custom\n",
    "num_nodes = 2000\n",
    "num_classes = 4\n",
    "nodes_per_class = num_nodes // num_classes\n",
    "feature_dim = 32\n",
    "\n",
    "# Crear grafo con estructura de comunidades\n",
    "sizes = [nodes_per_class] * num_classes\n",
    "p_intra = 0.02   # Probabilidad de arista dentro de la misma comunidad\n",
    "p_inter = 0.002  # Probabilidad de arista entre comunidades diferentes\n",
    "probs = np.full((num_classes, num_classes), p_inter)\n",
    "np.fill_diagonal(probs, p_intra)\n",
    "\n",
    "G = nx.stochastic_block_model(sizes, probs, seed=42)\n",
    "\n",
    "print(f\"Número de nodos: {G.number_of_nodes()}\")\n",
    "print(f\"Número de aristas: {G.number_of_edges()}\")\n",
    "print(f\"Densidad del grafo: {nx.density(G):.6f}\")\n",
    "print(f\"Promedio de grado: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298ba9f",
   "metadata": {},
   "source": [
    "### 1.2 Creación de Características con Señal Débil + Ruido Fuerte\n",
    "\n",
    "**Decisión Clave**: Crear features que tengan POCA correlación con las labels.  \n",
    "Esto fuerza a los modelos a depender de la estructura del grafo para clasificar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar labels basados en la estructura de bloques\n",
    "node_labels = np.array([i // nodes_per_class for i in range(num_nodes)])\n",
    "\n",
    "# Crear centros de clase con magnitud PEQUEÑA\n",
    "class_centers = np.random.randn(num_classes, feature_dim) * 0.3\n",
    "\n",
    "# Generar características: señal débil + ruido fuerte\n",
    "node_features = np.zeros((num_nodes, feature_dim))\n",
    "for i in range(num_nodes):\n",
    "    label = node_labels[i]\n",
    "    noise = np.random.randn(feature_dim) * 1.0        # Ruido FUERTE\n",
    "    weak_signal = class_centers[label] * 0.2          # Señal DÉBIL\n",
    "    node_features[i] = weak_signal + noise\n",
    "\n",
    "print(f\"Shape de características: {node_features.shape}\")\n",
    "print(f\"Estadísticas - Media: {node_features.mean():.3f}, Std: {node_features.std():.3f}\")\n",
    "print(f\"\\nDistribución de labels:\")\n",
    "unique, counts = np.unique(node_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Clase {label}: {count} nodos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29491d3",
   "metadata": {},
   "source": [
    "### 1.3 Conversión a Formato PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a tensors de PyTorch\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "y = torch.tensor(node_labels, dtype=torch.long)\n",
    "\n",
    "# Convertir edge list a formato COO\n",
    "edge_list = list(G.edges())\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Para grafos no dirigidos, añadir aristas en ambas direcciones\n",
    "edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "# Crear objeto Data de PyG\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "print(f\"Número de nodos: {data.num_nodes}\")\n",
    "print(f\"Número de aristas: {data.num_edges}\")\n",
    "print(f\"Número de features por nodo: {data.num_node_features}\")\n",
    "print(f\"Tiene nodos aislados: {data.has_isolated_nodes()}\")\n",
    "print(f\"Tiene self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Es no dirigido: {data.is_undirected()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdbc60e",
   "metadata": {},
   "source": [
    "### 1.4 Creación de 10 Splits Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc490217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(num_nodes, num_classes, train_ratio=0.6, val_ratio=0.2, seed=0):\n",
    "    \"\"\"Crear máscaras de train/val/test para clasificación de nodos.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_nodes)\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    val_size = int(num_nodes * val_ratio)\n",
    "    \n",
    "    train_idx = indices[:train_size]\n",
    "    val_idx = indices[train_size:train_size + val_size]\n",
    "    test_idx = indices[train_size + val_size:]\n",
    "    \n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    \n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "# Crear 10 splits para evaluación robusta\n",
    "num_runs = 10\n",
    "all_masks = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    train_mask, val_mask, test_mask = create_masks(data.num_nodes, num_classes, seed=run)\n",
    "    all_masks.append({'train': train_mask, 'val': val_mask, 'test': test_mask})\n",
    "\n",
    "print(f\"Creados {num_runs} splits diferentes\")\n",
    "print(f\"Ejemplo split 0:\")\n",
    "print(f\"  Train: {all_masks[0]['train'].sum().item()} nodos\")\n",
    "print(f\"  Val: {all_masks[0]['val'].sum().item()} nodos\")\n",
    "print(f\"  Test: {all_masks[0]['test'].sum().item()} nodos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5aec50",
   "metadata": {},
   "source": [
    "### 1.5 Visualización del Grafo Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar subsample del grafo\n",
    "sample_size = 500\n",
    "G_sample = G.subgraph(list(range(sample_size)))\n",
    "colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3']\n",
    "node_colors_viz = [colors[node_labels[i]] for i in range(sample_size)]\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "pos = nx.spring_layout(G_sample, seed=42, k=0.5, iterations=50)\n",
    "nx.draw(G_sample, pos, node_color=node_colors_viz, node_size=40,\n",
    "        edge_color='gray', alpha=0.7, width=0.4)\n",
    "\n",
    "# Añadir leyenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=colors[i], label=f'Clase {i}') for i in range(num_classes)]\n",
    "plt.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "plt.title(\"Grafo Sintético Custom (500 nodos de muestra)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/custom_graph_structure.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Grafo visualizado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14c055",
   "metadata": {},
   "source": [
    "## 2. Implementación de Modelos\n",
    "\n",
    "### 2.1 MLP Baseline (Ignora Estructura del Grafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1857cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron para clasificación de nodos.\n",
    "    Este modelo ignora completamente la estructura del grafo.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "mlp_test = MLP(data.num_node_features, 64, num_classes)\n",
    "print(mlp_test)\n",
    "print(f\"\\nNúmero de parámetros: {sum(p.numel() for p in mlp_test.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f50f1",
   "metadata": {},
   "source": [
    "### 2.2 GCN (Usa Paso de Mensajes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"Graph Convolutional Network para clasificación de nodos.\n",
    "    Utiliza la estructura del grafo mediante message passing.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "gcn_test = GCN(data.num_node_features, 64, num_classes)\n",
    "print(gcn_test)\n",
    "print(f\"\\nNúmero de parámetros: {sum(p.numel() for p in gcn_test.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ad0f8",
   "metadata": {},
   "source": [
    "### 2.3 Funciones de Entrenamiento y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data, optimizer, criterion, train_mask):\n",
    "    \"\"\"Entrenar el modelo por una época.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if isinstance(model, MLP):\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index)\n",
    "    \n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, mask):\n",
    "    \"\"\"Evaluar el modelo.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(model, MLP):\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index)\n",
    "    \n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[mask] == data.y[mask]).sum().item()\n",
    "    return correct / mask.sum().item()\n",
    "\n",
    "def run_experiment(model, data, masks, num_epochs=200, lr=0.01, weight_decay=5e-4, verbose=False):\n",
    "    \"\"\"Ejecutar experimento completo.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_mask, val_mask, test_mask = masks['train'], masks['val'], masks['test']\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_acc': [], 'test_acc': []}\n",
    "    best_val_acc, best_test_acc = 0, 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_epoch(model, data, optimizer, criterion, train_mask)\n",
    "        train_acc = evaluate(model, data, train_mask)\n",
    "        val_acc = evaluate(model, data, val_mask)\n",
    "        test_acc = evaluate(model, data, test_mask)\n",
    "        \n",
    "        history['train_loss'].append(loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "        \n",
    "        if verbose and (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss: {loss:.4f} | Train: {train_acc:.4f} | Val: {val_acc:.4f} | Test: {test_acc:.4f}\")\n",
    "    \n",
    "    return {'history': history, 'best_val_acc': best_val_acc, 'best_test_acc': best_test_acc}\n",
    "\n",
    "print(\"✓ Funciones de entrenamiento definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf56b5",
   "metadata": {},
   "source": [
    "## 3. Experimentos Base en Dataset Custom\n",
    "\n",
    "### 3.1 Experimento con Configuración Base\n",
    "\n",
    "**Hiperparámetros base:**\n",
    "- Hidden channels: 64\n",
    "- Learning rate: 0.01\n",
    "- Dropout: 0.5\n",
    "- Weight decay: 5e-4\n",
    "- Optimizer: Adam\n",
    "- Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca630db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración base\n",
    "base_config = {\n",
    "    'hidden_channels': 64,\n",
    "    'lr': 0.01,\n",
    "    'dropout': 0.5,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 200\n",
    "}\n",
    "\n",
    "# Almacenar resultados\n",
    "mlp_base_results = []\n",
    "gcn_base_results = []\n",
    "\n",
    "print(\"Ejecutando experimentos base en 10 splits...\")\n",
    "for run in tqdm(range(num_runs), desc=\"Runs\"):\n",
    "    # MLP\n",
    "    mlp = MLP(data.num_node_features, base_config['hidden_channels'], num_classes, base_config['dropout'])\n",
    "    mlp_result = run_experiment(mlp, data, all_masks[run], \n",
    "                                base_config['num_epochs'], base_config['lr'], base_config['weight_decay'])\n",
    "    mlp_base_results.append(mlp_result)\n",
    "    \n",
    "    # GCN\n",
    "    gcn = GCN(data.num_node_features, base_config['hidden_channels'], num_classes, base_config['dropout'])\n",
    "    gcn_result = run_experiment(gcn, data, all_masks[run],\n",
    "                                base_config['num_epochs'], base_config['lr'], base_config['weight_decay'])\n",
    "    gcn_base_results.append(gcn_result)\n",
    "\n",
    "# Estadísticas\n",
    "mlp_accs = [r['best_test_acc'] for r in mlp_base_results]\n",
    "gcn_accs = [r['best_test_acc'] for r in gcn_base_results]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTADOS BASE (Test Accuracy)\")\n",
    "print('='*60)\n",
    "print(f\"MLP: {np.mean(mlp_accs):.4f} ± {np.std(mlp_accs):.4f}\")\n",
    "print(f\"GCN: {np.mean(gcn_accs):.4f} ± {np.std(gcn_accs):.4f}\")\n",
    "print(f\"Mejora GCN sobre MLP: {(np.mean(gcn_accs) - np.mean(mlp_accs)):.4f} ({((np.mean(gcn_accs) / np.mean(mlp_accs)) - 1) * 100:.1f}%)\")\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40506a",
   "metadata": {},
   "source": [
    "### 3.2 Visualización de Curvas de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas del primer run\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "mlp_hist = mlp_base_results[0]['history']\n",
    "gcn_hist = gcn_base_results[0]['history']\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(mlp_hist['train_loss'], label='MLP', alpha=0.8, linewidth=2)\n",
    "axes[0].plot(gcn_hist['train_loss'], label='GCN', alpha=0.8, linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Train Accuracy\n",
    "axes[1].plot(mlp_hist['train_acc'], label='MLP', alpha=0.8, linewidth=2)\n",
    "axes[1].plot(gcn_hist['train_acc'], label='GCN', alpha=0.8, linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Accuracy\n",
    "axes[2].plot(mlp_hist['val_acc'], label='MLP', alpha=0.8, linewidth=2)\n",
    "axes[2].plot(gcn_hist['val_acc'], label='GCN', alpha=0.8, linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[2].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/custom_base_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Curvas guardadas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
