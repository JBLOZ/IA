{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38208a63",
   "metadata": {},
   "source": [
    "# practica_01_jordi_blasco_lozano  \n",
    "February 16, 2026\n",
    "\n",
    "## 1 Práctica 1 — Maximum Clique (Clique Problem)\n",
    "\n",
    "**Autor:** Jordi Blasco Lozano\n",
    "\n",
    "### 1.0.1 Índice\n",
    "\n",
    "1. Resumen e introducción  \n",
    "2. Implementación (funciones y clases auxiliares)  \n",
    "3. Ejercicio 1 — Baseline exacto: Brute Force  \n",
    "4. Ejercicio 2 — Relajación continua: Motzkin–Straus  \n",
    "5. Ejercicio 3 — Replicator Dynamics (RD) + Decoder  \n",
    "6. Comparativa final (tablas + visualizaciones)  \n",
    "7. Discusión y conclusiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff574c6c",
   "metadata": {},
   "source": [
    "## 1.1 Resumen\n",
    "\n",
    "Este notebook resuelve la Práctica 1 (Maximum Clique) siguiendo un pipeline incremental:\n",
    "\n",
    "1. **Brute force** para obtener *ground truth* en grafos pequeños (baseline exacto).  \n",
    "2. **Motzkin–Straus** para entender cómo el problema discreto se relaja a una optimización continua sobre el simplex.  \n",
    "3. **Replicator Dynamics (RD)** (formulación de Pelillo) para resolver la relajación continua de forma iterativa, y un **decoder greedy** para recuperar una clique discreta.  \n",
    "4. Experimentos en **IMDB-BINARY** y **COLLAB** (TU Dortmund vía PyG): tamaño medio de clique, tiempo de cómputo y, cuando es posible, comparación contra brute force.\n",
    "\n",
    "La idea clave es que, aunque Maximum Clique es NP-hard, la relajación continua + RD suele encontrar cliques grandes de manera eficiente, especialmente cuando el grafo tiene estructura densa local.\n",
    "\n",
    "## 1.2 1. Introducción\n",
    "\n",
    "Una **clique** en un grafo no dirigido es un conjunto de nodos tal que **toda pareja** de nodos está conectada por una arista. La **maximum clique** es la de mayor tamaño.\n",
    "\n",
    "Brute force es la forma más directa de resolverlo (enumerar subconjuntos), pero explota en tiempo exponencial. La parte interesante de esta práctica es que, gracias al teorema de **Motzkin–Straus**, podemos transformar el problema en uno continuo: maximizar una forma cuadrática en el **simplex**. A partir de ahí, **Replicator Dynamics** proporciona un algoritmo multiplicativo que respeta las restricciones del simplex y mejora la función objetivo de manera monótona.\n",
    "\n",
    "A lo largo del notebook mantengo el mismo criterio que en la Práctica 00: agrupar en una sección de “Implementación” todas las funciones auxiliares para dejar los ejercicios limpios y centrados en el análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac367c0f",
   "metadata": {},
   "source": [
    "## 1.3 2. Implementación: funciones y clases auxiliares\n",
    "\n",
    "En este bloque agrupo los imports, funciones de ayuda (conversión a matriz de adyacencia, chequeo de cliques, evaluadores) y un pequeño “runner” para mantener el notebook limpio.  \n",
    "La idea es la misma que en la Práctica 00: en los ejercicios únicamente llamo a estas funciones, evitando repetir código y facilitando la lectura de la entrega.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4e6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "PyTorch version: 2.0.1\n",
      "CUDA available: False\n",
      "Using device: cpu\n",
      "Setup completado\n"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Crear carpeta de salida para figuras (evita errores al guardar plots)\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# (Opcional) PyTorch / PyG: solo necesario para cargar datasets TU Dortmund con PyG\n",
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Definir dispositivo (por consistencia con la Práctica 00; aquí lo usamos solo si ampliamos)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Setup completado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8a4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyg_to_adjacency(data, make_undirected=True, dtype=float):\n",
    "    \"\"\"\n",
    "    Convierte un PyG Data (grafo) a matriz de adyacencia numpy.\n",
    "\n",
    "    Args:\n",
    "        data: PyG Data\n",
    "        make_undirected: si True, fuerza grafo no dirigido\n",
    "        dtype: dtype de la matriz devuelta\n",
    "\n",
    "    Returns:\n",
    "        A: np.ndarray (n, n) con entradas 0/1 (diagonal 0)\n",
    "        G: networkx.Graph equivalente\n",
    "    \"\"\"\n",
    "    G = to_networkx(data, to_undirected=make_undirected)\n",
    "    # Asegurar que los nodos estén etiquetados 0..n-1 (PyG suele cumplirlo)\n",
    "    A = nx.to_numpy_array(G, dtype=dtype)\n",
    "    # Por claridad, anulamos diagonal (no usamos self-loops en esta práctica)\n",
    "    np.fill_diagonal(A, 0.0)\n",
    "    return A, G\n",
    "\n",
    "\n",
    "def is_clique(nodes, A):\n",
    "    \"\"\"\n",
    "    Check if a set of nodes forms a clique.\n",
    "\n",
    "    Args:\n",
    "        nodes: list of node indices\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        bool: True if nodes form a clique, False otherwise\n",
    "    \"\"\"\n",
    "    nodes = list(nodes)\n",
    "    if len(nodes) <= 1:\n",
    "        return True\n",
    "\n",
    "    # Verificar que toda pareja esté conectada\n",
    "    for i, j in combinations(nodes, 2):\n",
    "        if A[i, j] == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def brute_force_max_clique(A):\n",
    "    \"\"\"\n",
    "    Find the maximum clique by brute force enumeration.\n",
    "\n",
    "    Args:\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        list: nodes forming the maximum clique\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    # Recorremos tamaños de clique de mayor a menor; primera válida => máxima\n",
    "    for k in range(n, 0, -1):\n",
    "        for subset in combinations(range(n), k):\n",
    "            if is_clique(subset, A):\n",
    "                return list(subset)\n",
    "    return []\n",
    "\n",
    "\n",
    "def motzkin_straus_objective(x, A):\n",
    "    \"\"\"\n",
    "    Compute the Motzkin-Straus objective f(x) = x^T A x\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (n,) - point in the simplex\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        float: objective value\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float).reshape(-1)\n",
    "    return float(x @ A @ x)\n",
    "\n",
    "\n",
    "def regularized_objective(x, A):\n",
    "    \"\"\"\n",
    "    Compute the regularized objective f_hat(x) = x^T (A + 0.5*I) x\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (n,) - point in the simplex\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        float: regularized objective value\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float).reshape(-1)\n",
    "    n = A.shape[0]\n",
    "    A_reg = A + 0.5 * np.eye(n, dtype=float)\n",
    "    return float(x @ A_reg @ x)\n",
    "\n",
    "\n",
    "def replicator_dynamics(A, max_iter=1000, tol=1e-12, use_regularization=True):\n",
    "    \"\"\"\n",
    "    Run Replicator Dynamics to find the maximum clique.\n",
    "\n",
    "    This follows the formulation from Pelillo et al.:\n",
    "        x_new = x * (A @ x)\n",
    "        x_new = x_new / x_new.sum()\n",
    "\n",
    "    Args:\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "        max_iter: int - maximum number of iterations\n",
    "        tol: float - convergence tolerance (L1 change)\n",
    "        use_regularization: bool - whether to use A + 0.5*I\n",
    "\n",
    "    Returns:\n",
    "        x: numpy array of shape (n,) - final simplex point\n",
    "        history: dict with 'objectives' and 'iterations'\n",
    "    \"\"\"\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Regularización para evitar soluciones espurias (caso 'cherry', etc.)\n",
    "    if use_regularization:\n",
    "        A_reg = A + 0.5 * np.eye(n, dtype=float)\n",
    "    else:\n",
    "        A_reg = A.copy()\n",
    "\n",
    "    # Barycenter\n",
    "    x = np.ones(n, dtype=float) / n\n",
    "\n",
    "    objectives = [float(x @ A_reg @ x)]\n",
    "    it = 0\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        it = t + 1\n",
    "        x_old = x.copy()\n",
    "\n",
    "        Ax = A_reg @ x\n",
    "        x = x * Ax  # Hadamard\n",
    "\n",
    "        s = x.sum()\n",
    "        if s <= 0:\n",
    "            # Grafo degenerado (sin aristas) => volvemos al barycenter y paramos\n",
    "            x = np.ones(n, dtype=float) / n\n",
    "            break\n",
    "        x = x / s\n",
    "\n",
    "        objectives.append(float(x @ A_reg @ x))\n",
    "\n",
    "        # Convergencia: cambio L1\n",
    "        if np.sum(np.abs(x - x_old)) < tol:\n",
    "            break\n",
    "\n",
    "    history = {'objectives': objectives, 'iterations': it}\n",
    "    return x, history\n",
    "\n",
    "\n",
    "def decode_clique(x, A, threshold=1e-6):\n",
    "    \"\"\"\n",
    "    Extract the maximum clique from the RD solution.\n",
    "\n",
    "    Strategy:\n",
    "    1. Sort nodes by x value (descending)\n",
    "    2. Greedily add nodes that maintain clique property\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (n,) - RD solution\n",
    "        A: numpy array of shape (n, n) - adjacency matrix\n",
    "        threshold: float - minimum x value to consider\n",
    "\n",
    "    Returns:\n",
    "        clique: list of node indices\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float).reshape(-1)\n",
    "    n = x.shape[0]\n",
    "    A = np.asarray(A, dtype=float)\n",
    "\n",
    "    order = np.argsort(-x)  # descending\n",
    "    clique = []\n",
    "\n",
    "    for i in order:\n",
    "        if x[i] < threshold and len(clique) > 0:\n",
    "            break\n",
    "\n",
    "        # Can_Extend(C, i, A)\n",
    "        ok = True\n",
    "        for j in clique:\n",
    "            if A[j, i] == 0:\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "        if ok:\n",
    "            clique.append(int(i))\n",
    "\n",
    "    # Pequeño “polish”: intentar extender con el resto (por si threshold corta demasiado pronto)\n",
    "    # Esto mantiene la propiedad de clique por construcción.\n",
    "    for i in order:\n",
    "        if int(i) in clique:\n",
    "            continue\n",
    "        ok = True\n",
    "        for j in clique:\n",
    "            if A[j, i] == 0:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            clique.append(int(i))\n",
    "\n",
    "    return clique\n",
    "\n",
    "\n",
    "def visualize_rd(A, graph_name=\"Test Graph\", use_regularization=True):\n",
    "    \"\"\"\n",
    "    Run RD and create visualization of convergence.\n",
    "    \"\"\"\n",
    "    x_final, history = replicator_dynamics(A, max_iter=2000, tol=1e-12, use_regularization=use_regularization)\n",
    "    clique = decode_clique(x_final, A)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "    # Plot 1: Objective value over time (monótono en teoría)\n",
    "    axes[0].plot(history['objectives'], alpha=0.9)\n",
    "    axes[0].set_title('Objetivo (xᵀ(A+0.5I)x)')\n",
    "    axes[0].set_xlabel('Iteración')\n",
    "    axes[0].set_ylabel('Valor')\n",
    "\n",
    "    # Plot 2: Distribución final de x\n",
    "    axes[1].bar(np.arange(n), x_final, alpha=0.9)\n",
    "    axes[1].set_title('x final (barycenter → soporte)')\n",
    "    axes[1].set_xlabel('Nodo')\n",
    "    axes[1].set_ylabel('xᵢ')\n",
    "\n",
    "    # Plot 3: Grafo coloreado por x (y borde rojo si está en la clique decodificada)\n",
    "    G = nx.from_numpy_array(np.asarray(A, dtype=float))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    node_vals = x_final\n",
    "    nodes = list(G.nodes())\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, ax=axes[2], alpha=0.35, width=0.8)\n",
    "    sc = nx.draw_networkx_nodes(\n",
    "        G, pos, ax=axes[2],\n",
    "        node_color=[node_vals[i] for i in nodes],\n",
    "        node_size=250,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    # Resaltar clique\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, ax=axes[2],\n",
    "        nodelist=clique,\n",
    "        node_size=330,\n",
    "        node_color='none',\n",
    "        edgecolors='crimson',\n",
    "        linewidths=2.0\n",
    "    )\n",
    "    axes[2].set_title(f'Grafo coloreado por x (clique size={len(clique)})')\n",
    "    axes[2].axis('off')\n",
    "    plt.colorbar(sc, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.suptitle(f\"Replicator Dynamics — {graph_name}\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return x_final, history, clique\n",
    "\n",
    "\n",
    "class CliqueExperiment:\n",
    "    \"\"\"\n",
    "    Clase ligera para evaluar brute force y RD en datasets (y comparar contra ground truth cuando sea posible).\n",
    "\n",
    "    Igual que en la Práctica 00, la idea es: ejecutar -> almacenar resultados en DataFrames\n",
    "    -> visualizar y resumir sin imprimir demasiado.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._bf_rows = []\n",
    "        self._rd_rows = []\n",
    "\n",
    "    def run_bruteforce(self, dataset, dataset_name, max_graphs=20, max_nodes=25):\n",
    "        self._bf_rows = []\n",
    "        for i in tqdm(range(min(max_graphs, len(dataset))), desc=f'Brute force — {dataset_name}'):\n",
    "            data = dataset[i]\n",
    "            n = int(data.num_nodes)\n",
    "            if n > max_nodes:\n",
    "                # Saltamos por coste exponencial\n",
    "                continue\n",
    "\n",
    "            A, _ = pyg_to_adjacency(data, make_undirected=True)\n",
    "            start = time.time()\n",
    "            clique = brute_force_max_clique(A)\n",
    "            elapsed = time.time() - start\n",
    "\n",
    "            self._bf_rows.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'graph_idx': i,\n",
    "                'num_nodes': n,\n",
    "                'clique_size': len(clique),\n",
    "                'clique': clique,\n",
    "                'time': elapsed\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(self._bf_rows)\n",
    "\n",
    "    def run_rd(self, dataset, dataset_name, num_graphs=50, max_iter=1000, tol=1e-12, use_regularization=True):\n",
    "        self._rd_rows = []\n",
    "        for i in tqdm(range(min(num_graphs, len(dataset))), desc=f'RD — {dataset_name}'):\n",
    "            data = dataset[i]\n",
    "            A, _ = pyg_to_adjacency(data, make_undirected=True)\n",
    "\n",
    "            start = time.time()\n",
    "            x_final, hist = replicator_dynamics(A, max_iter=max_iter, tol=tol, use_regularization=use_regularization)\n",
    "            clique = decode_clique(x_final, A)\n",
    "            elapsed = time.time() - start\n",
    "\n",
    "            valid = is_clique(clique, A)\n",
    "\n",
    "            self._rd_rows.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'graph_idx': i,\n",
    "                'num_nodes': int(data.num_nodes),\n",
    "                'clique_size': len(clique),\n",
    "                'clique': clique,\n",
    "                'valid': bool(valid),\n",
    "                'time': elapsed,\n",
    "                'iterations': int(hist['iterations'])\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(self._rd_rows)\n",
    "\n",
    "    @staticmethod\n",
    "    def summarize(df, title=None):\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        summary = df.agg({\n",
    "            'clique_size': ['mean', 'std', 'min', 'max'],\n",
    "            'time': ['mean', 'std', 'min', 'max'],\n",
    "        }).T\n",
    "        summary.columns = ['Mean', 'Std', 'Min', 'Max']\n",
    "        summary = summary.reset_index().rename(columns={'index': 'Metric'})\n",
    "        if title:\n",
    "            print(title)\n",
    "        return summary\n",
    "\n",
    "    @staticmethod\n",
    "    def compare_against_ground_truth(df_bf, df_rd):\n",
    "        \"\"\"\n",
    "        Compara RD vs brute force en los grafos que tengan ground truth (merge por graph_idx).\n",
    "        Devuelve un DataFrame con métricas y un resumen agregado.\n",
    "        \"\"\"\n",
    "        if df_bf.empty or df_rd.empty:\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        merged = df_rd.merge(df_bf[['graph_idx', 'clique_size']], on='graph_idx', how='inner', suffixes=('_rd', '_bf'))\n",
    "        merged['exact_match'] = merged['clique_size_rd'] == merged['clique_size_bf']\n",
    "        merged['ratio'] = merged['clique_size_rd'] / merged['clique_size_bf'].replace(0, np.nan)\n",
    "\n",
    "        summary = pd.DataFrame([{\n",
    "            'Num graphs (with BF)': len(merged),\n",
    "            'Exact match rate': merged['exact_match'].mean(),\n",
    "            'Mean ratio (RD/BF)': merged['ratio'].mean(),\n",
    "            'Median ratio (RD/BF)': merged['ratio'].median(),\n",
    "        }])\n",
    "\n",
    "        return merged, summary\n",
    "\n",
    "\n",
    "def plot_size_histograms(df_list, labels, title, filename=None):\n",
    "    \"\"\"Histograma simple de tamaños de clique para varias series.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for df, lab in zip(df_list, labels):\n",
    "        plt.hist(df['clique_size'], bins=20, alpha=0.6, label=lab)\n",
    "    plt.title(title, fontsize=13, fontweight='bold')\n",
    "    plt.xlabel('Clique size')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_time_scatter(df, title, filename=None):\n",
    "    \"\"\"Scatter: num_nodes vs time.\"\"\"\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(df['num_nodes'], df['time'], alpha=0.7)\n",
    "    plt.title(title, fontsize=13, fontweight='bold')\n",
    "    plt.xlabel('Número de nodos')\n",
    "    plt.ylabel('Tiempo (s)')\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a46e0",
   "metadata": {},
   "source": [
    "## 1.4 3. Ejercicio 1 — Baseline exacto: Brute Force\n",
    "\n",
    "En este primer ejercicio implemento el baseline exacto. La idea es sencilla: enumerar todos los subconjuntos de nodos empezando por los más grandes y devolver el primero que sea una clique.\n",
    "\n",
    "Este método es inservible para grafos medianos/grandes por complejidad exponencial, pero es muy útil como **ground truth** en grafos pequeños (y para medir “cuán cerca” están los métodos aproximados).\n",
    "\n",
    "### 3.1 Tests rápidos en grafos sintéticos (4–8 nodos)\n",
    "\n",
    "Antes de lanzar nada sobre datasets, pruebo con grafos de juguete donde conozco la solución:\n",
    "- Un triángulo + nodo extra  \n",
    "- Un cuadrado con diagonal (contiene clique de tamaño 3)  \n",
    "- Un grafo “cherry” (camino de longitud 2), cuya maximum clique es de tamaño 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2551022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graph</th>\n",
       "      <th>n</th>\n",
       "      <th>Clique</th>\n",
       "      <th>Clique size</th>\n",
       "      <th>Is clique?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Triangle+Tail</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Square+Diagonal</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cherry</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Graph  n     Clique  Clique size  Is clique?\n",
       "0    Triangle+Tail  4  [0, 1, 2]            3        True\n",
       "1  Square+Diagonal  4  [0, 1, 2]            3        True\n",
       "2           Cherry  3     [0, 2]            2        True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Grafo 1: triángulo (0-1-2) + nodo 3 conectado solo a 2\n",
    "A1 = np.array([\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 0, 1, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# --- Grafo 2: cuadrado 0-1-2-3-0 + diagonal 0-2  => clique máxima tamaño 3 (0,1,2) o (0,2,3)\n",
    "A2 = np.array([\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 0, 1, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# --- Grafo 3: cherry  0-2-1  => clique máxima tamaño 2\n",
    "A3 = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 0]\n",
    "], dtype=float)\n",
    "\n",
    "tests = [('Triangle+Tail', A1), ('Square+Diagonal', A2), ('Cherry', A3)]\n",
    "rows = []\n",
    "for name, A in tests:\n",
    "    clique = brute_force_max_clique(A)\n",
    "    rows.append({\n",
    "        'Graph': name,\n",
    "        'n': A.shape[0],\n",
    "        'Clique': clique,\n",
    "        'Clique size': len(clique),\n",
    "        'Is clique?': is_clique(clique, A)\n",
    "    })\n",
    "\n",
    "display(pd.DataFrame(rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0d4e0",
   "metadata": {},
   "source": [
    "### 3.2 Brute force en IMDB-BINARY (primeros 20 grafos, saltando >25 nodos)\n",
    "\n",
    "Aquí aplico brute force solo donde es razonable: **primeros 20 grafos** de IMDB-BINARY, y además salto grafos con más de 25 nodos para evitar tiempos prohibitivos.\n",
    "\n",
    "Nota: en COLLAB el tamaño medio de los grafos es mayor, así que brute force suele ser inviable excepto casos muy pequeños.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33af098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/IMDB-BINARY.zip\n"
     ]
    },
    {
     "ename": "ClientConnectorCertificateError",
     "evalue": "Cannot connect to host www.chrsmrrs.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:1313\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_shutdown_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_shutdown_timeout\n\u001b[0;32m-> 1313\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, sock\u001b[38;5;241m=\u001b[39msock)\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1112\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, ssl_shutdown_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA Stream Socket was expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msock\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1112\u001b[0m transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_transport(\n\u001b[1;32m   1113\u001b[0m     sock, protocol_factory, ssl, server_hostname,\n\u001b[1;32m   1114\u001b[0m     ssl_handshake_timeout\u001b[38;5;241m=\u001b[39mssl_handshake_timeout,\n\u001b[1;32m   1115\u001b[0m     ssl_shutdown_timeout\u001b[38;5;241m=\u001b[39mssl_shutdown_timeout)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Get the socket from the transport because SSL transport closes\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m# the old socket and creates a new SSL socket\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1145\u001b[0m, in \u001b[0;36mBaseEventLoop._create_connection_transport\u001b[0;34m(self, sock, protocol_factory, ssl, server_hostname, server_side, ssl_handshake_timeout, ssl_shutdown_timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py:575\u001b[0m, in \u001b[0;36mSSLProtocol._on_handshake_complete\u001b[0;34m(self, handshake_exc)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m handshake_exc\n\u001b[1;32m    577\u001b[0m peercert \u001b[38;5;241m=\u001b[39m sslobj\u001b[38;5;241m.\u001b[39mgetpeercert()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py:557\u001b[0m, in \u001b[0;36mSSLProtocol._do_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLAgainErrors:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:979\u001b[0m, in \u001b[0;36mSSLObject.do_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientConnectorCertificateError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Carga de datasets (TU Dortmund vía PyG)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m imdb_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTUDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIMDB-BINARY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m collab_dataset \u001b[38;5;241m=\u001b[39m TUDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLLAB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDB-BINARY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(imdb_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m grafos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/datasets/tu_dataset.py:129\u001b[0m, in \u001b[0;36mTUDataset.__init__\u001b[0;34m(self, root, name, transform, pre_transform, pre_filter, force_reload, use_node_attr, use_edge_attr, cleaned)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaned \u001b[38;5;241m=\u001b[39m cleaned\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mtorch_load(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/data/dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_reload \u001b[38;5;241m=\u001b[39m force_reload\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_download:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/data/dataset.py:230\u001b[0m, in \u001b[0;36mDataset._download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    229\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/datasets/tu_dataset.py:197\u001b[0m, in \u001b[0;36mTUDataset.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaned_url \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaned \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43murl\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mls(osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)):\n\u001b[1;32m    199\u001b[0m         fs\u001b[38;5;241m.\u001b[39mmv(filename, osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, osp\u001b[38;5;241m.\u001b[39mbasename(filename)))\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch_geometric/io/fs.py:155\u001b[0m, in \u001b[0;36mcp\u001b[0;34m(path1, path2, extract, log, use_cache, clear_cache)\u001b[0m\n\u001b[1;32m    152\u001b[0m     multiple_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Perform the copy:\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m open_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m open_file \u001b[38;5;28;01mas\u001b[39;00m f_from:\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiple_files:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/core.py:295\u001b[0m, in \u001b[0;36mopen_files\u001b[0;34m(urlpath, mode, compression, encoding, errors, name_function, num, protocol, newline, auto_mkdir, expand, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_files\u001b[39m(\n\u001b[1;32m    217\u001b[0m     urlpath,\n\u001b[1;32m    218\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    229\u001b[0m ):\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a path or paths, return a list of ``OpenFile`` objects.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    For writing, a str path must contain the \"*\" character, which will be filled\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     fs, fs_token, paths \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_token_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mprotocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    305\u001b[0m         fs\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;241m=\u001b[39m auto_mkdir\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/core.py:667\u001b[0m, in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    665\u001b[0m     inkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfo\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m urls\n\u001b[1;32m    666\u001b[0m paths, protocol, _ \u001b[38;5;241m=\u001b[39m chain[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 667\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[43mfilesystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(urlpath, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    669\u001b[0m     pchains \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    670\u001b[0m         _un_chain(stringify_path(u), storage_options \u001b[38;5;129;01mor\u001b[39;00m {})[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m urlpath\n\u001b[1;32m    671\u001b[0m     ]\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/registry.py:307\u001b[0m, in \u001b[0;36mfilesystem\u001b[0;34m(protocol, **storage_options)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrow_hdfs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m protocol has been deprecated and will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremoved in the future. Specify it as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhdfs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m get_filesystem_class(protocol)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/spec.py:81\u001b[0m, in \u001b[0;36m_Cached.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[token]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Setting _fs_token here causes some static linters to complain.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_fs_token_ \u001b[38;5;241m=\u001b[39m token\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/implementations/zip.py:62\u001b[0m, in \u001b[0;36mZipFileSystem.__init__\u001b[0;34m(self, fo, mode, target_protocol, target_options, compression, allowZip64, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_zip_64 \u001b[38;5;241m=\u001b[39m allowZip64\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mof \u001b[38;5;241m=\u001b[39m fo\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfo \u001b[38;5;241m=\u001b[39m \u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# the whole instance is a context\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfo,\n\u001b[1;32m     65\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel,\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/core.py:105\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_magic(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath):\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/implementations/cached.py:446\u001b[0m, in \u001b[0;36mCachingFileSystem.__getattribute__.<locals>.<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;66;03m# all the methods defined in this class. Note `open` here, since\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;66;03m# it calls `_open`, but is actually in superclass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/spec.py:1310\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1310\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/implementations/cached.py:446\u001b[0m, in \u001b[0;36mCachingFileSystem.__getattribute__.<locals>.<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;66;03m# all the methods defined in this class. Note `open` here, since\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;66;03m# it calls `_open`, but is actually in superclass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/implementations/cached.py:871\u001b[0m, in \u001b[0;36mSimpleCacheFileSystem._open\u001b[0;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m             f2\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(path, mode)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/fsspec/implementations/http.py:246\u001b[0m, in \u001b[0;36mHTTPFileSystem._get_file\u001b[0;34m(self, rpath, lpath, chunk_size, callback, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(rpath)\n\u001b[1;32m    245\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_session()\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_url(rpath), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m         size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/client.py:1510\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp: _RetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m   1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/client.py:779\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size, middlewares)\u001b[0m\n\u001b[1;32m    776\u001b[0m     handler \u001b[38;5;241m=\u001b[39m _connect_and_send_request\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 779\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m handler(req)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# Client connector errors should not be retried\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    782\u001b[0m     ConnectionTimeoutError,\n\u001b[1;32m    783\u001b[0m     ClientConnectorError,\n\u001b[1;32m    784\u001b[0m     ClientConnectorCertificateError,\n\u001b[1;32m    785\u001b[0m     ClientConnectorSSLError,\n\u001b[1;32m    786\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/client.py:734\u001b[0m, in \u001b[0;36mClientSession._request.<locals>._connect_and_send_request\u001b[0;34m(req)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 734\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m    735\u001b[0m         req, traces\u001b[38;5;241m=\u001b[39mtraces, timeout\u001b[38;5;241m=\u001b[39mreal_timeout\n\u001b[1;32m    736\u001b[0m     )\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionTimeoutError(\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection timeout to host \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:672\u001b[0m, in \u001b[0;36mBaseConnector.connect\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msend_connection_create_start()\n\u001b[0;32m--> 672\u001b[0m proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(req, traces, timeout)\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traces:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:1239\u001b[0m, in \u001b[0;36mTCPConnector._create_connection\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_proxy_connection(req, traces, timeout)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1239\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_direct_connection(req, traces, timeout)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:1611\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_exc\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:1580\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1575\u001b[0m server_hostname \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1576\u001b[0m     (req\u001b[38;5;241m.\u001b[39mserver_hostname \u001b[38;5;129;01mor\u001b[39;00m host)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m sslcontext \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m )\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     transp, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_create_connection(\n\u001b[1;32m   1581\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factory,\n\u001b[1;32m   1582\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1583\u001b[0m         ssl\u001b[38;5;241m=\u001b[39msslcontext,\n\u001b[1;32m   1584\u001b[0m         addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[1;32m   1585\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m   1586\u001b[0m         req\u001b[38;5;241m=\u001b[39mreq,\n\u001b[1;32m   1587\u001b[0m         client_error\u001b[38;5;241m=\u001b[39mclient_error,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ClientConnectorError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1590\u001b[0m     last_exc \u001b[38;5;241m=\u001b[39m exc\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/aiohttp/connector.py:1315\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, sock\u001b[38;5;241m=\u001b[39msock)\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectorCertificateError(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ssl_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectorSSLError(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mClientConnectorCertificateError\u001b[0m: Cannot connect to host www.chrsmrrs.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]"
     ]
    }
   ],
   "source": [
    "# Carga de datasets (TU Dortmund vía PyG)\n",
    "imdb_dataset = TUDataset(root='./data', name='IMDB-BINARY')\n",
    "collab_dataset = TUDataset(root='./data', name='COLLAB')\n",
    "\n",
    "print(f\"IMDB-BINARY: {len(imdb_dataset)} grafos\")\n",
    "print(f\"COLLAB: {len(collab_dataset)} grafos\")\n",
    "\n",
    "# Muestra rápida de un grafo\n",
    "sample = imdb_dataset[0]\n",
    "print(\"\\nEjemplo IMDB[0]:\")\n",
    "print(f\"  Nodes: {sample.num_nodes}\")\n",
    "print(f\"  Edges: {sample.num_edges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bf28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = CliqueExperiment()\n",
    "\n",
    "bf_imdb = bench.run_bruteforce(imdb_dataset, 'IMDB-BINARY', max_graphs=20, max_nodes=25)\n",
    "display(bf_imdb.head(10))\n",
    "\n",
    "# Resumen\n",
    "display(bench.summarize(bf_imdb, title=\"\\nResumen brute force — IMDB-BINARY (subset)\"))\n",
    "\n",
    "plot_time_scatter(bf_imdb, 'Brute force — IMDB-BINARY (subset)', filename='images/bf_time_imdb.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659eb026",
   "metadata": {},
   "source": [
    "## 1.5 4. Ejercicio 2 — Relajación continua: Motzkin–Straus\n",
    "\n",
    "El teorema de Motzkin–Straus nos permite reescribir Maximum Clique como un problema continuo:\n",
    "\n",
    "\\[\n",
    "\\max_{x \\in \\Delta_n} \\; f(x) = x^\\top A x\n",
    "\\]\n",
    "\n",
    "donde \\(\\Delta_n\\) es el simplex (\\(x_i \\ge 0\\) y \\(\\sum_i x_i = 1\\)). El valor máximo está relacionado con el tamaño de la maximum clique \\(\\omega(G)\\) según:\n",
    "\n",
    "\\[\n",
    "\\max_{x \\in \\Delta_n} x^\\top A x = 1 - \\frac{1}{\\omega(G)}.\n",
    "\\]\n",
    "\n",
    "En la práctica aparece el fenómeno de **soluciones espurias** (por ejemplo en el grafo “cherry”), por lo que suele utilizarse una versión regularizada:\n",
    "\n",
    "\\[\n",
    "\\hat{f}(x) = x^\\top (A + \\tfrac{1}{2}I) x.\n",
    "\\]\n",
    "\n",
    "### 4.1 Verificación en grafos de juguete\n",
    "\n",
    "En esta celda verifico:\n",
    "- Que el valor de Motzkin–Straus coincide con \\(1 - 1/k\\) usando el clique máximo encontrado por brute force.\n",
    "- Que en el cherry graph existen soluciones con el mismo valor (espurias) y que la regularización las penaliza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b25e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_motzkin_straus():\n",
    "    rows = []\n",
    "\n",
    "    # Test 1: K3 (triángulo)\n",
    "    A = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 0]\n",
    "    ], dtype=float)\n",
    "    clique = brute_force_max_clique(A)\n",
    "    k = len(clique)\n",
    "    x = np.zeros(A.shape[0])\n",
    "    x[clique] = 1.0 / k\n",
    "\n",
    "    rows.append({\n",
    "        'Graph': 'K3',\n",
    "        'omega (BF)': k,\n",
    "        'f(x*)': motzkin_straus_objective(x, A),\n",
    "        '1 - 1/omega': 1 - 1/k,\n",
    "        'abs diff': abs(motzkin_straus_objective(x, A) - (1 - 1/k)),\n",
    "        'f_hat(x*)': regularized_objective(x, A),\n",
    "    })\n",
    "\n",
    "    # Test 2: cuadrado + diagonal 0-2 (A2)\n",
    "    A = A2.copy()\n",
    "    clique = brute_force_max_clique(A)\n",
    "    k = len(clique)\n",
    "    x = np.zeros(A.shape[0])\n",
    "    x[clique] = 1.0 / k\n",
    "\n",
    "    rows.append({\n",
    "        'Graph': 'Square+Diagonal',\n",
    "        'omega (BF)': k,\n",
    "        'f(x*)': motzkin_straus_objective(x, A),\n",
    "        '1 - 1/omega': 1 - 1/k,\n",
    "        'abs diff': abs(motzkin_straus_objective(x, A) - (1 - 1/k)),\n",
    "        'f_hat(x*)': regularized_objective(x, A),\n",
    "    })\n",
    "\n",
    "    # Test 3: cherry (A3) — mostrar solución espuria\n",
    "    A = A3.copy()\n",
    "    # Solución \"clique\": {0,2}\n",
    "    x_true = np.array([0.5, 0.0, 0.5])\n",
    "    # Solución espuria mencionada en el enunciado: (1/4, 1/4, 1/2)\n",
    "    x_spur = np.array([0.25, 0.25, 0.5])\n",
    "\n",
    "    omega = len(brute_force_max_clique(A))\n",
    "\n",
    "    rows.append({\n",
    "        'Graph': 'Cherry (true clique)',\n",
    "        'omega (BF)': omega,\n",
    "        'f(x*)': motzkin_straus_objective(x_true, A),\n",
    "        '1 - 1/omega': 1 - 1/omega,\n",
    "        'abs diff': abs(motzkin_straus_objective(x_true, A) - (1 - 1/omega)),\n",
    "        'f_hat(x*)': regularized_objective(x_true, A),\n",
    "    })\n",
    "\n",
    "    rows.append({\n",
    "        'Graph': 'Cherry (spurious)',\n",
    "        'omega (BF)': omega,\n",
    "        'f(x*)': motzkin_straus_objective(x_spur, A),\n",
    "        '1 - 1/omega': 1 - 1/omega,\n",
    "        'abs diff': abs(motzkin_straus_objective(x_spur, A) - (1 - 1/omega)),\n",
    "        'f_hat(x*)': regularized_objective(x_spur, A),\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_ms = verify_motzkin_straus()\n",
    "display(df_ms)\n",
    "\n",
    "print(\"\\nObservación clave (Cherry): f(x) coincide en ambas soluciones, pero f_hat(x) penaliza la espuria.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a8b3a",
   "metadata": {},
   "source": [
    "## 1.6 5. Ejercicio 3 — Replicator Dynamics (RD) + Decoder\n",
    "\n",
    "Una vez tenemos la formulación continua, necesitamos un algoritmo práctico para maximizarla bajo restricciones de simplex. RD es ideal aquí porque:\n",
    "\n",
    "- Mantiene \\(x\\) siempre en el simplex (normalización).  \n",
    "- En teoría, incrementa la función objetivo en cada iteración hasta converger a un punto estacionario.  \n",
    "- Con la regularización \\(A + 0.5I\\) tiende a evitar máximos “no-clique” (espurios).\n",
    "\n",
    "### 5.1 Visualización de convergencia en un ejemplo pequeño\n",
    "\n",
    "Para ver “qué hace” RD, lo ejecuto en el grafo *Square+Diagonal* y muestro:\n",
    "1) la curva del objetivo, 2) el vector final \\(x\\), y 3) el grafo coloreado por \\(x\\) (y resaltando la clique decodificada).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2eb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_rd(A2, graph_name='Square+Diagonal', use_regularization=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13f6eb",
   "metadata": {},
   "source": [
    "### 5.2 RD en IMDB-BINARY y COLLAB (50 grafos)\n",
    "\n",
    "Aquí aplico RD (50 grafos en cada dataset) y reporto:\n",
    "- Tamaño medio de clique y desviación estándar\n",
    "- Tiempo medio de cómputo\n",
    "- Proporción de cliques válidas (debería ser 100% porque el decoder fuerza la propiedad)\n",
    "\n",
    "Además, donde existe brute force (subset de IMDB con <=25 nodos), comparo tamaños para estimar “exactitud”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094896b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RD en ambos datasets (50 grafos)\n",
    "rd_imdb = bench.run_rd(imdb_dataset, 'IMDB-BINARY', num_graphs=50, max_iter=1000, tol=1e-12, use_regularization=True)\n",
    "rd_collab = bench.run_rd(collab_dataset, 'COLLAB', num_graphs=50, max_iter=1000, tol=1e-12, use_regularization=True)\n",
    "\n",
    "display(rd_imdb.head(10))\n",
    "display(rd_collab.head(10))\n",
    "\n",
    "print(\"\\nResumen RD — IMDB-BINARY\")\n",
    "display(bench.summarize(rd_imdb))\n",
    "\n",
    "print(\"\\nResumen RD — COLLAB\")\n",
    "display(bench.summarize(rd_collab))\n",
    "\n",
    "# Validación: deberían ser cliques válidas por construcción (sanity check)\n",
    "print(f\"Valid cliques (IMDB): {rd_imdb['valid'].mean()*100:.1f}%\")\n",
    "print(f\"Valid cliques (COLLAB): {rd_collab['valid'].mean()*100:.1f}%\")\n",
    "\n",
    "plot_size_histograms(\n",
    "    [rd_imdb, rd_collab],\n",
    "    ['IMDB (RD)', 'COLLAB (RD)'],\n",
    "    title='Distribución de tamaños de clique (RD)',\n",
    "    filename='images/rd_size_hist.png'\n",
    ")\n",
    "\n",
    "plot_time_scatter(rd_imdb, 'RD — IMDB-BINARY (50 grafos)', filename='images/rd_time_imdb.png')\n",
    "plot_time_scatter(rd_collab, 'RD — COLLAB (50 grafos)', filename='images/rd_time_collab.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b90e36",
   "metadata": {},
   "source": [
    "## 1.7 6. Comparativa final (tablas + visualizaciones)\n",
    "\n",
    "En esta sección cierro el experimento con dos comparativas:\n",
    "\n",
    "1. **RD vs Brute Force (IMDB subset)**: solo en grafos donde brute force es factible (\\(n \\le 25\\)).  \n",
    "2. **Tabla resumen por dataset y método**: tamaño medio de clique y tiempo medio.\n",
    "\n",
    "La métrica “Exact match rate” se define como: fracción de grafos donde RD recupera una clique del mismo tamaño que la máxima (según brute force).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación RD vs brute force (solo para grafos donde BF existe)\n",
    "merged_imdb, comp_summary = bench.compare_against_ground_truth(bf_imdb, rd_imdb)\n",
    "display(comp_summary)\n",
    "\n",
    "if not merged_imdb.empty:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.scatter(merged_imdb['clique_size_bf'], merged_imdb['clique_size_rd'], alpha=0.75)\n",
    "    plt.plot([merged_imdb['clique_size_bf'].min(), merged_imdb['clique_size_bf'].max()],\n",
    "             [merged_imdb['clique_size_bf'].min(), merged_imdb['clique_size_bf'].max()],\n",
    "             linestyle='--', linewidth=2)\n",
    "    plt.title('RD vs Brute Force (IMDB subset)', fontsize=13, fontweight='bold')\n",
    "    plt.xlabel('Clique size (Brute Force)')\n",
    "    plt.ylabel('Clique size (RD)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/rd_vs_bf_imdb.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Tabla final (sin GNN+RD porque no es parte obligatoria del enunciado en esta entrega)\n",
    "summary_rows = []\n",
    "\n",
    "def add_method_summary(method, dataset_name, df):\n",
    "    if df.empty:\n",
    "        return\n",
    "    summary_rows.append({\n",
    "        'Method': method,\n",
    "        'Dataset': dataset_name,\n",
    "        'Mean Clique Size': df['clique_size'].mean(),\n",
    "        'Std Clique Size': df['clique_size'].std(),\n",
    "        'Mean Time (s)': df['time'].mean(),\n",
    "        'Std Time (s)': df['time'].std(),\n",
    "        'Graphs': len(df)\n",
    "    })\n",
    "\n",
    "add_method_summary('Brute Force', 'IMDB-BINARY (subset)', bf_imdb)\n",
    "add_method_summary('Replicator Dynamics', 'IMDB-BINARY', rd_imdb)\n",
    "add_method_summary('Replicator Dynamics', 'COLLAB', rd_collab)\n",
    "\n",
    "final_table = pd.DataFrame(summary_rows)\n",
    "display(final_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22fa93",
   "metadata": {},
   "source": [
    "## 1.8 7. Discusión y conclusiones\n",
    "\n",
    "**1) Brute force como referencia.**  \n",
    "El baseline exacto es útil para grafos pequeños: nos da una cota superior real y permite medir cuándo un método aproximado acierta exactamente. En cuanto el número de nodos crece, el coste exponencial lo vuelve impracticable.\n",
    "\n",
    "**2) Motzkin–Straus como “puente” discreto→continuo.**  \n",
    "La relajación continua es sorprendentemente informativa: el valor óptimo en el simplex está directamente ligado al tamaño de la maximum clique. La parte delicada son las **soluciones espurias**, que motivan el término de regularización \\(0.5I\\).\n",
    "\n",
    "**3) RD es rápido y estable, pero no garantiza óptimo global.**  \n",
    "RD tiende a encontrar cliques válidas (el decoder lo fuerza) y a producir tamaños competitivos en poco tiempo. Aun así, al ser un problema no convexo, puede converger a máximos locales dependiendo del grafo (y del punto inicial). En grafos donde disponemos de brute force, la comparación RD/BF permite cuantificar cuántas veces cae en el óptimo.\n",
    "\n",
    "**4) Extensiones naturales.**  \n",
    "Una mejora habitual es aprender una **inicialización** mejor que el barycenter (por ejemplo con una GNN), y luego refinar con RD. Esto aparece como extensión en el enunciado, pero no es requisito obligatorio en esta entrega.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
