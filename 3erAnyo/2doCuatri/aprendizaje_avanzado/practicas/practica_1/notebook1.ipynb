{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4b63e6",
   "metadata": {},
   "source": [
    "# Práctica 1: Aprendizaje Supervisado\n",
    "## Dataset: Estimation of Obesity Levels Based on Eating Habits and Physical Condition\n",
    "\n",
    "**Autor:** Jordi Blasco Lozano  \n",
    "**DNI:** 74527208D  \n",
    "**Email:** jbl42@alu.ua.es  \n",
    "**Asignatura:** Aprendizaje Avanzado - Curso 2025/2026  \n",
    "**Universidad de Alicante - Escuela Politécnica Superior**\n",
    "\n",
    "> Nota: se reutiliza el mismo dataset y el mismo preprocesado de la Práctica 0.  \n",
    "> El objetivo es comparar modelos supervisados (SVM, árboles y ensembles) y analizar el efecto de hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0973b",
   "metadata": {},
   "source": [
    "## 1. Carga de datos y configuración\n",
    "\n",
    "En esta primera sección importamos todas las librerías necesarias, definimos funciones auxiliares para guardar tablas y figuras, y cargamos el dataset. Reutilizamos el mismo CSV de la Práctica 0 (*Estimation of Obesity Levels Based on Eating Habits and Physical Condition*) para garantizar comparabilidad directa con los resultados anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d10849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Carpetas de salida\n",
    "BASE_DIR = Path('.').resolve()\n",
    "IMAGES_DIR = BASE_DIR / 'images'\n",
    "TABLES_DIR = BASE_DIR / 'tables'\n",
    "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24adfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset_path() -> Path:\n",
    "    \"\"\"Busca el CSV en las rutas típicas del repo de prácticas.\"\"\"\n",
    "    candidates = [\n",
    "        BASE_DIR / 'data' / 'ObesityDataSet_raw_and_data_sinthetic.csv',\n",
    "        BASE_DIR.parent / 'practica_0' / 'data' / 'ObesityDataSet_raw_and_data_sinthetic.csv',\n",
    "        BASE_DIR.parent / 'practica0' / 'data' / 'ObesityDataSet_raw_and_data_sinthetic.csv',\n",
    "        BASE_DIR / 'ObesityDataSet_raw_and_data_sinthetic.csv',\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"No se encontró el dataset.\\n\\n\"\n",
    "        \"Rutas probadas:\\n - \" + \"\\n - \".join(str(p) for p in candidates) + \"\\n\\n\"\n",
    "        \"Asegúrate de tener el CSV en practica_0/data o en practica_1/data.\"\n",
    "    )\n",
    "\n",
    "def save_table(df: pd.DataFrame, name: str) -> Path:\n",
    "    \"\"\"Guarda una tabla como LaTeX (solo tabular) en ./tables/{name}.tex\"\"\"\n",
    "    out = TABLES_DIR / f\"{name}.tex\"\n",
    "    latex = df.to_latex(index=False, escape=True, na_rep='-', float_format=\"%.4f\", bold_rows=False)\n",
    "    out.write_text(latex, encoding='utf-8')\n",
    "    return out\n",
    "\n",
    "def save_fig(path: Path, dpi: int = 300):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def metrics_row(y_true, y_pred) -> dict:\n",
    "    return {\n",
    "        'Test Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision (w)': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'Recall (w)': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'F1 (w)': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "    }\n",
    "\n",
    "def plot_confusion(y_true, y_pred, class_names, filename: str, title: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    ax.set_xlabel('Predicho')\n",
    "    ax.set_ylabel('Real')\n",
    "    ax.set_title(title)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    save_fig(IMAGES_DIR / filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd1a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta: C:\\Users\\jordi\\Documents\\UNI\\IA\\3erAnyo\\2doCuatri\\aprendizaje_avanzado\\practicas\\practica_0\\data\\ObesityDataSet_raw_and_data_sinthetic.csv\n",
      "Shape original: (2111, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = find_dataset_path()\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Ruta:', DATA_PATH)\n",
    "print('Shape original:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18520a5e",
   "metadata": {},
   "source": [
    "## 2. Preprocesado (idéntico a Práctica 0)\n",
    "\n",
    "Tal como indica el enunciado, el preprocesado se da por supuesto y no es necesario detallarlo de nuevo. Para garantizar comparabilidad con la Práctica 0, se aplica exactamente el mismo pipeline de limpieza:\n",
    "\n",
    "1. **Eliminación de outliers en Weight y Height** mediante el método IQR (Rango Intercuartílico).\n",
    "2. **Transformación Box-Cox en Age** y posterior filtrado IQR sobre la distribución transformada.\n",
    "3. **Encoding de variables categóricas:** *Label Encoding* para las binarias (Gender, family_history, FAVC, SMOKE, SCC) y *One-Hot Encoding* con `drop_first=True` para las multiclase (CAEC, CALC, MTRANS).\n",
    "4. **Split train/test estratificado** 80/20 con `random_state=42`.\n",
    "5. **Filtrado de outliers en train** con Z-score (|z| > 3) sobre las variables numéricas originales.\n",
    "\n",
    "> **Nota sobre el escalado:** la estandarización no se aplica manualmente aquí, sino dentro de `Pipeline` (StandardScaler + modelo) para SVM y modelos lineales. Esto elimina el riesgo de *Data Leakage* y garantiza que en cada fold de validación cruzada la estandarización se recalcula de forma independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ebc784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape tras limpieza: (2107, 17)\n",
      "Shape tras encoding: (2107, 23)\n",
      "Train: (1685, 23) | Test: (422, 23)\n",
      "Outliers eliminados en train (Z>3): 0\n"
     ]
    }
   ],
   "source": [
    "target_col = 'NObeyesdad'\n",
    "\n",
    "# 1) IQR en Weight y Height\n",
    "df_clean = df.copy()\n",
    "mask_clean = pd.Series(True, index=df_clean.index)\n",
    "for col in ['Weight', 'Height']:\n",
    "    q1 = df_clean[col].quantile(0.25)\n",
    "    q3 = df_clean[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    mask_clean &= (df_clean[col] >= lower) & (df_clean[col] <= upper)\n",
    "\n",
    "df_clean = df_clean.loc[mask_clean].reset_index(drop=True)\n",
    "\n",
    "# 2) Box-Cox en Age + IQR post\n",
    "df_clean['Age'], lambda_age = stats.boxcox(df_clean['Age'] + 1)\n",
    "q1 = df_clean['Age'].quantile(0.25)\n",
    "q3 = df_clean['Age'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "df_clean = df_clean[(df_clean['Age'] >= lower) & (df_clean['Age'] <= upper)].reset_index(drop=True)\n",
    "\n",
    "# 3) Separar X/y + encoding del target\n",
    "X = df_clean.drop(columns=[target_col]).copy()\n",
    "y = df_clean[target_col].copy()\n",
    "\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "class_names = le_target.classes_.tolist()\n",
    "\n",
    "# 4) Encoding de features (idéntico a práctica 0)\n",
    "X_processed = X.copy()\n",
    "\n",
    "binary_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
    "for col in binary_cols:\n",
    "    if col in X_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_processed[col] = le.fit_transform(X_processed[col])\n",
    "\n",
    "multi_cat_cols = ['CAEC', 'CALC', 'MTRANS']\n",
    "X_processed = pd.get_dummies(X_processed, columns=multi_cat_cols, drop_first=True)\n",
    "\n",
    "# Columnas numéricas originales (para Z-score post-split)\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != target_col]\n",
    "\n",
    "# 5) Split 80/20 estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded,\n",
    "    test_size=0.2, random_state=RANDOM_STATE, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 6) Filtrado de outliers en train con Z-score en columnas numéricas originales\n",
    "scaler_temp = StandardScaler()\n",
    "X_train_z = scaler_temp.fit_transform(X_train[numeric_cols])\n",
    "mask_inliers = (np.abs(X_train_z) <= 3).all(axis=1)\n",
    "\n",
    "rows_before = len(X_train)\n",
    "X_train = X_train.loc[mask_inliers].reset_index(drop=True)\n",
    "y_train = y_train[mask_inliers]\n",
    "rows_removed = rows_before - len(X_train)\n",
    "\n",
    "print('Shape tras limpieza:', df_clean.shape)\n",
    "print('Shape tras encoding:', X_processed.shape)\n",
    "print(f'Train: {X_train.shape} | Test: {X_test.shape}')\n",
    "print(f'Outliers eliminados en train (Z>3): {rows_removed}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e5d3e",
   "metadata": {},
   "source": [
    "## 3. Parte 1 — Support Vector Machines (SVM)\n",
    "\n",
    "Las SVM buscan el hiperplano que maximiza el margen entre clases. En problemas no linealmente separables, utilizan funciones *kernel* para proyectar los datos a un espacio de mayor dimensionalidad donde sí son separables. Los principales hiperparámetros son:\n",
    "\n",
    "- **C:** controla el trade-off entre maximizar el margen y minimizar errores de clasificación. Un C alto genera un margen estrecho con pocos errores (riesgo de *overfitting*), mientras que un C bajo genera un margen amplio pero permite más errores (*underfitting*).\n",
    "- **gamma (γ):** en kernels RBF y polinomial, controla el alcance de influencia de cada muestra. Un gamma alto implica influencia local (fronteras complejas), y un gamma bajo implica influencia amplia (fronteras suaves).\n",
    "- **degree:** grado del polinomio en el kernel polinomial.\n",
    "\n",
    "> **Importante:** SVM es sensible a la escala de las variables, por lo que siempre encapsulamos un `StandardScaler` dentro del `Pipeline` antes del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358f748",
   "metadata": {},
   "source": [
    "### 3.1 SVM con diferentes kernels (parámetros por defecto)\n",
    "\n",
    "Empezamos entrenando modelos SVM con los cuatro kernels principales (Linear, Polinomial grado 3, RBF y Sigmoid) usando los hiperparámetros por defecto de scikit-learn. Para cada kernel medimos: accuracy en validación cruzada 5-Fold, accuracy y métricas ponderadas en test, número de vectores de soporte y tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9822e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>CV Std</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision (w)</th>\n",
       "      <th>Recall (w)</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Nº SV</th>\n",
       "      <th>% Train SV</th>\n",
       "      <th>Fit Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.941840</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.939125</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.938064</td>\n",
       "      <td>565</td>\n",
       "      <td>33.531157</td>\n",
       "      <td>0.048107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF</td>\n",
       "      <td>0.852819</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.880678</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.874658</td>\n",
       "      <td>1089</td>\n",
       "      <td>64.629080</td>\n",
       "      <td>0.050225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poly (d=3)</td>\n",
       "      <td>0.745401</td>\n",
       "      <td>0.020507</td>\n",
       "      <td>0.744076</td>\n",
       "      <td>0.761190</td>\n",
       "      <td>0.744076</td>\n",
       "      <td>0.738924</td>\n",
       "      <td>1202</td>\n",
       "      <td>71.335312</td>\n",
       "      <td>0.053569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>0.032014</td>\n",
       "      <td>0.651659</td>\n",
       "      <td>0.649538</td>\n",
       "      <td>0.651659</td>\n",
       "      <td>0.650088</td>\n",
       "      <td>1217</td>\n",
       "      <td>72.225519</td>\n",
       "      <td>0.049305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kernel  CV Accuracy    CV Std  Test Accuracy  Precision (w)  Recall (w)    F1 (w)  Nº SV  % Train SV  Fit Time (s)\n",
       "0      Linear     0.941840  0.024940       0.938389       0.939125    0.938389  0.938064    565   33.531157      0.048107\n",
       "2         RBF     0.852819  0.023183       0.872038       0.880678    0.872038  0.874658   1089   64.629080      0.050225\n",
       "1  Poly (d=3)     0.745401  0.020507       0.744076       0.761190    0.744076  0.738924   1202   71.335312      0.053569\n",
       "3     Sigmoid     0.640950  0.032014       0.651659       0.649538    0.651659  0.650088   1217   72.225519      0.049305"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = {\n",
    "    'Linear':     SVC(kernel='linear', random_state=RANDOM_STATE),\n",
    "    'Poly (d=3)': SVC(kernel='poly', degree=3, random_state=RANDOM_STATE),\n",
    "    'RBF':        SVC(kernel='rbf', random_state=RANDOM_STATE),\n",
    "    'Sigmoid':    SVC(kernel='sigmoid', random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, svc in kernels.items():\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svm', svc)])\n",
    "\n",
    "    # CV\n",
    "    cv_scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean, cv_std = cv_scores.mean(), cv_scores.std()\n",
    "\n",
    "    # Fit + test\n",
    "    t0 = perf_counter()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fit_time = perf_counter() - t0\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    m = metrics_row(y_test, y_pred)\n",
    "\n",
    "    n_sv = int(pipe.named_steps['svm'].n_support_.sum())\n",
    "    rows.append({\n",
    "        'Kernel': name,\n",
    "        'CV Accuracy': cv_mean,\n",
    "        'CV Std': cv_std,\n",
    "        **m,\n",
    "        'Nº SV': n_sv,\n",
    "        '% Train SV': 100 * n_sv / len(X_train),\n",
    "        'Fit Time (s)': fit_time,\n",
    "    })\n",
    "\n",
    "df_svm_kernels = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_svm_kernels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5577547",
   "metadata": {},
   "source": [
    "El kernel **Linear** obtiene el mejor resultado con parámetros por defecto (CV = 0.9418, Test = 0.9384), superando claramente al resto. Esto puede deberse a que el preprocesado (encoding + estandarización) ya genera un espacio de 23 dimensiones donde las clases son razonablemente separables por fronteras lineales, tal como sugerían los resultados de Regresión Logística en la Práctica 0 (F1 = 0.9359 con C = 10).\n",
    "\n",
    "El kernel **RBF**, que suele ser el más versátil, queda en segundo lugar (CV = 0.8528) con los parámetros por defecto. Sin embargo, esto no significa que sea peor: sus hiperparámetros C y gamma necesitan ajustarse, cosa que haremos en la siguiente sección.\n",
    "\n",
    "El kernel **Sigmoid** es el peor con diferencia (CV = 0.6410). Este kernel se comporta como un perceptrón multicapa de una capa oculta y suele dar problemas de rendimiento cuando no se ajustan cuidadosamente sus parámetros.\n",
    "\n",
    "También es interesante observar el número de **vectores de soporte (SV)**: el kernel lineal usa 565 SV (33.5% del training set), mientras que los kernels no lineales necesitan muchos más (64–72%). A mayor número de SV, mayor complejidad efectiva del clasificador y mayor coste de inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85543642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_kernels.tex')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_svm_kernels[['Kernel','CV Accuracy','Test Accuracy','Precision (w)','Recall (w)','F1 (w)','Nº SV','% Train SV']], 'svm_kernels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78b9de",
   "metadata": {},
   "source": [
    "### 3.2 Optimización del kernel RBF (GridSearchCV)\n",
    "\n",
    "El kernel RBF (`exp(-γ·||x-x'||²)`) suele ser el más efectivo para datos no lineales, pero depende fuertemente de dos hiperparámetros:\n",
    "\n",
    "- **C** (regularización): valores altos → margen pequeño, se ajusta más a los datos.\n",
    "- **gamma (γ)**: valores altos → cada muestra influye solo en su vecindad cercana, produciendo fronteras más complejas.\n",
    "\n",
    "Utilizamos `GridSearchCV` con CV 5-Fold para explorar combinaciones de C ∈ {0.1, 1, 10, 100} y γ ∈ {0.001, 0.01, 0.1, 1, 'scale', 'auto'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd479e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'svm__C': 100, 'svm__gamma': 0.01}\n",
      "Mejor CV score: 0.9401\n",
      "Test score: 0.9431\n",
      "Tiempo GridSearch: 3.725s\n"
     ]
    }
   ],
   "source": [
    "pipe_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': [0.001, 0.01, 0.1, 1, 'scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_rbf = GridSearchCV(\n",
    "    pipe_rbf, param_grid_rbf,\n",
    "    cv=5, scoring='accuracy', n_jobs=-1, refit=True\n",
    ")\n",
    "\n",
    "t0 = perf_counter()\n",
    "grid_rbf.fit(X_train, y_train)\n",
    "grid_time = perf_counter() - t0\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_rbf.best_params_)\n",
    "print(f\"Mejor CV score: {grid_rbf.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_rbf.best_estimator_.score(X_test, y_test):.4f}\")\n",
    "print(f\"Tiempo GridSearch: {grid_time:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772c6d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Nº SV</th>\n",
       "      <th>% Train</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.940059</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>629</td>\n",
       "      <td>37.329377</td>\n",
       "      <td>0.042572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.922255</td>\n",
       "      <td>0.940758</td>\n",
       "      <td>879</td>\n",
       "      <td>52.166172</td>\n",
       "      <td>0.047493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.908605</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>799</td>\n",
       "      <td>47.418398</td>\n",
       "      <td>0.047326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.908605</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>799</td>\n",
       "      <td>47.418398</td>\n",
       "      <td>0.045705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.908012</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>850</td>\n",
       "      <td>50.445104</td>\n",
       "      <td>0.046181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.908012</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>850</td>\n",
       "      <td>50.445104</td>\n",
       "      <td>0.047440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.907418</td>\n",
       "      <td>0.919431</td>\n",
       "      <td>880</td>\n",
       "      <td>52.225519</td>\n",
       "      <td>0.040854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.889614</td>\n",
       "      <td>0.898104</td>\n",
       "      <td>943</td>\n",
       "      <td>55.964392</td>\n",
       "      <td>0.064266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.889021</td>\n",
       "      <td>0.902844</td>\n",
       "      <td>939</td>\n",
       "      <td>55.727003</td>\n",
       "      <td>0.063836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>1053</td>\n",
       "      <td>62.492582</td>\n",
       "      <td>0.060063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  gamma  CV Accuracy  Test Accuracy  Nº SV    % Train  Tiempo (s)\n",
       "0  100.0   0.01     0.940059       0.943128    629  37.329377    0.042572\n",
       "1  100.0  0.001     0.922255       0.940758    879  52.166172    0.047493\n",
       "2  100.0  scale     0.908605       0.921801    799  47.418398    0.047326\n",
       "3  100.0   auto     0.908605       0.921801    799  47.418398    0.045705\n",
       "4   10.0  scale     0.908012       0.909953    850  50.445104    0.046181\n",
       "5   10.0   auto     0.908012       0.909953    850  50.445104    0.047440\n",
       "6   10.0   0.01     0.907418       0.919431    880  52.225519    0.040854\n",
       "7   10.0    0.1     0.889614       0.898104    943  55.964392    0.064266\n",
       "8  100.0    0.1     0.889021       0.902844    939  55.727003    0.063836\n",
       "9    1.0    0.1     0.865875       0.860190   1053  62.492582    0.060063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla con al menos 10 combinaciones representativas: usamos las 10 mejores por CV\n",
    "cvres = pd.DataFrame(grid_rbf.cv_results_)\n",
    "cvres = cvres.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "top = cvres.head(10).copy()\n",
    "rows = []\n",
    "for _, r in top.iterrows():\n",
    "    C = r['param_svm__C']\n",
    "    gamma = r['param_svm__gamma']\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='rbf', C=C, gamma=gamma, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    t0 = perf_counter()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    t_fit = perf_counter() - t0\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    n_sv = int(pipe.named_steps['svm'].n_support_.sum())\n",
    "    rows.append({\n",
    "        'C': float(C),\n",
    "        'gamma': str(gamma),\n",
    "        'CV Accuracy': float(r['mean_test_score']),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Nº SV': n_sv,\n",
    "        '% Train': 100 * n_sv / len(X_train),\n",
    "        'Tiempo (s)': t_fit\n",
    "    })\n",
    "\n",
    "df_svm_rbf = pd.DataFrame(rows)\n",
    "df_svm_rbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aac640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_rbf_grid.tex')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_svm_rbf, 'svm_rbf_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8b6de",
   "metadata": {},
   "source": [
    "La mejor combinación encontrada es **C = 100** y **γ = 0.01** (CV = 0.9401, Test = 0.9431), superando al kernel RBF por defecto en casi 9 puntos porcentuales. El valor alto de C indica que el modelo se beneficia de reducir la tolerancia a errores de clasificación, mientras que γ = 0.01 mantiene una influencia moderada de cada muestra, evitando *overfitting* con fronteras demasiado irregulares.\n",
    "\n",
    "### 3.3 Optimización del kernel polinomial (GridSearchCV)\n",
    "\n",
    "El kernel polinomial (`(γ·⟨x, x'⟩ + r)^d`) permite controlar la complejidad de la frontera mediante el grado (degree) y la combinación de C y γ. Exploramos degree ∈ {2, 3, 4}, C ∈ {0.1, 1, 10} y γ ∈ {'scale', 'auto', 0.1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b3eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'svm__C': 10, 'svm__degree': 3, 'svm__gamma': 0.1}\n",
      "Mejor CV score: 0.8718\n",
      "Test score: 0.8886\n",
      "Tiempo GridSearch: 0.901s\n"
     ]
    }
   ],
   "source": [
    "pipe_poly = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='poly', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid_poly = {\n",
    "    'svm__degree': [2, 3, 4],\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1]\n",
    "}\n",
    "\n",
    "grid_poly = GridSearchCV(\n",
    "    pipe_poly, param_grid_poly,\n",
    "    cv=5, scoring='accuracy', n_jobs=-1, refit=True\n",
    ")\n",
    "\n",
    "t0 = perf_counter()\n",
    "grid_poly.fit(X_train, y_train)\n",
    "grid_time_poly = perf_counter() - t0\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_poly.best_params_)\n",
    "print(f\"Mejor CV score: {grid_poly.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_poly.best_estimator_.score(X_test, y_test):.4f}\")\n",
    "print(f\"Tiempo GridSearch: {grid_time_poly:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f791a12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Nº SV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.871810</td>\n",
       "      <td>0.888626</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.864095</td>\n",
       "      <td>0.876777</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.860534</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.860534</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.858754</td>\n",
       "      <td>0.845972</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.847478</td>\n",
       "      <td>0.855450</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.847478</td>\n",
       "      <td>0.855450</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.839169</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.835608</td>\n",
       "      <td>0.845972</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.830861</td>\n",
       "      <td>0.838863</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   degree     C  gamma  CV Accuracy  Test Accuracy  Nº SV\n",
       "0       3  10.0    0.1     0.871810       0.888626    789\n",
       "1       3   1.0    0.1     0.864095       0.876777    897\n",
       "2       3  10.0   auto     0.860534       0.879147    916\n",
       "3       3  10.0  scale     0.860534       0.879147    916\n",
       "4       2  10.0    0.1     0.858754       0.845972    783\n",
       "5       2  10.0  scale     0.847478       0.855450    900\n",
       "6       2  10.0   auto     0.847478       0.855450    900\n",
       "7       4   1.0    0.1     0.839169       0.843602    959\n",
       "8       4  10.0    0.1     0.835608       0.845972    856\n",
       "9       2   1.0    0.1     0.830861       0.838863    946"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres_poly = pd.DataFrame(grid_poly.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Cogemos 10 representativas (top 10)\n",
    "top = cvres_poly.head(10).copy()\n",
    "rows = []\n",
    "for _, r in top.iterrows():\n",
    "    degree = int(r['param_svm__degree'])\n",
    "    C = float(r['param_svm__C'])\n",
    "    gamma = r['param_svm__gamma']\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='poly', degree=degree, C=C, gamma=gamma, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    n_sv = int(pipe.named_steps['svm'].n_support_.sum())\n",
    "    rows.append({\n",
    "        'degree': degree,\n",
    "        'C': C,\n",
    "        'gamma': str(gamma),\n",
    "        'CV Accuracy': float(r['mean_test_score']),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Nº SV': n_sv\n",
    "    })\n",
    "\n",
    "df_svm_poly = pd.DataFrame(rows)\n",
    "df_svm_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fc10cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_poly_grid.tex')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_svm_poly, 'svm_poly_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8dbb7",
   "metadata": {},
   "source": [
    "La mejor configuración polinomial es **degree = 3, C = 10, γ = 0.1** (CV = 0.8718, Test = 0.8886). Aunque mejora respecto al kernel polinomial por defecto, se queda por debajo tanto del kernel lineal como del RBF optimizado. Grados mayores (d = 4) no mejoran el rendimiento, lo que sugiere que la relación entre las features no requiere interacciones de orden superior para este problema.\n",
    "\n",
    "### 3.4 Comparación de implementaciones lineales (SVC linear vs LinearSVC vs SGDClassifier)\n",
    "\n",
    "Scikit-learn ofrece tres implementaciones del caso lineal con distinta formulación interna y coste computacional:\n",
    "\n",
    "| Implementación | Formulación | Uso recomendado |\n",
    "|:---|:---|:---|\n",
    "| `SVC(kernel='linear')` | Dual (libsvm) | n_samples < 10,000 |\n",
    "| `LinearSVC` | Primal (liblinear) | Datasets medianos, kernel lineal |\n",
    "| `SGDClassifier(loss='hinge')` | SGD con hinge loss | Datasets grandes (> 100,000) |\n",
    "\n",
    "Comparamos rendimiento y tiempo de entrenamiento de las tres implementaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14e8e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Implementación</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Nº SV</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC(linear)</td>\n",
       "      <td>0.941840</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>565</td>\n",
       "      <td>0.058051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.763205</td>\n",
       "      <td>0.786730</td>\n",
       "      <td>-</td>\n",
       "      <td>0.047093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.706231</td>\n",
       "      <td>0.694313</td>\n",
       "      <td>-</td>\n",
       "      <td>0.027383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Implementación  CV Accuracy  Test Accuracy Nº SV  Tiempo (s)\n",
       "0    SVC(linear)     0.941840       0.938389   565    0.058051\n",
       "1      LinearSVC     0.763205       0.786730     -    0.047093\n",
       "2  SGDClassifier     0.706231       0.694313     -    0.027383"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_linear = {\n",
    "    'SVC(linear)':   Pipeline([('scaler', StandardScaler()),\n",
    "                               ('svm', SVC(kernel='linear', random_state=RANDOM_STATE))]),\n",
    "    'LinearSVC':     Pipeline([('scaler', StandardScaler()),\n",
    "                               ('svm', LinearSVC(random_state=RANDOM_STATE, max_iter=10000))]),\n",
    "    'SGDClassifier': Pipeline([('scaler', StandardScaler()),\n",
    "                               ('svm', SGDClassifier(loss='hinge', random_state=RANDOM_STATE))]),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in models_linear.items():\n",
    "    t0 = perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = perf_counter() - t0\n",
    "\n",
    "    cv = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    n_sv = '-'\n",
    "    if name.startswith('SVC'):\n",
    "        n_sv = int(model.named_steps['svm'].n_support_.sum())\n",
    "\n",
    "    rows.append({\n",
    "        'Implementación': name,\n",
    "        'CV Accuracy': cv.mean(),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Nº SV': n_sv,\n",
    "        'Tiempo (s)': fit_time\n",
    "    })\n",
    "\n",
    "df_svm_linear_impl = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_svm_linear_impl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8895be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_linear_impl.tex')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_svm_linear_impl, 'svm_linear_impl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d8870",
   "metadata": {},
   "source": [
    "`SVC(linear)` es claramente superior en accuracy (CV = 0.9418, Test = 0.9384), mientras que `LinearSVC` y `SGDClassifier` quedan por debajo (CV ≈ 0.76 y 0.71 respectivamente). La diferencia se debe a que `SVC` resuelve el problema dual exacto, mientras que `LinearSVC` usa otra formulación (liblinear) y `SGDClassifier` realiza optimización estocástica que puede no converger al óptimo global sin un ajuste cuidadoso de hiperparámetros. En tiempo, las tres son similares dado el tamaño reducido de nuestro dataset (~1685 muestras). Para datasets masivos (>100k), SGDClassifier sería la única opción viable.\n",
    "\n",
    "### 3.5 Análisis de vectores de soporte (configuraciones representativas)\n",
    "\n",
    "Los vectores de soporte son las muestras de entrenamiento que definen la frontera de decisión. A mayor número de SV, el modelo utiliza más datos para trazar la frontera, lo que puede indicar mayor complejidad o mayor dificultad del problema para ese kernel. Comparamos el número de SV en distintas configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1297b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuración</th>\n",
       "      <th>Nº SV</th>\n",
       "      <th>% Training Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear (C=1)</td>\n",
       "      <td>565</td>\n",
       "      <td>33.531157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF (C=10, γ=0.1)</td>\n",
       "      <td>943</td>\n",
       "      <td>55.964392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBF (C=1, γ=scale)</td>\n",
       "      <td>1089</td>\n",
       "      <td>64.629080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poly (d=3, C=1)</td>\n",
       "      <td>1202</td>\n",
       "      <td>71.335312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBF (C=100, γ=1)</td>\n",
       "      <td>1260</td>\n",
       "      <td>74.777448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Configuración  Nº SV  % Training Set\n",
       "0        Linear (C=1)    565       33.531157\n",
       "2   RBF (C=10, γ=0.1)    943       55.964392\n",
       "1  RBF (C=1, γ=scale)   1089       64.629080\n",
       "4     Poly (d=3, C=1)   1202       71.335312\n",
       "3    RBF (C=100, γ=1)   1260       74.777448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = [\n",
    "    ('Linear (C=1)',        dict(kernel='linear', C=1, gamma='scale')),\n",
    "    ('RBF (C=1, γ=scale)',  dict(kernel='rbf', C=1, gamma='scale')),\n",
    "    ('RBF (C=10, γ=0.1)',   dict(kernel='rbf', C=10, gamma=0.1)),\n",
    "    ('RBF (C=100, γ=1)',    dict(kernel='rbf', C=100, gamma=1)),\n",
    "    ('Poly (d=3, C=1)',     dict(kernel='poly', degree=3, C=1, gamma='scale')),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for name, params in configs:\n",
    "    svc = SVC(random_state=RANDOM_STATE, **params)\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svm', svc)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    n_sv = int(pipe.named_steps['svm'].n_support_.sum())\n",
    "    rows.append({\n",
    "        'Configuración': name,\n",
    "        'Nº SV': n_sv,\n",
    "        '% Training Set': 100 * n_sv / len(X_train),\n",
    "    })\n",
    "\n",
    "df_sv = pd.DataFrame(rows).sort_values('% Training Set')\n",
    "df_sv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec2f6dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_support_vectors.tex')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_sv, 'svm_support_vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080c072",
   "metadata": {},
   "source": [
    "La configuración con menor porcentaje de SV es el kernel lineal (C = 1), lo que indica que necesita relativamente pocos puntos de referencia para definir la frontera. La configuración extrema **RBF (C = 100, γ = 1)** usa una proporción elevada del training set como SV, señal de que con γ alto la frontera es tan local que prácticamente memoriza los datos (riesgo de *overfitting*).\n",
    "\n",
    "### 3.6 Evaluación final SVM (mejor modelo) + matriz de confusión\n",
    "\n",
    "Evaluamos el mejor modelo SVM encontrado (RBF con C = 100, γ = 0.01) en el conjunto de test y generamos su *classification report* y matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0632fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.96      0.98      0.97        54\n",
      "      Normal_Weight       0.86      0.86      0.86        57\n",
      "     Obesity_Type_I       0.92      0.99      0.95        70\n",
      "    Obesity_Type_II       0.98      0.93      0.96        60\n",
      "   Obesity_Type_III       1.00      0.98      0.99        65\n",
      " Overweight_Level_I       0.90      0.90      0.90        58\n",
      "Overweight_Level_II       0.98      0.95      0.96        58\n",
      "\n",
      "           accuracy                           0.94       422\n",
      "          macro avg       0.94      0.94      0.94       422\n",
      "       weighted avg       0.94      0.94      0.94       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_rbf.best_estimator_\n",
    "best_svm.fit(X_train, y_train)\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm, target_names=class_names))\n",
    "\n",
    "plot_confusion(\n",
    "    y_test, y_pred_svm, class_names,\n",
    "    filename='confusion_matrix_svm.png',\n",
    "    title='Matriz de Confusión — Mejor SVM'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2233d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Nº SV</th>\n",
       "      <th>% Train SV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Linear</td>\n",
       "      <td>0.941840</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.938064</td>\n",
       "      <td>565</td>\n",
       "      <td>33.531157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM RBF (best)</td>\n",
       "      <td>0.940059</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>0.943202</td>\n",
       "      <td>629</td>\n",
       "      <td>37.329377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Poly (best)</td>\n",
       "      <td>0.871810</td>\n",
       "      <td>0.888626</td>\n",
       "      <td>0.888466</td>\n",
       "      <td>789</td>\n",
       "      <td>46.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM Sigmoid</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>0.651659</td>\n",
       "      <td>0.650088</td>\n",
       "      <td>1217</td>\n",
       "      <td>72.225519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Modelo  CV Accuracy  Test Accuracy    F1 (w)  Nº SV  % Train SV\n",
       "0       SVM Linear     0.941840       0.938389  0.938064    565   33.531157\n",
       "2   SVM RBF (best)     0.940059       0.943128  0.943202    629   37.329377\n",
       "1  SVM Poly (best)     0.871810       0.888626  0.888466    789   46.824926\n",
       "3      SVM Sigmoid     0.640950       0.651659  0.650088   1217   72.225519"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla resumen (Parte 1)\n",
    "def summarize_model(name, model, is_svm=True):\n",
    "    cv = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    m = metrics_row(y_test, y_pred)\n",
    "    n_sv = '-'\n",
    "    pct = '-'\n",
    "    if is_svm and hasattr(model.named_steps['svm'], 'n_support_'):\n",
    "        n_sv = int(model.named_steps['svm'].n_support_.sum())\n",
    "        pct = 100 * n_sv / len(X_train)\n",
    "    return {\n",
    "        'Modelo': name,\n",
    "        'CV Accuracy': cv.mean(),\n",
    "        'Test Accuracy': m['Test Accuracy'],\n",
    "        'F1 (w)': m['F1 (w)'],\n",
    "        'Nº SV': n_sv,\n",
    "        '% Train SV': pct\n",
    "    }\n",
    "\n",
    "svm_summary_rows = [\n",
    "    summarize_model('SVM Linear', Pipeline([('scaler', StandardScaler()),\n",
    "                                           ('svm', SVC(kernel='linear', random_state=RANDOM_STATE))]), True),\n",
    "    summarize_model('SVM Poly (best)', grid_poly.best_estimator_, True),\n",
    "    summarize_model('SVM RBF (best)', grid_rbf.best_estimator_, True),\n",
    "    summarize_model('SVM Sigmoid', Pipeline([('scaler', StandardScaler()),\n",
    "                                            ('svm', SVC(kernel='sigmoid', random_state=RANDOM_STATE))]), True),\n",
    "]\n",
    "\n",
    "df_svm_summary = pd.DataFrame(svm_summary_rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_svm_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7df213b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/svm_summary.tex')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_svm_summary, 'svm_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7a51d",
   "metadata": {},
   "source": [
    "El mejor SVM (RBF, C = 100, γ = 0.01) alcanza un **Test Accuracy de 0.9431** y un F1 ponderado de 0.94. Las clases extremas (Insufficient_Weight, Obesity_Type_III) obtienen F1 > 0.95, mientras que las intermedias (Normal_Weight, Overweight_Level_I) se benefician de la frontera no lineal para mejorar respecto a la Práctica 0 con Regresión Logística. El kernel lineal queda muy cerca (0.9384), lo que confirma que nuestros datos son bastante separables en el espacio original de 23 dimensiones.\n",
    "\n",
    "La tabla resumen de la Parte 1 recoge los mejores resultados por cada familia de kernel.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Parte 2 — Árboles de Decisión\n",
    "\n",
    "Los árboles de decisión (CART) realizan particiones recursivas del espacio de features según criterios de impureza (Gini o entropía). Su principal ventaja es la interpretabilidad: producen reglas de decisión legibles. El reto principal es controlar el *overfitting*, ya que sin restricciones un árbol puede memorizar completamente el training set. Para combatirlo se usan dos estrategias:\n",
    "\n",
    "- **Poda previa (pre-pruning):** limitar la profundidad (`max_depth`), el mínimo de muestras por split/hoja o el número de hojas.\n",
    "- **Poda posterior (post-pruning, CCP):** entrenar el árbol completo y después ir podando ramas usando el parámetro `ccp_alpha` (cost-complexity pruning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefc575",
   "metadata": {},
   "source": [
    "### 4.1 Árbol sin restricciones (baseline)\n",
    "\n",
    "Empezamos por entrenar un árbol sin ninguna restricción para observar el comportamiento de *overfitting*: esperamos que alcance un 100% de accuracy en train pero un rendimiento inferior en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2855dc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuración</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Nº Hojas</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sin restricciones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92891</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "      <td>0.008541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Configuración  Train Accuracy  Test Accuracy  Profundidad  Nº Hojas  Tiempo (s)\n",
       "0  Sin restricciones             1.0        0.92891           12       101    0.008541"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_full = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "t0 = perf_counter()\n",
    "tree_full.fit(X_train, y_train)\n",
    "t_fit = perf_counter() - t0\n",
    "\n",
    "train_acc = tree_full.score(X_train, y_train)\n",
    "test_acc = tree_full.score(X_test, y_test)\n",
    "\n",
    "df_tree_baseline = pd.DataFrame([{\n",
    "    'Configuración': 'Sin restricciones',\n",
    "    'Train Accuracy': train_acc,\n",
    "    'Test Accuracy': test_acc,\n",
    "    'Profundidad': tree_full.get_depth(),\n",
    "    'Nº Hojas': tree_full.get_n_leaves(),\n",
    "    'Tiempo (s)': t_fit\n",
    "}])\n",
    "df_tree_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b56ddf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_baseline.tex')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_baseline, 'tree_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593fce7",
   "metadata": {},
   "source": [
    "Efectivamente, el árbol sin restricciones alcanza **100% en train** pero solo **92.89% en test**, con una profundidad de 12 niveles y 101 hojas. La brecha de ~7 puntos entre train y test es señal clara de *overfitting*: el modelo ha memorizado el ruido del training set, creando hojas que responden a patrones no generalizables.\n",
    "\n",
    "### 4.2 Efecto de max_depth\n",
    "\n",
    "Exploramos cómo limitar la profundidad máxima del árbol afecta al equilibrio entre sesgo y varianza. A poca profundidad (1–3), el modelo es demasiado simple (*underfitting*); a profundidad sin límite, se produce *overfitting*. El objetivo es encontrar el punto intermedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ce38e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>CV Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Profundidad real</th>\n",
       "      <th>Nº Hojas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.290801</td>\n",
       "      <td>0.290801</td>\n",
       "      <td>0.291469</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.554303</td>\n",
       "      <td>0.553116</td>\n",
       "      <td>0.545024</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.643323</td>\n",
       "      <td>0.629080</td>\n",
       "      <td>0.656398</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.852819</td>\n",
       "      <td>0.823145</td>\n",
       "      <td>0.819905</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.885460</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.998813</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922849</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max_depth  Train Acc    CV Acc  Test Acc  Profundidad real  Nº Hojas\n",
       "0         1   0.290801  0.290801  0.291469                 1         2\n",
       "1         2   0.554303  0.553116  0.545024                 2         4\n",
       "2         3   0.643323  0.629080  0.656398                 3         8\n",
       "3         5   0.852819  0.823145  0.819905                 5        25\n",
       "4         7   0.945401  0.885460  0.900474                 7        57\n",
       "5        10   0.998813  0.925223  0.928910                10        98\n",
       "6        15   1.000000  0.922849  0.928910                12       101\n",
       "7      None   1.000000  0.924036  0.928910                12       101"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = [1, 2, 3, 5, 7, 10, 15, None]\n",
    "rows = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_STATE)\n",
    "\n",
    "    cv_scores = cross_val_score(tree, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "\n",
    "    tree.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'max_depth': 'None' if depth is None else depth,\n",
    "        'Train Acc': tree.score(X_train, y_train),\n",
    "        'CV Acc': cv_mean,\n",
    "        'Test Acc': tree.score(X_test, y_test),\n",
    "        'Profundidad real': tree.get_depth(),\n",
    "        'Nº Hojas': tree.get_n_leaves()\n",
    "    })\n",
    "\n",
    "df_tree_depth = pd.DataFrame(rows)\n",
    "df_tree_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc2645d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Temp\\ipykernel_23876\\1536526240.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfp['max_depth_num'] = dfp['max_depth'].replace('None', np.nan).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Curva profundidad vs rendimiento\n",
    "dfp = df_tree_depth.copy()\n",
    "dfp['max_depth_num'] = dfp['max_depth'].replace('None', np.nan).astype(float)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(dfp['max_depth_num'], dfp['Train Acc'], marker='o', label='Train')\n",
    "ax.plot(dfp['max_depth_num'], dfp['CV Acc'], marker='o', label='CV')\n",
    "ax.plot(dfp['max_depth_num'], dfp['Test Acc'], marker='o', label='Test')\n",
    "ax.set_xlabel('max_depth (None omitido)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Efecto de max_depth en Decision Tree')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "save_fig(IMAGES_DIR / 'decision_tree_depth_curve.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2912f93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_max_depth.tex')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_depth, 'tree_max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c48b5",
   "metadata": {},
   "source": [
    "La gráfica y la tabla muestran el patrón clásico: con **max_depth = 1** (stump) el accuracy de CV es muy bajo porque un solo split no puede capturar la complejidad de 7 clases. A partir de **max_depth = 5–7** el rendimiento se estabiliza, y aumentar la profundidad más allá no mejora la generalización sino que incrementa el *overfitting* (train sube pero CV se estanca o baja). El test accuracy máximo se obtiene en torno a profundidad 7–10.\n",
    "\n",
    "### 4.3 Criterios de división\n",
    "\n",
    "Comparamos los tres criterios de impureza disponibles para clasificación: **Gini** (usado por defecto en CART), **Entropía** (ID3/C4.5) y **Log Loss**. Los tres miden la heterogeneidad de los nodos, pero con fórmulas ligeramente distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b27f2644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criterio</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>CV Std</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Nº Hojas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>0.941840</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.959716</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.941840</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.959716</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Criterio  CV Accuracy    CV Std  Test Accuracy  Nº Hojas\n",
       "1   entropy     0.941840  0.011508       0.959716        79\n",
       "2  log_loss     0.941840  0.011508       0.959716        79\n",
       "0      gini     0.924036  0.011039       0.928910       101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterios = ['gini', 'entropy', 'log_loss']\n",
    "rows = []\n",
    "for crit in criterios:\n",
    "    tree = DecisionTreeClassifier(criterion=crit, random_state=RANDOM_STATE)\n",
    "    cv_scores = cross_val_score(tree, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    tree.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'Criterio': crit,\n",
    "        'CV Accuracy': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std(),\n",
    "        'Test Accuracy': tree.score(X_test, y_test),\n",
    "        'Nº Hojas': tree.get_n_leaves()\n",
    "    })\n",
    "\n",
    "df_tree_criteria = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_tree_criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e169e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_criteria.tex')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_criteria[['Criterio','CV Accuracy','Test Accuracy','Nº Hojas']], 'tree_criteria')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c3f73",
   "metadata": {},
   "source": [
    "Los tres criterios producen resultados muy similares, con diferencias menores a 1 punto porcentual. Es un resultado habitual: la teoría predice que Gini y Entropía difieren poco en la práctica, y log_loss es equivalente a entropía para clasificación. La elección del criterio es, en este caso, irrelevante frente a otros hiperparámetros como la profundidad o el mínimo de muestras por hoja.\n",
    "\n",
    "### 4.4 Poda previa — GridSearchCV\n",
    "\n",
    "Además de `max_depth`, existen otros parámetros de poda previa: `min_samples_split` (mínimo de muestras para dividir un nodo), `min_samples_leaf` (mínimo de muestras en cada hoja) y `max_leaf_nodes` (máximo número de hojas). Exploramos combinaciones de todos ellos con `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387dcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Mejor CV score: 0.9288\n",
      "Test score: 0.9218\n",
      "Tiempo GridSearch: 0.976s\n"
     ]
    }
   ],
   "source": [
    "param_grid_tree = {\n",
    "    'max_depth':         [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf':  [1, 2, 5, 10],\n",
    "    'max_leaf_nodes':    [None, 10, 20, 50]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    param_grid_tree,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "t0 = perf_counter()\n",
    "grid_tree.fit(X_train, y_train)\n",
    "t_grid = perf_counter() - t0\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_tree.best_params_)\n",
    "print(f\"Mejor CV score: {grid_tree.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_tree.best_estimator_.score(X_test, y_test):.4f}\")\n",
    "print(f\"Tiempo GridSearch: {t_grid:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a44a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>CV Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.921801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.927596</td>\n",
       "      <td>0.928910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.927003</td>\n",
       "      <td>0.917062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.921801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.928910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.928910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.921801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.928910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.922849</td>\n",
       "      <td>0.926540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.922255</td>\n",
       "      <td>0.926540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max_depth  min_samples_split  min_samples_leaf max_leaf_nodes    CV Acc  Test Acc\n",
       "0      None                  2                 2           None  0.928783  0.921801\n",
       "1      None                  5                 1           None  0.927596  0.928910\n",
       "2      None                  5                 2           None  0.927003  0.917062\n",
       "3        10                  2                 2           None  0.925223  0.921801\n",
       "4        10                  2                 1           None  0.925223  0.928910\n",
       "5        10                  5                 1           None  0.925223  0.928910\n",
       "6        10                  5                 2           None  0.924036  0.921801\n",
       "7      None                  2                 1           None  0.924036  0.928910\n",
       "8      None                  2                 2             50  0.922849  0.926540\n",
       "9        10                  2                 2             50  0.922255  0.926540"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres_tree = pd.DataFrame(grid_tree.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "top = cvres_tree.head(10).copy()\n",
    "\n",
    "rows = []\n",
    "for _, r in top.iterrows():\n",
    "    params = {\n",
    "        'max_depth': r['param_max_depth'],\n",
    "        'min_samples_split': int(r['param_min_samples_split']),\n",
    "        'min_samples_leaf': int(r['param_min_samples_leaf']),\n",
    "        'max_leaf_nodes': r['param_max_leaf_nodes'],\n",
    "    }\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'max_depth': 'None' if params['max_depth'] is None else int(params['max_depth']),\n",
    "        'min_samples_split': params['min_samples_split'],\n",
    "        'min_samples_leaf': params['min_samples_leaf'],\n",
    "        'max_leaf_nodes': 'None' if params['max_leaf_nodes'] is None else int(params['max_leaf_nodes']),\n",
    "        'CV Acc': float(r['mean_test_score']),\n",
    "        'Test Acc': model.score(X_test, y_test),\n",
    "    })\n",
    "\n",
    "df_tree_grid = pd.DataFrame(rows)\n",
    "df_tree_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "597c2445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_grid_prepruning.tex')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_grid, 'tree_grid_prepruning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f7e39",
   "metadata": {},
   "source": [
    "La mejor configuración de poda previa encontrada por GridSearch es **max_depth = None, min_samples_leaf = 2, min_samples_split = 2, max_leaf_nodes = None** (CV = 0.9288, Test = 0.9218). El parámetro clave es `min_samples_leaf = 2`, que impide que se creen hojas con una sola muestra, reduciendo el sobreajuste sin limitar la profundidad.\n",
    "\n",
    "### 4.5 Poda posterior — Cost-Complexity Pruning (ccp_alpha)\n",
    "\n",
    "CART implementa poda posterior mediante el parámetro `ccp_alpha`. A mayor valor de alpha, mayor poda: se eliminan las ramas cuya contribución a la reducción de impureza no compense el incremento de complejidad. El procedimiento es: (1) entrenar el árbol completo, (2) obtener la secuencia de alphas mediante `cost_complexity_pruning_path`, y (3) evaluar cada alpha con CV para encontrar el equilibrio óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c54406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha (en los seleccionados): {'alpha': 0.000791295746785361, 'cv': np.float64(0.9275964391691394)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccp_alpha</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Nº Hojas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.927596</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.926409</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.925223</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.924036</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.918101</td>\n",
       "      <td>0.936019</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.915134</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.924171</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.872404</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.787537</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.091220</td>\n",
       "      <td>0.502671</td>\n",
       "      <td>0.431280</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ccp_alpha  CV Accuracy  Test Accuracy  Profundidad  Nº Hojas\n",
       "2    0.000791     0.927596       0.928910           10        74\n",
       "4    0.001149     0.926409       0.926540           10        57\n",
       "5    0.001385     0.925223       0.924171           10        49\n",
       "3    0.001107     0.925223       0.926540           10        67\n",
       "0    0.000000     0.924036       0.928910           12       101\n",
       "1    0.000581     0.924036       0.928910           10        86\n",
       "6    0.002148     0.918101       0.936019            9        41\n",
       "7    0.002428     0.915134       0.928910            8        35\n",
       "8    0.004285     0.899110       0.924171            8        28\n",
       "9    0.008398     0.872404       0.900474            8        22\n",
       "10   0.021421     0.787537       0.800948            6        12\n",
       "11   0.091220     0.502671       0.431280            2         3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = DecisionTreeClassifier(random_state=RANDOM_STATE).cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas[:-1]  # último -> solo raíz\n",
    "\n",
    "# Selección de alphas representativos (si hay muchos)\n",
    "if len(ccp_alphas) > 12:\n",
    "    idx = np.unique(np.round(np.linspace(0, len(ccp_alphas)-1, 12)).astype(int))\n",
    "    alphas_sel = ccp_alphas[idx]\n",
    "else:\n",
    "    alphas_sel = ccp_alphas\n",
    "\n",
    "rows = []\n",
    "best = {'alpha': None, 'cv': -1}\n",
    "\n",
    "for alpha in alphas_sel:\n",
    "    tree = DecisionTreeClassifier(ccp_alpha=float(alpha), random_state=RANDOM_STATE)\n",
    "    cv_scores = cross_val_score(tree, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "\n",
    "    tree.fit(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "    rows.append({\n",
    "        'ccp_alpha': float(alpha),\n",
    "        'CV Accuracy': cv_mean,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Profundidad': tree.get_depth(),\n",
    "        'Nº Hojas': tree.get_n_leaves()\n",
    "    })\n",
    "    if cv_mean > best['cv']:\n",
    "        best = {'alpha': float(alpha), 'cv': cv_mean}\n",
    "\n",
    "df_tree_ccp = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "print('Mejor alpha (en los seleccionados):', best)\n",
    "df_tree_ccp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45c435e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva alpha vs rendimiento (sobre los alphas seleccionados)\n",
    "dfp = df_tree_ccp.sort_values('ccp_alpha')\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(dfp['ccp_alpha'], dfp['CV Accuracy'], marker='o', label='CV')\n",
    "ax.plot(dfp['ccp_alpha'], dfp['Test Accuracy'], marker='o', label='Test')\n",
    "ax.set_xlabel('ccp_alpha')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Cost-Complexity Pruning: alpha vs rendimiento')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "save_fig(IMAGES_DIR / 'decision_tree_ccp_curve.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "473e6a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_ccp.tex')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_ccp, 'tree_ccp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90edc77",
   "metadata": {},
   "source": [
    "El mejor `ccp_alpha ≈ 0.00079` produce un CV de 0.9276, con una profundidad de 10 y 74 hojas. La curva muestra cómo, a medida que alpha crece, el árbol se simplifica: al principio la poda elimina ramas ruidosas mejorando la generalización, pero si alpha es demasiado grande el árbol se poda en exceso y pierde capacidad discriminativa.\n",
    "\n",
    "### 4.6 Importancia de características (mejor árbol por poda previa)\n",
    "\n",
    "Una de las grandes ventajas de los árboles de decisión es que permiten calcular la **importancia de cada feature** según la reducción media de impureza (Gini importance). Las variables usadas en los primeros splits del árbol tienen mayor importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98a77625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importancia (Gini)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight</td>\n",
       "      <td>0.506558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height</td>\n",
       "      <td>0.246968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.160277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.024752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAVC</td>\n",
       "      <td>0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CH2O</td>\n",
       "      <td>0.010139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAEC_Sometimes</td>\n",
       "      <td>0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TUE</td>\n",
       "      <td>0.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCP</td>\n",
       "      <td>0.003756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAEC_Frequently</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MTRANS_Walking</td>\n",
       "      <td>0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCC</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CALC_no</td>\n",
       "      <td>0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MTRANS_Public_Transportation</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAF</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importancia (Gini)\n",
       "3                         Weight            0.506558\n",
       "2                         Height            0.246968\n",
       "0                         Gender            0.160277\n",
       "1                            Age            0.024752\n",
       "5                           FAVC            0.023797\n",
       "9                           CH2O            0.010139\n",
       "14                CAEC_Sometimes            0.007591\n",
       "12                           TUE            0.004725\n",
       "7                            NCP            0.003756\n",
       "13               CAEC_Frequently            0.002327\n",
       "22                MTRANS_Walking            0.002271\n",
       "10                           SCC            0.001833\n",
       "18                       CALC_no            0.001635\n",
       "21  MTRANS_Public_Transportation            0.001054\n",
       "11                           FAF            0.000785"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = grid_tree.best_estimator_\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "importances = best_tree.feature_importances_\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "df_tree_imp = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importancia (Gini)': importances\n",
    "}).sort_values('Importancia (Gini)', ascending=False)\n",
    "\n",
    "df_tree_imp.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "560193e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top-15 importancias\n",
    "topk = df_tree_imp.head(15).iloc[::-1]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(topk['Feature'], topk['Importancia (Gini)'])\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_title('Decision Tree — Importancia de características (top 15)')\n",
    "save_fig(IMAGES_DIR / 'decision_tree_feature_importance.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adc51f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_feature_importance.tex')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_imp.head(20), 'tree_feature_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b40381",
   "metadata": {},
   "source": [
    "Como era de esperar, **Weight** y **Height** dominan ampliamente la importancia, coherente con lo que observamos en los scatter plots de la Práctica 0 (el IMC se calcula directamente a partir de estas dos variables). El resto de features tienen importancias mucho menores pero contribuyen colectivamente a las decisiones en niveles más profundos del árbol.\n",
    "\n",
    "### 4.7 Visualización del árbol (profundidad limitada para legibilidad)\n",
    "\n",
    "Visualizamos los primeros 4 niveles del mejor árbol. Se puede observar cómo las primeras divisiones utilizan Weight para separar rápidamente los niveles extremos de obesidad, y luego Height refina las categorías intermedias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0db6711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Weight <= 99.54\n",
      "|   |--- Weight <= 60.06\n",
      "|   |   |--- Height <= 1.66\n",
      "|   |   |   |--- Weight <= 46.83\n",
      "|   |   |   |   |--- Height <= 1.51\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- Height >  1.51\n",
      "|   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |--- Weight >  46.83\n",
      "|   |   |   |   |--- Height <= 1.52\n",
      "|   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |--- Height >  1.52\n",
      "|   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |--- Height >  1.66\n",
      "|   |   |   |--- Weight <= 60.00\n",
      "|   |   |   |   |--- TUE <= 0.02\n",
      "|   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |--- TUE >  0.02\n",
      "|   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |--- Weight >  60.00\n",
      "|   |   |   |   |--- Height <= 1.82\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- Height >  1.82\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- Weight >  60.06\n",
      "|   |   |--- Weight <= 76.04\n",
      "|   |   |   |--- Height <= 1.72\n",
      "|   |   |   |   |--- FAVC <= 0.50\n",
      "|   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |--- FAVC >  0.50\n",
      "|   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |--- Height >  1.72\n",
      "|   |   |   |   |--- Weight <= 75.31\n",
      "|   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |--- Weight >  75.31\n",
      "|   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |--- Weight >  76.04\n",
      "|   |   |   |--- Height <= 1.67\n",
      "|   |   |   |   |--- Height <= 1.65\n",
      "|   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |--- Height >  1.65\n",
      "|   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |--- Height >  1.67\n",
      "|   |   |   |   |--- Weight <= 89.92\n",
      "|   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |--- Weight >  89.92\n",
      "|   |   |   |   |   |--- truncated branch of depth 4\n",
      "|--- Weight >  99.54\n",
      "|   |--- Gender <= 0.50\n",
      "|   |   |--- Weight <= 102.00\n",
      "|   |   |   |--- class: 3\n",
      "|   |   |--- Weight >  102.00\n",
      "|   |   |   |--- class: 4\n",
      "|   |--- Gender >  0.50\n",
      "|   |   |--- Weight <= 109.74\n",
      "|   |   |   |--- Height <= 1.75\n",
      "|   |   |   |   |--- CH2O <= 1.83\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- CH2O >  1.83\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- Height >  1.75\n",
      "|   |   |   |   |--- Height <= 1.87\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- Height >  1.87\n",
      "|   |   |   |   |   |--- class: 6\n",
      "|   |   |--- Weight >  109.74\n",
      "|   |   |   |--- Age <= 0.61\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |   |--- Age >  0.61\n",
      "|   |   |   |   |--- Age <= 0.61\n",
      "|   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |--- Age >  0.61\n",
      "|   |   |   |   |   |--- class: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 10))\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8,\n",
    "    max_depth=4,\n",
    "    ax=ax\n",
    ")\n",
    "save_fig(IMAGES_DIR / 'decision_tree.png', dpi=250)\n",
    "\n",
    "print(export_text(best_tree, feature_names=feature_names, max_depth=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856be53",
   "metadata": {},
   "source": [
    "### 4.8 Evaluación final (Parte 2)\n",
    "\n",
    "Comparamos las tres estrategias de árboles de decisión:\n",
    "\n",
    "- **Sin restricciones**: árbol completo sin ninguna limitación de crecimiento.\n",
    "- **Mejor poda previa (pre-pruning)**: mejor combinación de `max_depth`, `min_samples_split` y `min_samples_leaf` obtenida por GridSearchCV.\n",
    "- **Mejor poda posterior (post-pruning)**: mejor `ccp_alpha` seleccionado por validación cruzada.\n",
    "\n",
    "En la tabla reportamos Test Accuracy, F1 ponderado, profundidad y número de hojas para cada variante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc9efe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision (w)</th>\n",
       "      <th>Recall (w)</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Profundidad</th>\n",
       "      <th>Nº Hojas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sin restricciones</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.932683</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>12</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mejor poda posterior</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.932683</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mejor poda previa</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.925161</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.922354</td>\n",
       "      <td>11</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modelo  Test Accuracy  Precision (w)  Recall (w)    F1 (w)  Profundidad  Nº Hojas\n",
       "0     Sin restricciones       0.928910       0.932683    0.928910  0.929719           12       101\n",
       "2  Mejor poda posterior       0.928910       0.932683    0.928910  0.929719           10        74\n",
       "1     Mejor poda previa       0.921801       0.925161    0.921801  0.922354           11        90"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mejor árbol por poda posterior (sobre los alphas seleccionados)\n",
    "alpha_best = df_tree_ccp.sort_values('CV Accuracy', ascending=False).iloc[0]['ccp_alpha']\n",
    "tree_ccp_best = DecisionTreeClassifier(ccp_alpha=float(alpha_best), random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit/eval\n",
    "tree_ccp_best.fit(X_train, y_train)\n",
    "y_pred_ccp = tree_ccp_best.predict(X_test)\n",
    "\n",
    "tree_pre_best = grid_tree.best_estimator_\n",
    "tree_pre_best.fit(X_train, y_train)\n",
    "y_pred_pre = tree_pre_best.predict(X_test)\n",
    "\n",
    "y_pred_full = tree_full.predict(X_test)\n",
    "\n",
    "df_tree_summary = pd.DataFrame([\n",
    "    {'Modelo': 'Sin restricciones', **metrics_row(y_test, y_pred_full),\n",
    "     'Profundidad': tree_full.get_depth(), 'Nº Hojas': tree_full.get_n_leaves()},\n",
    "    {'Modelo': 'Mejor poda previa', **metrics_row(y_test, y_pred_pre),\n",
    "     'Profundidad': tree_pre_best.get_depth(), 'Nº Hojas': tree_pre_best.get_n_leaves()},\n",
    "    {'Modelo': 'Mejor poda posterior', **metrics_row(y_test, y_pred_ccp),\n",
    "     'Profundidad': tree_ccp_best.get_depth(), 'Nº Hojas': tree_ccp_best.get_n_leaves()},\n",
    "]).sort_values('F1 (w)', ascending=False)\n",
    "\n",
    "df_tree_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "465267af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/tree_summary.tex')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_tree_summary, 'tree_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3ba0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_global = tree_pre_best  # por defecto, usamos el mejor pre-pruning\n",
    "y_pred_best_tree = best_tree_global.predict(X_test)\n",
    "plot_confusion(\n",
    "    y_test, y_pred_best_tree, class_names,\n",
    "    filename='confusion_matrix_tree.png',\n",
    "    title='Matriz de Confusión — Mejor Decision Tree'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2c5ba",
   "metadata": {},
   "source": [
    "**Análisis de resultados (Parte 2):**\n",
    "\n",
    "El árbol **sin restricciones** y la **poda posterior** obtienen el mismo Test Accuracy (92.89 %), pero la poda posterior logra resultados equivalentes con un árbol **más compacto** (profundidad 10, 74 hojas frente a profundidad 12, 101 hojas). La poda previa queda ligeramente por debajo (92.18 %), probablemente porque las restricciones de `min_samples_leaf` impiden capturar algunas divisiones finas que sí se modelan con el árbol completo.\n",
    "\n",
    "En general, los árboles de decisión individuales alcanzan un techo en torno al 93 % de accuracy en este dataset. La matriz de confusión revela que las categorías intermedias (Normal_Weight, Overweight_Level_I/II) son las más propensas a confusión, lo cual tiene sentido dado que comparten rangos de IMC cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c784ee8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Parte 3 — Random Forest y Extra Trees\n",
    "\n",
    "En esta sección pasamos de un único árbol de decisión a **métodos de ensemble** basados en *bagging*. La idea central de Random Forest es entrenar múltiples árboles de decisión sobre subconjuntos aleatorios de los datos (bootstrap) y de las features, y agregar sus predicciones por votación mayoritaria. Esta diversificación reduce la varianza del modelo sin aumentar significativamente el sesgo, lo que suele mejorar la generalización respecto a un árbol individual.\n",
    "\n",
    "Además de Random Forest, evaluaremos **Extra Trees** (Extremely Randomized Trees), una variante que introduce aún más aleatoriedad al elegir los umbrales de corte de forma aleatoria en lugar de buscar los óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace101a8",
   "metadata": {},
   "source": [
    "### 5.1 Random Forest por defecto\n",
    "\n",
    "Comenzamos entrenando un Random Forest con la configuración por defecto de scikit-learn (`n_estimators=100`, `max_features='sqrt'`), activando el **OOB score** (Out-of-Bag) como estimación del error de generalización sin necesidad de validación cruzada. Cada árbol se entrena sobre una muestra bootstrap (~63.2 % de los datos), y el OOB score se calcula evaluando cada muestra solo con los árboles que **no** la incluyeron en su bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85ff7e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuración</th>\n",
       "      <th>OOB Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF por defecto (n=100)</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>0.945498</td>\n",
       "      <td>0.946826</td>\n",
       "      <td>0.138665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Configuración  OOB Score  Test Accuracy    F1 (w)  Tiempo (s)\n",
       "0  RF por defecto (n=100)   0.941246       0.945498  0.946826    0.138665"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_default = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=RANDOM_STATE,\n",
    "    n_jobs=-1, oob_score=True\n",
    ")\n",
    "t0 = perf_counter()\n",
    "rf_default.fit(X_train, y_train)\n",
    "t_fit = perf_counter() - t0\n",
    "\n",
    "y_pred = rf_default.predict(X_test)\n",
    "m = metrics_row(y_test, y_pred)\n",
    "\n",
    "df_rf_default = pd.DataFrame([{\n",
    "    'Configuración': 'RF por defecto (n=100)',\n",
    "    'OOB Score': rf_default.oob_score_,\n",
    "    'Test Accuracy': m['Test Accuracy'],\n",
    "    'F1 (w)': m['F1 (w)'],\n",
    "    'Tiempo (s)': t_fit\n",
    "}])\n",
    "df_rf_default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2c0e66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_default.tex')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_default, 'rf_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624934a7",
   "metadata": {},
   "source": [
    "### 5.2 Efecto del número de estimadores\n",
    "\n",
    "El parámetro `n_estimators` controla cuántos árboles se combinan en el ensemble. Más árboles proporcionan predicciones más estables (menor varianza), pero con rendimientos decrecientes y mayor coste computacional. Entrenamos Random Forest con 10, 25, 50, 100, 200 y 500 árboles para observar la curva de convergencia tanto del OOB score como de la accuracy en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b4e701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\ensemble\\_forest.py:612: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>OOB Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.846884</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.036479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.908605</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>0.051969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.927596</td>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.074461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>0.945498</td>\n",
       "      <td>0.149437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.944214</td>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.270960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.947181</td>\n",
       "      <td>0.952607</td>\n",
       "      <td>0.626438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  OOB Score  Test Accuracy  Tiempo (s)\n",
       "0            10   0.846884       0.909953    0.036479\n",
       "1            25   0.908605       0.943128    0.051969\n",
       "2            50   0.927596       0.947867    0.074461\n",
       "3           100   0.941246       0.945498    0.149437\n",
       "4           200   0.944214       0.947867    0.270960\n",
       "5           500   0.947181       0.952607    0.626438"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for n in [10, 25, 50, 100, 200, 500]:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n, random_state=RANDOM_STATE, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "    t0 = perf_counter()\n",
    "    rf.fit(X_train, y_train)\n",
    "    t_fit = perf_counter() - t0\n",
    "\n",
    "    rows.append({\n",
    "        'n_estimators': n,\n",
    "        'OOB Score': rf.oob_score_,\n",
    "        'Test Accuracy': rf.score(X_test, y_test),\n",
    "        'Tiempo (s)': t_fit\n",
    "    })\n",
    "\n",
    "df_rf_n = pd.DataFrame(rows)\n",
    "df_rf_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b73eeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df_rf_n['n_estimators'], df_rf_n['OOB Score'], marker='o', label='OOB')\n",
    "ax.plot(df_rf_n['n_estimators'], df_rf_n['Test Accuracy'], marker='o', label='Test')\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Random Forest — Efecto de n_estimators')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "save_fig(IMAGES_DIR / 'rf_n_estimators_curve.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "682b4fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_n_estimators.tex')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_n, 'rf_n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be3c6c",
   "metadata": {},
   "source": [
    "Se observa una mejora rápida al pasar de 10 a 50 árboles (de 91.0 % a 94.8 % en test), con **rendimientos decrecientes** a partir de 100 árboles. Con 500 árboles alcanzamos 95.3 %, pero el tiempo de entrenamiento se multiplica por ×4.5 respecto a 100 árboles. El OOB score sigue una tendencia similar y converge hacia el 94.7 %, confirmando su fiabilidad como estimador del error de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51843eeb",
   "metadata": {},
   "source": [
    "### 5.3 Efecto de `max_features`\n",
    "\n",
    "El parámetro `max_features` determina cuántas features se consideran como candidatas en cada split. Valores más bajos (`'sqrt'`, `'log2'`) aumentan la diversidad entre árboles (decorrelación), mientras que usar todas las features (`None`) permite que cada árbol sea más preciso individualmente pero aumenta la correlación entre árboles.\n",
    "\n",
    "Comparamos cuatro opciones: `'sqrt'` ($\\approx 5$), `'log2'` ($\\approx 4$), `0.5` (la mitad = 11) y `None` (todas = 23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "155f7ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>OOB Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>0.954303</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log2</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>0.945498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>0.945498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max_features  OOB Score  Test Accuracy\n",
       "2          0.5   0.959644       0.954976\n",
       "3         None   0.954303       0.952607\n",
       "1         log2   0.941246       0.945498\n",
       "0         sqrt   0.941246       0.945498"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for mf in ['sqrt', 'log2', 0.5, None]:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, max_features=mf,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'max_features': str(mf),\n",
    "        'OOB Score': rf.oob_score_,\n",
    "        'Test Accuracy': rf.score(X_test, y_test),\n",
    "    })\n",
    "\n",
    "df_rf_mf = pd.DataFrame(rows).sort_values('Test Accuracy', ascending=False)\n",
    "df_rf_mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08e7d5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_max_features.tex')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_mf, 'rf_max_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90d561",
   "metadata": {},
   "source": [
    "Curiosamente, usar **la mitad de las features** (`0.5`, Test = 95.50 %) y **todas las features** (`None`, Test = 95.26 %) supera a las opciones clásicas `'sqrt'` y `'log2'` (94.55 %). Esto sugiere que nuestro dataset tiene pocas features realmente predictivas (Weight, Height) y necesitan estar disponibles en la mayoría de splits para maximizar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecacbc9",
   "metadata": {},
   "source": [
    "### 5.4 Grid Search (Random Forest)\n",
    "\n",
    "Realizamos una búsqueda exhaustiva combinando `n_estimators`, `max_features`, `max_depth` y `min_samples_leaf`. Mostramos las 10 mejores configuraciones ordenadas por CV Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "621a8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "Mejor CV score: 0.9519\n",
      "Test score: 0.9550\n",
      "Tiempo GridSearch: 11.588s\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators':     [100, 200],\n",
    "    'max_features':     ['sqrt', 'log2', None],\n",
    "    'max_depth':        [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "t0 = perf_counter()\n",
    "grid_rf.fit(X_train, y_train)\n",
    "t_grid = perf_counter() - t0\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_rf.best_params_)\n",
    "print(f\"Mejor CV score: {grid_rf.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_rf.best_estimator_.score(X_test, y_test):.4f}\")\n",
    "print(f\"Tiempo GridSearch: {t_grid:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f50c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>CV Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950742</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950742</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949555</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.948368</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.948368</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947774</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947181</td>\n",
       "      <td>0.959716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947181</td>\n",
       "      <td>0.959716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators max_features max_depth  min_samples_leaf    CV Acc  Test Acc\n",
       "0           200         None      None                 1  0.951929  0.954976\n",
       "1           200         None        20                 1  0.951929  0.954976\n",
       "2           100         None        20                 1  0.950742  0.952607\n",
       "3           100         None      None                 1  0.950742  0.952607\n",
       "4           200         None        10                 1  0.949555  0.952607\n",
       "5           200         None      None                 2  0.948368  0.957346\n",
       "6           200         None        20                 2  0.948368  0.957346\n",
       "7           100         None        10                 1  0.947774  0.957346\n",
       "8           100         None        20                 2  0.947181  0.959716\n",
       "9           100         None      None                 2  0.947181  0.959716"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres_rf = pd.DataFrame(grid_rf.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "top = cvres_rf.head(10)\n",
    "\n",
    "rows = []\n",
    "for _, r in top.iterrows():\n",
    "    params = {\n",
    "        'n_estimators': int(r['param_n_estimators']),\n",
    "        'max_features': r['param_max_features'],\n",
    "        'max_depth': r['param_max_depth'],\n",
    "        'min_samples_leaf': int(r['param_min_samples_leaf'])\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'max_features': str(params['max_features']),\n",
    "        'max_depth': 'None' if params['max_depth'] is None else int(params['max_depth']),\n",
    "        'min_samples_leaf': params['min_samples_leaf'],\n",
    "        'CV Acc': float(r['mean_test_score']),\n",
    "        'Test Acc': model.score(X_test, y_test),\n",
    "    })\n",
    "\n",
    "df_rf_grid = pd.DataFrame(rows)\n",
    "df_rf_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86b95ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_grid.tex')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_grid, 'rf_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50ef0c",
   "metadata": {},
   "source": [
    "### 5.5 Importancia de características (Gini vs Permutation)\n",
    "\n",
    "Calculamos la importancia de las features de dos maneras:\n",
    "\n",
    "1. **Gini importance** (*Mean Decrease Impurity*): suma de las reducciones de impureza Gini ponderadas por la probabilidad de alcanzar cada nodo, promediada sobre todos los árboles del bosque. Es rápida pero puede estar **sesgada hacia features de alta cardinalidad**.\n",
    "2. **Permutation importance**: mide cuánto cae la accuracy al permutar aleatoriamente los valores de una feature. Es más lenta pero más **robusta** y no tiene sesgos de cardinalidad.\n",
    "\n",
    "Comparamos ambas métricas para las 15 features más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24c3c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Gini Importance</th>\n",
       "      <th>Permutation Importance</th>\n",
       "      <th>Perm Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight</td>\n",
       "      <td>0.458525</td>\n",
       "      <td>0.738389</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.311611</td>\n",
       "      <td>0.015403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.158342</td>\n",
       "      <td>0.172038</td>\n",
       "      <td>0.013866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.038769</td>\n",
       "      <td>0.058057</td>\n",
       "      <td>0.007587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAVC</td>\n",
       "      <td>0.023532</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAF</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>-0.002133</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FCVC</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CH2O</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TUE</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCP</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CALC_no</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAEC_Frequently</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>0.002236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAEC_Sometimes</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CALC_Sometimes</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family_history_with_overweight</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature  Gini Importance  Permutation Importance  Perm Std\n",
       "3                           Weight         0.458525                0.738389  0.018725\n",
       "2                           Height         0.246338                0.311611  0.015403\n",
       "0                           Gender         0.158342                0.172038  0.013866\n",
       "1                              Age         0.038769                0.058057  0.007587\n",
       "5                             FAVC         0.023532                0.005687  0.002172\n",
       "11                             FAF         0.012838               -0.002133  0.002691\n",
       "6                             FCVC         0.009884               -0.000474  0.002552\n",
       "9                             CH2O         0.008880                0.002844  0.002763\n",
       "12                             TUE         0.008615                0.002133  0.002893\n",
       "7                              NCP         0.008572                0.004502  0.002691\n",
       "18                         CALC_no         0.004721               -0.001896  0.001422\n",
       "13                 CAEC_Frequently         0.004519               -0.002607  0.002236\n",
       "14                  CAEC_Sometimes         0.003825               -0.004502  0.001659\n",
       "17                  CALC_Sometimes         0.003181                0.000474  0.000948\n",
       "4   family_history_with_overweight         0.002385                0.001185  0.001590"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = grid_rf.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Gini importance\n",
    "gini_imp = pd.Series(best_rf.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# Permutation importance (más robusta)\n",
    "perm = permutation_importance(best_rf, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X_train.columns)\n",
    "perm_std = pd.Series(perm.importances_std, index=X_train.columns)\n",
    "\n",
    "df_rf_imp = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Gini Importance': gini_imp.values,\n",
    "    'Permutation Importance': perm_imp.values,\n",
    "    'Perm Std': perm_std.values\n",
    "}).sort_values('Gini Importance', ascending=False)\n",
    "\n",
    "df_rf_imp.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc9b30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = df_rf_imp.head(15).iloc[::-1]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(topk['Feature'], topk['Gini Importance'])\n",
    "ax.set_xlabel('Gini Importance')\n",
    "ax.set_title('Random Forest — Importancia de características (top 15)')\n",
    "save_fig(IMAGES_DIR / 'rf_feature_importance_gini.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0112b00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_importances.tex')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_imp.head(25), 'rf_importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b7cb3",
   "metadata": {},
   "source": [
    "### 5.6 Extra Trees (Extremely Randomized Trees)\n",
    "\n",
    "**Extra Trees** difiere de Random Forest en dos aspectos clave:\n",
    "- No usa *bootstrap* (se entrena con todo el dataset).\n",
    "- Los **umbrales de corte se eligen al azar** en lugar de buscarse óptimamente.\n",
    "\n",
    "Esta mayor aleatoriedad puede reducir aún más la varianza, aunque a costa de mayor sesgo. Suele funcionar bien en datasets donde Random Forest ya obtiene buenos resultados, pero no siempre mejora la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d73ac764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees (n=100)</td>\n",
       "      <td>0.91632</td>\n",
       "      <td>0.92654</td>\n",
       "      <td>0.927715</td>\n",
       "      <td>0.087105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  CV Accuracy  Test Accuracy    F1 (w)  Tiempo (s)\n",
       "0  Extra Trees (n=100)      0.91632        0.92654  0.927715    0.087105"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "cv_et = cross_val_score(et, X_train, y_train, cv=5, scoring='accuracy')\n",
    "t0 = perf_counter()\n",
    "et.fit(X_train, y_train)\n",
    "t_fit = perf_counter() - t0\n",
    "\n",
    "y_pred = et.predict(X_test)\n",
    "m = metrics_row(y_test, y_pred)\n",
    "\n",
    "df_et = pd.DataFrame([{\n",
    "    'Modelo': 'Extra Trees (n=100)',\n",
    "    'CV Accuracy': cv_et.mean(),\n",
    "    'Test Accuracy': m['Test Accuracy'],\n",
    "    'F1 (w)': m['F1 (w)'],\n",
    "    'Tiempo (s)': t_fit\n",
    "}])\n",
    "df_et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c3f9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/extra_trees.tex')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_et, 'extra_trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6845dff",
   "metadata": {},
   "source": [
    "### 5.7 Evaluación final (Parte 3)\n",
    "\n",
    "Comparamos todos los modelos basados en bagging junto con el árbol de decisión baseline como referencia. Incluimos Test Accuracy, F1 ponderado y OOB Score (cuando está disponible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "541265e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision (w)</th>\n",
       "      <th>Recall (w)</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>OOB Score</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest mejor config</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.956814</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.955283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest por defecto</td>\n",
       "      <td>0.945498</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.945498</td>\n",
       "      <td>0.946826</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree (baseline)</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.932683</td>\n",
       "      <td>0.928910</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>0.932466</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>0.927715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Modelo  Test Accuracy  Precision (w)  Recall (w)    F1 (w)  OOB Score  Tiempo (s)\n",
       "2  Random Forest mejor config       0.954976       0.956814    0.954976  0.955283        NaN         NaN\n",
       "1   Random Forest por defecto       0.945498       0.952690    0.945498  0.946826   0.941246         NaN\n",
       "0    Decision Tree (baseline)       0.928910       0.932683    0.928910  0.929719        NaN         NaN\n",
       "3                 Extra Trees       0.926540       0.932466    0.926540  0.927715        NaN         NaN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen comparativo Parte 3\n",
    "# (Incluye baseline del árbol para referencia)\n",
    "\n",
    "tree_baseline_test = tree_full.predict(X_test)\n",
    "rf_default_pred = rf_default.predict(X_test)\n",
    "rf_best_pred = best_rf.predict(X_test)\n",
    "et_pred = et.predict(X_test)\n",
    "\n",
    "df_rf_summary = pd.DataFrame([\n",
    "    {'Modelo': 'Decision Tree (baseline)',\n",
    "     **metrics_row(y_test, tree_baseline_test),\n",
    "     'OOB Score': np.nan, 'Tiempo (s)': np.nan},\n",
    "    {'Modelo': 'Random Forest por defecto',\n",
    "     **metrics_row(y_test, rf_default_pred),\n",
    "     'OOB Score': rf_default.oob_score_, 'Tiempo (s)': np.nan},\n",
    "    {'Modelo': 'Random Forest mejor config',\n",
    "     **metrics_row(y_test, rf_best_pred),\n",
    "     'OOB Score': getattr(best_rf, 'oob_score_', np.nan), 'Tiempo (s)': np.nan},\n",
    "    {'Modelo': 'Extra Trees',\n",
    "     **metrics_row(y_test, et_pred),\n",
    "     'OOB Score': np.nan, 'Tiempo (s)': np.nan},\n",
    "]).sort_values('F1 (w)', ascending=False)\n",
    "\n",
    "df_rf_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8ec230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/rf_summary.tex')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_rf_summary, 'rf_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29b5d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión del mejor modelo de la parte (por F1)\n",
    "best_part3_name = df_rf_summary.iloc[0]['Modelo']\n",
    "if best_part3_name == 'Random Forest mejor config':\n",
    "    y_pred_best = rf_best_pred\n",
    "elif best_part3_name == 'Random Forest por defecto':\n",
    "    y_pred_best = rf_default_pred\n",
    "elif best_part3_name == 'Extra Trees':\n",
    "    y_pred_best = et_pred\n",
    "else:\n",
    "    y_pred_best = tree_baseline_test\n",
    "\n",
    "plot_confusion(\n",
    "    y_test, y_pred_best, class_names,\n",
    "    filename='confusion_matrix_rf.png',\n",
    "    title=f'Matriz de Confusión — Mejor modelo Parte 3: {best_part3_name}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5dc576",
   "metadata": {},
   "source": [
    "**Análisis de resultados (Parte 3):**\n",
    "\n",
    "El **Random Forest con la mejor configuración** (200 árboles, todas las features, sin límite de profundidad) alcanza un **95.50 % de Test Accuracy**, una mejora sustancial respecto al mejor árbol individual (92.89 %). Esto confirma el beneficio del ensemble: la agregación de múltiples árboles reduce la varianza y suaviza los errores individuales.\n",
    "\n",
    "Resulta interesante que **usar todas las features** (`max_features=None`) supere a `'sqrt'` y `'log2'`. Esto podría deberse a que nuestro dataset tiene solo 23 features y las dos más predictivas (Weight, Height) necesitan estar disponibles en cada split para un rendimiento óptimo.\n",
    "\n",
    "**Extra Trees** (92.65 %) rinde por debajo del Random Forest estándar. La aleatorización extra en los umbrales no aporta beneficio aquí, probablemente porque el dataset no es tan ruidoso como para que la reducción de varianza adicional compense el aumento de sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823283f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Parte 4 — Gradient Boosting y AdaBoost\n",
    "\n",
    "A diferencia del *bagging* (Random Forest), los métodos de **boosting** construyen el ensemble de forma **secuencial**: cada nuevo estimador se entrena para corregir los errores del anterior. En esta sección evaluamos dos algoritmos de boosting:\n",
    "\n",
    "- **Gradient Boosting** (`GradientBoostingClassifier`): ajusta cada árbol al *gradiente negativo* de la función de pérdida. Permite árboles de profundidad moderada y ofrece control fino mediante `learning_rate`, `n_estimators`, `max_depth` y `subsample`.\n",
    "- **AdaBoost** (`AdaBoostClassifier`): aumenta el peso de las muestras mal clasificadas en cada iteración. Clásicamente utiliza *stumps* (árboles de profundidad 1) como estimadores base.\n",
    "\n",
    "Veremos que Gradient Boosting es especialmente potente para este dataset, mientras que AdaBoost con stumps resulta insuficiente para un problema de 7 clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b65014",
   "metadata": {},
   "source": [
    "### 6.1 Gradient Boosting por defecto\n",
    "\n",
    "Entrenamos un `GradientBoostingClassifier` con los parámetros por defecto de scikit-learn (`n_estimators=100`, `learning_rate=0.1`, `max_depth=3`). A diferencia de Random Forest, Gradient Boosting **no admite paralelización** (los árboles se entrenan secuencialmente), por lo que el tiempo de entrenamiento será significativamente mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "485cefde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting (default)</td>\n",
       "      <td>0.95727</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.967405</td>\n",
       "      <td>2.086784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  CV Accuracy  Test Accuracy    F1 (w)  Tiempo (s)\n",
       "0  Gradient Boosting (default)      0.95727       0.966825  0.967405    2.086784"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_default = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "cv_gb = cross_val_score(gb_default, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "t0 = perf_counter()\n",
    "gb_default.fit(X_train, y_train)\n",
    "t_fit = perf_counter() - t0\n",
    "\n",
    "y_pred = gb_default.predict(X_test)\n",
    "m = metrics_row(y_test, y_pred)\n",
    "\n",
    "df_gb_default = pd.DataFrame([{\n",
    "    'Modelo': 'Gradient Boosting (default)',\n",
    "    'CV Accuracy': cv_gb.mean(),\n",
    "    'Test Accuracy': m['Test Accuracy'],\n",
    "    'F1 (w)': m['F1 (w)'],\n",
    "    'Tiempo (s)': t_fit\n",
    "}])\n",
    "df_gb_default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2c97aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/gb_default.tex')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_gb_default, 'gb_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0e0a7",
   "metadata": {},
   "source": [
    "### 6.2 Efecto de `n_estimators` y `learning_rate`\n",
    "\n",
    "Existe un **trade-off** clásico entre estos dos parámetros: un `learning_rate` bajo necesita más estimadores para converger, pero suele generalizar mejor (cada árbol contribuye poco, evitando saltos bruscos). Un `learning_rate` alto converge rápido pero puede sobreajustar.\n",
    "\n",
    "Probamos varias combinaciones para explorar este equilibrio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14f5bb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.971564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.957864</td>\n",
       "      <td>0.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.943128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.945498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>0.900474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  CV Accuracy  Test Accuracy\n",
       "2           200           0.10     0.959644       0.971564\n",
       "3            50           0.50     0.957864       0.954976\n",
       "1           100           0.10     0.957270       0.966825\n",
       "0            50           0.10     0.945401       0.943128\n",
       "4           100           0.05     0.943027       0.945498\n",
       "5           200           0.01     0.906825       0.900474"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = [\n",
    "    (50,  0.1), (100, 0.1), (200, 0.1),\n",
    "    (50,  0.5), (100, 0.05), (200, 0.01)\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for n_est, lr in configs:\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=n_est, learning_rate=lr, random_state=RANDOM_STATE\n",
    "    )\n",
    "    cv = cross_val_score(gb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    gb.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'n_estimators': n_est,\n",
    "        'learning_rate': lr,\n",
    "        'CV Accuracy': cv.mean(),\n",
    "        'Test Accuracy': gb.score(X_test, y_test)\n",
    "    })\n",
    "\n",
    "df_gb_nlr = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_gb_nlr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d8f55d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/gb_n_lr.tex')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_gb_nlr, 'gb_n_lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839b40d",
   "metadata": {},
   "source": [
    "La combinación `(n_estimators=200, learning_rate=0.1)` lidera con un **CV = 95.96 % y Test = 97.16 %**. Reducir el learning_rate a 0.01 con solo 200 árboles resulta insuficiente (90.07 %): el modelo no ha convergido porque necesitaría muchos más estimadores. Un learning_rate alto (0.5) con pocos árboles (50) ofrece un buen compromiso rápido pero no alcanza el rendimiento máximo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dce41",
   "metadata": {},
   "source": [
    "### 6.3 Efecto de `max_depth`\n",
    "\n",
    "En Gradient Boosting, `max_depth` controla la complejidad de cada árbol individual. A diferencia de Random Forest (donde los árboles suelen ser profundos), en boosting se prefieren **árboles poco profundos** (3–5 niveles) porque el propio proceso iterativo se encarga de capturar interacciones complejas.\n",
    "\n",
    "Árboles con `max_depth=1` (stumps) solo capturan efectos principales. Con `max_depth=3` se modelan interacciones de hasta 3 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5cd0d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956083</td>\n",
       "      <td>0.959716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.990504</td>\n",
       "      <td>0.938872</td>\n",
       "      <td>0.940758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.878932</td>\n",
       "      <td>0.843917</td>\n",
       "      <td>0.841232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  Train Acc  CV Accuracy  Test Accuracy\n",
       "2          3   1.000000     0.957270       0.966825\n",
       "3          5   1.000000     0.956083       0.959716\n",
       "1          2   0.990504     0.938872       0.940758\n",
       "0          1   0.878932     0.843917       0.841232"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for depth in [1, 2, 3, 5]:\n",
    "    gb = GradientBoostingClassifier(\n",
    "        max_depth=depth, n_estimators=100, learning_rate=0.1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    cv = cross_val_score(gb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    gb.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        'max_depth': depth,\n",
    "        'Train Acc': gb.score(X_train, y_train),\n",
    "        'CV Accuracy': cv.mean(),\n",
    "        'Test Accuracy': gb.score(X_test, y_test),\n",
    "    })\n",
    "\n",
    "df_gb_depth = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_gb_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "608366c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(df_gb_depth['max_depth'], df_gb_depth['Train Acc'], marker='o', label='Train')\n",
    "ax.plot(df_gb_depth['max_depth'], df_gb_depth['CV Accuracy'], marker='o', label='CV')\n",
    "ax.plot(df_gb_depth['max_depth'], df_gb_depth['Test Accuracy'], marker='o', label='Test')\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Gradient Boosting — Efecto de max_depth')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "save_fig(IMAGES_DIR / 'gb_depth_curve.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1588b1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/gb_depth.tex')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_gb_depth, 'gb_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04d447",
   "metadata": {},
   "source": [
    "Con `max_depth=3` se obtiene el mejor CV (95.73 %) y test (96.68 %). Profundidades mayores (`max_depth=5`) alcanzan 100 % en train pero la CV y test empiezan a descender ligeramente, indicando **sobreajuste incipiente**. Los stumps (`max_depth=1`) solo alcanzan 84.4 %, confirmando que se necesitan interacciones entre variables para clasificar correctamente las 7 categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f61477",
   "metadata": {},
   "source": [
    "### 6.4 Grid Search (Gradient Boosting)\n",
    "\n",
    "Combinamos `n_estimators`, `learning_rate`, `max_depth` y `subsample` en una búsqueda exhaustiva. El parámetro `subsample < 1.0` introduce *stochastic gradient boosting*, donde cada árbol se entrena con una fracción aleatoria de los datos, lo que puede mejorar la generalización y reducir el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd456e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Mejor CV score: 0.9596\n",
      "Test score: 0.9716\n",
      "Tiempo GridSearch: 44.456s\n"
     ]
    }
   ],
   "source": [
    "param_grid_gb = {\n",
    "    'n_estimators':  [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
    "    'max_depth':     [1, 2, 3],\n",
    "    'subsample':     [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "t0 = perf_counter()\n",
    "grid_gb.fit(X_train, y_train)\n",
    "t_grid = perf_counter() - t0\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_gb.best_params_)\n",
    "print(f\"Mejor CV score: {grid_gb.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_gb.best_estimator_.score(X_test, y_test):.4f}\")\n",
    "print(f\"Tiempo GridSearch: {t_grid:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a68a1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>CV Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.971564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.962085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.962085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.957864</td>\n",
       "      <td>0.969194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957864</td>\n",
       "      <td>0.959716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>0.945498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957270</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956677</td>\n",
       "      <td>0.962085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.956083</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  max_depth  subsample    CV Acc  Test Acc\n",
       "0           200           0.10          3        1.0  0.959644  0.971564\n",
       "1           200           0.50          3        0.8  0.958457  0.957346\n",
       "2           200           0.50          3        1.0  0.958457  0.962085\n",
       "3           200           0.10          3        0.8  0.958457  0.962085\n",
       "4           100           0.50          3        0.8  0.957864  0.969194\n",
       "5           200           0.05          3        1.0  0.957864  0.959716\n",
       "6           200           0.05          3        0.8  0.957270  0.945498\n",
       "7           100           0.10          3        1.0  0.957270  0.966825\n",
       "8           100           0.50          3        1.0  0.956677  0.962085\n",
       "9           100           0.10          3        0.8  0.956083  0.952607"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres_gb = pd.DataFrame(grid_gb.cv_results_).sort_values('mean_test_score', ascending=False).head(10)\n",
    "\n",
    "rows = []\n",
    "for _, r in cvres_gb.iterrows():\n",
    "    params = {\n",
    "        'n_estimators': int(r['param_n_estimators']),\n",
    "        'learning_rate': float(r['param_learning_rate']),\n",
    "        'max_depth': int(r['param_max_depth']),\n",
    "        'subsample': float(r['param_subsample'])\n",
    "    }\n",
    "    model = GradientBoostingClassifier(random_state=RANDOM_STATE, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    rows.append({\n",
    "        **params,\n",
    "        'CV Acc': float(r['mean_test_score']),\n",
    "        'Test Acc': model.score(X_test, y_test),\n",
    "    })\n",
    "\n",
    "df_gb_grid = pd.DataFrame(rows)\n",
    "df_gb_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96b9c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/gb_grid.tex')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_gb_grid, 'gb_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26bec60",
   "metadata": {},
   "source": [
    "### 6.5 AdaBoost (stumps)\n",
    "\n",
    "AdaBoost con *decision stumps* (`max_depth=1`) es un clasificador de boosting clásico. Cada stump solo puede usar **una feature y un umbral**, lo que lo convierte en un clasificador extremadamente débil. AdaBoost pondera las muestras según si fueron bien o mal clasificadas, forzando a los nuevos stumps a enfocarse en los ejemplos difíciles.\n",
    "\n",
    "> **Nota**: Para un problema multiclase con 7 categorías, los stumps son demasiado simples como estimadores base. Esperamos resultados pobres comparados con Gradient Boosting, que usa árboles más profundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0539cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468843</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.197057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.467656</td>\n",
       "      <td>0.497630</td>\n",
       "      <td>0.194547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>0.433649</td>\n",
       "      <td>0.385678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.421801</td>\n",
       "      <td>0.096884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  CV Accuracy  Test Accuracy  Tiempo (s)\n",
       "1           100            1.0     0.468843       0.407583    0.197057\n",
       "2           100            0.5     0.467656       0.497630    0.194547\n",
       "3           200            0.1     0.455786       0.433649    0.385678\n",
       "0            50            1.0     0.439169       0.421801    0.096884"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_adaboost(n_estimators: int, learning_rate: float) -> AdaBoostClassifier:\n",
    "    \"\"\"Compatibilidad sklearn: estimator (nuevo) vs base_estimator (antiguo).\"\"\"\n",
    "    stump = DecisionTreeClassifier(max_depth=1, random_state=RANDOM_STATE)\n",
    "    try:\n",
    "        return AdaBoostClassifier(\n",
    "            estimator=stump,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    except TypeError:\n",
    "        return AdaBoostClassifier(\n",
    "            base_estimator=stump,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "ada_configs = [\n",
    "    (50,  1.0),\n",
    "    (100, 1.0),\n",
    "    (100, 0.5),\n",
    "    (200, 0.1)\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for n_est, lr in ada_configs:\n",
    "    ada = make_adaboost(n_est, lr)\n",
    "    cv = cross_val_score(ada, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    t0 = perf_counter()\n",
    "    ada.fit(X_train, y_train)\n",
    "    t_fit = perf_counter() - t0\n",
    "    rows.append({\n",
    "        'n_estimators': n_est,\n",
    "        'learning_rate': lr,\n",
    "        'CV Accuracy': cv.mean(),\n",
    "        'Test Accuracy': ada.score(X_test, y_test),\n",
    "        'Tiempo (s)': t_fit\n",
    "    })\n",
    "\n",
    "df_ada = pd.DataFrame(rows).sort_values('CV Accuracy', ascending=False)\n",
    "df_ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb364bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/adaboost.tex')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_ada, 'adaboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0072d",
   "metadata": {},
   "source": [
    "### 6.6 Evaluación final (Parte 4)\n",
    "\n",
    "Comparamos los modelos de boosting (GB default, GB mejor configuración y AdaBoost) junto con el mejor Random Forest como referencia. Incluimos la matriz de confusión del mejor modelo de esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dce3133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision (w)</th>\n",
       "      <th>Recall (w)</th>\n",
       "      <th>F1 (w)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting (mejor config)</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.974512</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting (default)</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.967405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (mejor config)</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.956814</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.955283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost (mejor config)</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.375229</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.380158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Modelo  Test Accuracy  Precision (w)  Recall (w)    F1 (w)\n",
       "2  Gradient Boosting (mejor config)       0.971564       0.974512    0.971564  0.971800\n",
       "1       Gradient Boosting (default)       0.966825       0.971119    0.966825  0.967405\n",
       "0      Random Forest (mejor config)       0.954976       0.956814    0.954976  0.955283\n",
       "3           AdaBoost (mejor config)       0.407583       0.375229    0.407583  0.380158"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb = grid_gb.best_estimator_\n",
    "best_gb.fit(X_train, y_train)\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "\n",
    "best_ada_params = df_ada.iloc[0][['n_estimators','learning_rate']].to_dict()\n",
    "best_ada = make_adaboost(int(best_ada_params['n_estimators']), float(best_ada_params['learning_rate']))\n",
    "best_ada.fit(X_train, y_train)\n",
    "y_pred_ada = best_ada.predict(X_test)\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "df_gb_summary = pd.DataFrame([\n",
    "    {'Modelo': 'Random Forest (mejor config)', **metrics_row(y_test, y_pred_rf)},\n",
    "    {'Modelo': 'Gradient Boosting (default)', **metrics_row(y_test, gb_default.predict(X_test))},\n",
    "    {'Modelo': 'Gradient Boosting (mejor config)', **metrics_row(y_test, y_pred_gb)},\n",
    "    {'Modelo': 'AdaBoost (mejor config)', **metrics_row(y_test, y_pred_ada)},\n",
    "]).sort_values('F1 (w)', ascending=False)\n",
    "\n",
    "df_gb_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd6bc703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/gb_summary.tex')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_gb_summary, 'gb_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a55e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_part4_name = df_gb_summary.iloc[0]['Modelo']\n",
    "if best_part4_name == 'Gradient Boosting (mejor config)':\n",
    "    y_pred_best = y_pred_gb\n",
    "elif best_part4_name == 'AdaBoost (mejor config)':\n",
    "    y_pred_best = y_pred_ada\n",
    "elif best_part4_name == 'Gradient Boosting (default)':\n",
    "    y_pred_best = gb_default.predict(X_test)\n",
    "else:\n",
    "    y_pred_best = y_pred_rf\n",
    "\n",
    "plot_confusion(\n",
    "    y_test, y_pred_best, class_names,\n",
    "    filename='confusion_matrix_gb.png',\n",
    "    title=f'Matriz de Confusión — Mejor modelo Parte 4: {best_part4_name}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c97bc",
   "metadata": {},
   "source": [
    "**Análisis de resultados (Parte 4):**\n",
    "\n",
    "**Gradient Boosting** domina claramente esta sección con un **97.16 % de Test Accuracy** (F1 = 0.9718), superando tanto al GB por defecto (96.68 %) como al mejor Random Forest (95.50 %). La estrategia de boosting — construir árboles secuenciales que corrigen los errores del anterior — resulta especialmente eficaz en este dataset.\n",
    "\n",
    "Los parámetros óptimos son `learning_rate=0.1`, `max_depth=3` y `n_estimators=200`, confirmando que **árboles poco profundos combinados con muchas iteraciones** es la receta clásica de Gradient Boosting.\n",
    "\n",
    "**AdaBoost con stumps** fracasa estrepitosamente (≈ 47 % CV, 40 % test), lo cual era previsible: un stump solo puede dividir el espacio con un único corte, totalmente insuficiente para discriminar entre 7 clases de obesidad. En un problema binario, AdaBoost con stumps puede funcionar razonablemente, pero el salto a 7 clases lo vuelve inviable con estimadores tan débiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4508b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Comparación global de mejores modelos\n",
    "\n",
    "Finalmente, seleccionamos el **mejor modelo de cada parte** y los enfrentamos en una comparación directa. Para cada modelo calculamos CV Accuracy (5-fold), Test Accuracy, Precision, Recall, F1 ponderado y tiempo de entrenamiento. Esto nos permite evaluar no solo la calidad predictiva sino también el coste computacional de cada enfoque.\n",
    "\n",
    "Los modelos seleccionados son:\n",
    "- **SVM (best RBF)**: Pipeline con StandardScaler + SVC(kernel='rbf', C=100, gamma=0.01)\n",
    "- **Decision Tree (best pre-pruning)**: mejor configuración por GridSearchCV\n",
    "- **Random Forest (best)**: 200 árboles, todas las features, sin límite de profundidad\n",
    "- **Gradient Boosting (best)**: lr=0.1, max_depth=3, n_estimators=200, subsample=1.0\n",
    "- **AdaBoost (best)**: incluido para contrastar su bajo rendimiento con stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9adb3a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>CV Std</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision (w)</th>\n",
       "      <th>Recall (w)</th>\n",
       "      <th>F1 (w)</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting (best)</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.974512</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>4.069379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (best)</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.956814</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.955283</td>\n",
       "      <td>0.239856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (best RBF)</td>\n",
       "      <td>0.940059</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.943128</td>\n",
       "      <td>0.943202</td>\n",
       "      <td>0.040027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (best pre-pruning)</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.925161</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.922354</td>\n",
       "      <td>0.006653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost (best)</td>\n",
       "      <td>0.468843</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.375229</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.380158</td>\n",
       "      <td>0.193457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Modelo  CV Accuracy    CV Std  Test Accuracy  Precision (w)  Recall (w)    F1 (w)  Tiempo (s)\n",
       "3          Gradient Boosting (best)     0.959644  0.013083       0.971564       0.974512    0.971564  0.971800    4.069379\n",
       "2              Random Forest (best)     0.951929  0.016828       0.954976       0.956814    0.954976  0.955283    0.239856\n",
       "0                    SVM (best RBF)     0.940059  0.018234       0.943128       0.943953    0.943128  0.943202    0.040027\n",
       "1  Decision Tree (best pre-pruning)     0.928783  0.012589       0.921801       0.925161    0.921801  0.922354    0.006653\n",
       "4                   AdaBoost (best)     0.468843  0.027836       0.407583       0.375229    0.407583  0.380158    0.193457"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionamos mejores modelos por bloque\n",
    "best_models = {\n",
    "    'SVM (best RBF)': grid_rbf.best_estimator_,\n",
    "    'Decision Tree (best pre-pruning)': grid_tree.best_estimator_,\n",
    "    'Random Forest (best)': grid_rf.best_estimator_,\n",
    "    'Gradient Boosting (best)': grid_gb.best_estimator_,\n",
    "    'AdaBoost (best)': best_ada,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in best_models.items():\n",
    "    # CV accuracy\n",
    "    cv = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean, cv_std = cv.mean(), cv.std()\n",
    "\n",
    "    # Fit time\n",
    "    t0 = perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = perf_counter() - t0\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    m = metrics_row(y_test, y_pred)\n",
    "\n",
    "    rows.append({\n",
    "        'Modelo': name,\n",
    "        'CV Accuracy': cv_mean,\n",
    "        'CV Std': cv_std,\n",
    "        **m,\n",
    "        'Tiempo (s)': fit_time\n",
    "    })\n",
    "\n",
    "df_final = pd.DataFrame(rows).sort_values('F1 (w)', ascending=False)\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de700e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jordi/Documents/UNI/IA/3erAnyo/2doCuatri/aprendizaje_avanzado/practicas/practica_1/tables/final_comparison.tex')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table(df_final[['Modelo','CV Accuracy','Test Accuracy','Precision (w)','Recall (w)','F1 (w)','Tiempo (s)']], 'final_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97c904b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo global: Gradient Boosting (best)\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       1.00      0.91      0.95        54\n",
      "      Normal_Weight       0.86      1.00      0.93        57\n",
      "     Obesity_Type_I       0.99      0.99      0.99        70\n",
      "    Obesity_Type_II       0.98      0.98      0.98        60\n",
      "   Obesity_Type_III       1.00      1.00      1.00        65\n",
      " Overweight_Level_I       1.00      0.91      0.95        58\n",
      "Overweight_Level_II       0.98      1.00      0.99        58\n",
      "\n",
      "           accuracy                           0.97       422\n",
      "          macro avg       0.97      0.97      0.97       422\n",
      "       weighted avg       0.97      0.97      0.97       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_name = df_final.iloc[0]['Modelo']\n",
    "best_model = best_models[best_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print('Mejor modelo global:', best_name)\n",
    "print(classification_report(y_test, y_pred_best, target_names=class_names))\n",
    "\n",
    "plot_confusion(\n",
    "    y_test, y_pred_best, class_names,\n",
    "    filename='confusion_matrix_final.png',\n",
    "    title=f'Matriz de Confusión — Mejor modelo global: {best_name}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacfa86",
   "metadata": {},
   "source": [
    "**Análisis global y conclusiones:**\n",
    "\n",
    "El ranking final confirma que **Gradient Boosting** es el mejor modelo para este dataset, con un **97.16 % de Test Accuracy** y un F1 ponderado de 0.9718. Le sigue **Random Forest** con 95.50 %, luego **SVM (RBF)** con 94.31 %, **Decision Tree** con 92.18 % y finalmente **AdaBoost** con un rendimiento muy pobre (40.76 %).\n",
    "\n",
    "Observaciones clave:\n",
    "\n",
    "1. **La complejidad del ensemble importa**: de un árbol individual (92 %) a un bosque (95 %) y a boosting (97 %), cada nivel de sofisticación mejora el rendimiento.\n",
    "2. **SVM es competitivo** con un 94 % sin ser ensemble, pero requiere un escalado cuidadoso y es más lento de optimizar.\n",
    "3. **AdaBoost con stumps no es viable** para problemas multiclase complejos. Sería necesario usar estimadores base más profundos para que fuera competitivo.\n",
    "4. **El classification report** muestra que Obesity_Type_III alcanza F1 = 1.00 (perfectamente separable), mientras que las categorías con mayor confusión son Normal_Weight e Insufficient_Weight, que comparten rangos de peso similares.\n",
    "5. **Trade-off tiempo/rendimiento**: SVM es el más rápido de los buenos modelos (0.04s), mientras que GB necesita 4s. Para este dataset la diferencia es negligible, pero en producción podría ser relevante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
