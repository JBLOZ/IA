{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from PIL import Image\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PracticaCPUvsGPU:\n",
    "    def __init__(self, debug: bool = True):\n",
    "        \"\"\"\n",
    "        Inicializa la práctica.\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        if not self.debug:\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        \n",
    "        # Configurar logging según la variable debug\n",
    "        if self.debug:\n",
    "            logging.basicConfig(level=logging.DEBUG,\n",
    "                                format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.WARNING,\n",
    "                                format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "        logging.debug(\"GPU disponible (inicial): %s\", torch.cuda.is_available())\n",
    "        logging.debug(\"Número de GPUs (inicial): %s\", torch.cuda.device_count())\n",
    "    \n",
    "        # Definir las resoluciones a comparar\n",
    "        self.resoluciones = [(224, 224), (512, 512), (1024, 1024)]\n",
    "        \n",
    "        # Cargar el modelo ResNet18 para CPU y establecerlo en modo evaluación\n",
    "\n",
    "        self.model_cpu = models.resnet18(pretrained=True)\n",
    "        self.model_cpu.eval()\n",
    "        \n",
    "        # Verificar GPU y cargar modelo en GPU si aparece disponible\n",
    "        self.gpu_disponible = torch.cuda.is_available()\n",
    "        if self.gpu_disponible:\n",
    "            self.model_gpu = models.resnet18(pretrained=True).to('cuda')\n",
    "            self.model_gpu.eval()\n",
    "        else:\n",
    "            self.model_gpu = None\n",
    "        \n",
    "        # Directorio donde se encuentran las imágenes\n",
    "        self.imagenes_dir = \"Fotos ejemplo\"\n",
    "        # Lista de rutas de imagen (Foto facial 1.jpg a Foto facial 5.jpg)\n",
    "        self.image_paths = [os.path.join(self.imagenes_dir, f\"Foto facial {i}.jpg\") for i in range(1, 6)]\n",
    "    \n",
    "    def run_measurements(self):\n",
    "        \"\"\"\n",
    "        Recorre las imágenes y mide los tiempos de ejecución sobre CPU y GPU (si está disponible),\n",
    "        registrando los resultados mediante logging.\n",
    "        \"\"\"\n",
    "        for path in self.image_paths:\n",
    "            try:\n",
    "                image = Image.open(path)\n",
    "            except Exception as e:\n",
    "                logging.error(\"Error al abrir la imagen %s: %s\", path, e)\n",
    "                continue\n",
    "\n",
    "            for res in self.resoluciones:\n",
    "                # Definir la transformación para la resolución actual\n",
    "                transform_res = transforms.Compose([\n",
    "                    transforms.Resize(res),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "    \n",
    "                # Convertir la imagen a tensor y añadir dimensión batch\n",
    "                input_tensor = transform_res(image).unsqueeze(0)\n",
    "    \n",
    "                # Medición en CPU\n",
    "                start_cpu = time.time()\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model_cpu(input_tensor)\n",
    "                tiempo_cpu = time.time() - start_cpu\n",
    "    \n",
    "                resultado = f\"Imagen: {path} | Tamaño: {res[0]}x{res[1]} | Tiempo en CPU: {tiempo_cpu:.4f} segundos\"\n",
    "    \n",
    "                # Medición en GPU si está disponible\n",
    "                if self.gpu_disponible:\n",
    "                    input_tensor_gpu = input_tensor.to('cuda')\n",
    "                    start_gpu = time.time()\n",
    "                    with torch.no_grad():\n",
    "                        _ = self.model_gpu(input_tensor_gpu)\n",
    "                    torch.cuda.synchronize()  # Asegurarse de que la GPU finalice la operación\n",
    "                    tiempo_gpu = time.time() - start_gpu\n",
    "                    resultado += f\" | Tiempo en GPU: {tiempo_gpu:.4f} segundos\"\n",
    "                else:\n",
    "                    resultado += \" | GPU no disponible.\"\n",
    "    \n",
    "                logging.info(resultado)\n",
    "    \n",
    "    def generar_tabla_markdown(self) -> str:\n",
    "        \"\"\"\n",
    "        Genera una tabla en formato Markdown con los tiempos de ejecución en CPU y GPU.\n",
    "        \n",
    "        Returns:\n",
    "            Una cadena con la tabla Markdown.\n",
    "        \"\"\"\n",
    "        table_lines = []\n",
    "        # Cabecera de la tabla Markdown\n",
    "        table_lines.append(\"| Imagen | Tamaño | Tiempo CPU (s) | Tiempo GPU (s) |\")\n",
    "        table_lines.append(\"|--------|--------|----------------|----------------|\")\n",
    "    \n",
    "        for path in self.image_paths:\n",
    "            try:\n",
    "                image = Image.open(path)\n",
    "            except Exception as e:\n",
    "                table_lines.append(f\"| {path} | Error al abrir imagen: {e} | - | - |\")\n",
    "                continue\n",
    "    \n",
    "            for res in self.resoluciones:\n",
    "                transform_res = transforms.Compose([\n",
    "                    transforms.Resize(res),\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "                input_tensor = transform_res(image).unsqueeze(0)\n",
    "                start_cpu = time.time()\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model_cpu(input_tensor)\n",
    "                tiempo_cpu = time.time() - start_cpu\n",
    "    \n",
    "                if self.gpu_disponible:\n",
    "                    input_tensor_gpu = input_tensor.to('cuda')\n",
    "                    start_gpu = time.time()\n",
    "                    with torch.no_grad():\n",
    "                        _ = self.model_gpu(input_tensor_gpu)\n",
    "                    torch.cuda.synchronize()\n",
    "                    tiempo_gpu = time.time() - start_gpu\n",
    "                    tiempo_gpu_str = f\"{tiempo_gpu:.4f}\"\n",
    "                else:\n",
    "                    tiempo_gpu_str = \"N/A\"\n",
    "    \n",
    "                table_lines.append(f\"| {os.path.basename(path)} | {res[0]}x{res[1]} | {tiempo_cpu:.4f} | {tiempo_gpu_str} |\")\n",
    "    \n",
    "        return \"\\n\".join(table_lines)\n",
    "\n",
    "    def run_all(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el análisis (mediciones) y genera la tabla Markdown.\n",
    "        \"\"\"\n",
    "        self.run_measurements()\n",
    "        md_table = self.generar_tabla_markdown()\n",
    "        \n",
    "        return md_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 12:51:59,447 - DEBUG - GPU disponible (inicial): False\n",
      "2025-02-10 12:51:59,448 - DEBUG - Número de GPUs (inicial): 0\n",
      "2025-02-10 12:51:59,589 - INFO - Imagen: Fotos ejemplo\\Foto facial 1.jpg | Tamaño: 224x224 | Tiempo en CPU: 0.0120 segundos | GPU no disponible.\n",
      "2025-02-10 12:51:59,649 - INFO - Imagen: Fotos ejemplo\\Foto facial 1.jpg | Tamaño: 512x512 | Tiempo en CPU: 0.0530 segundos | GPU no disponible.\n",
      "2025-02-10 12:51:59,875 - INFO - Imagen: Fotos ejemplo\\Foto facial 1.jpg | Tamaño: 1024x1024 | Tiempo en CPU: 0.2223 segundos | GPU no disponible.\n",
      "2025-02-10 12:51:59,900 - INFO - Imagen: Fotos ejemplo\\Foto facial 2.jpg | Tamaño: 224x224 | Tiempo en CPU: 0.0150 segundos | GPU no disponible.\n",
      "2025-02-10 12:51:59,961 - INFO - Imagen: Fotos ejemplo\\Foto facial 2.jpg | Tamaño: 512x512 | Tiempo en CPU: 0.0540 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,178 - INFO - Imagen: Fotos ejemplo\\Foto facial 2.jpg | Tamaño: 1024x1024 | Tiempo en CPU: 0.2127 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,203 - INFO - Imagen: Fotos ejemplo\\Foto facial 3.jpg | Tamaño: 224x224 | Tiempo en CPU: 0.0160 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,263 - INFO - Imagen: Fotos ejemplo\\Foto facial 3.jpg | Tamaño: 512x512 | Tiempo en CPU: 0.0540 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,495 - INFO - Imagen: Fotos ejemplo\\Foto facial 3.jpg | Tamaño: 1024x1024 | Tiempo en CPU: 0.2274 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,518 - INFO - Imagen: Fotos ejemplo\\Foto facial 4.jpg | Tamaño: 224x224 | Tiempo en CPU: 0.0140 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,580 - INFO - Imagen: Fotos ejemplo\\Foto facial 4.jpg | Tamaño: 512x512 | Tiempo en CPU: 0.0546 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,801 - INFO - Imagen: Fotos ejemplo\\Foto facial 4.jpg | Tamaño: 1024x1024 | Tiempo en CPU: 0.2169 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,827 - INFO - Imagen: Fotos ejemplo\\Foto facial 5.jpg | Tamaño: 224x224 | Tiempo en CPU: 0.0160 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:00,890 - INFO - Imagen: Fotos ejemplo\\Foto facial 5.jpg | Tamaño: 512x512 | Tiempo en CPU: 0.0560 segundos | GPU no disponible.\n",
      "2025-02-10 12:52:01,121 - INFO - Imagen: Fotos ejemplo\\Foto facial 5.jpg | Tamaño: 1024x1024 | Tiempo en CPU: 0.2260 segundos | GPU no disponible.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m practica \u001b[38;5;241m=\u001b[39m PracticaCPUvsGPU(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m tabla \u001b[38;5;241m=\u001b[39m \u001b[43mpractica\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabla)\n",
      "Cell \u001b[1;32mIn[11], line 136\u001b[0m, in \u001b[0;36mPracticaCPUvsGPU.run_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03mEjecuta el análisis (mediciones) y genera la tabla Markdown.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_measurements()\n\u001b[1;32m--> 136\u001b[0m md_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerar_tabla_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m md_table\n",
      "Cell \u001b[1;32mIn[11], line 113\u001b[0m, in \u001b[0;36mPracticaCPUvsGPU.generar_tabla_markdown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m start_cpu \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 113\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m tiempo_cpu \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_cpu\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_disponible:\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     else:\n\u001b[0;32m   1736\u001b[0m         return self._call_impl(*args, **kwargs)\n\u001b[0;32m   1738\u001b[0m # torchrec tests the code consistency with the following code\n\u001b[1;32m-> 1739\u001b[0m # fmt: off\n\u001b[0;32m   1740\u001b[0m def _call_impl(self, *args, **kwargs):\n\u001b[0;32m   1741\u001b[0m     forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result, args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     else:\n\u001b[0;32m   1736\u001b[0m         return self._call_impl(*args, **kwargs)\n\u001b[0;32m   1738\u001b[0m # torchrec tests the code consistency with the following code\n\u001b[1;32m-> 1739\u001b[0m # fmt: off\n\u001b[0;32m   1740\u001b[0m def _call_impl(self, *args, **kwargs):\n\u001b[0;32m   1741\u001b[0m     forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result, args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     else:\n\u001b[0;32m   1736\u001b[0m         return self._call_impl(*args, **kwargs)\n\u001b[0;32m   1738\u001b[0m # torchrec tests the code consistency with the following code\n\u001b[1;32m-> 1739\u001b[0m # fmt: off\n\u001b[0;32m   1740\u001b[0m def _call_impl(self, *args, **kwargs):\n\u001b[0;32m   1741\u001b[0m     forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result, args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     else:\n\u001b[0;32m   1736\u001b[0m         return self._call_impl(*args, **kwargs)\n\u001b[0;32m   1738\u001b[0m # torchrec tests the code consistency with the following code\n\u001b[1;32m-> 1739\u001b[0m # fmt: off\n\u001b[0;32m   1740\u001b[0m def _call_impl(self, *args, **kwargs):\n\u001b[0;32m   1741\u001b[0m     forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m():\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result, args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "practica = PracticaCPUvsGPU(debug=False)\n",
    "tabla = practica.run_all()\n",
    "print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
