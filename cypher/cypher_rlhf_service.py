import os
import json
import argparse
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
from promptGenerator import PromptGenerator
from responseEvaluator import ResponseEvaluator

#####################################################################
#                 CONFIGURACI√ìN F√ÅCIL DEL SERVICIO                   #
#####################################################################

# Tu clave de API de OpenAI (si est√° vac√≠a, se buscar√° en variables de entorno)
API_KEY = "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"

# Modo del servicio: "generate" para generar prompts o "evaluate" para evaluar respuestas
SERVICE_MODE = "evaluate"  # Opciones: "generate" o "evaluate"

# ------ Configuraci√≥n para modo "generate" ------
# Categor√≠a del prompt a generar (dejar en blanco para aleatorio)
PROMPT_CATEGORY = "Open QA"  # Opciones: "Rewrite", "Classification", "Summarization", "Extraction", 
                             # "Closed QA", "Brainstorming", "Chatbot", "Creative Writing", "Open QA"

# Tema del prompt (dejar en blanco para aleatorio)
PROMPT_TOPIC = ""  # Opciones: "Business & Management", "Computer Science & Technology",
                                        # "Education", "Fitness/Sports", "Health/Medical", "Life Sciences & Biology",
                                        # "Physics Sciences & Engineering", "Social Sciences & Law", 
                                        # "Travel & Transportation", "Mathematics", "Other"

# ------ Configuraci√≥n para modo "evaluate" ------
# Ruta al archivo JSON con el prompt generado (s√≥lo para modo "evaluate")
PROMPT_FILE = "results\open_qa_education_20250410_132634.json"

# Respuesta A a evaluar (texto completo)
RESPONSE_A = """
La ense√±anza de la lengua espa√±ola en las escuelas ha evolucionado notablemente en las √∫ltimas d√©cadas, adapt√°ndose a nuevos enfoques pedag√≥gicos y a las necesidades de los estudiantes. A continuaci√≥n, te presento algunos cambios clave en metodolog√≠as y sus efectos en la percepci√≥n del idioma entre los j√≥venes:

1. **Enfoque comunicativo**: A partir de los a√±os 80 y 90, se comenz√≥ a privilegiar un enfoque m√°s comunicativo, en lugar de la ense√±anza centrada en la gram√°tica. Esto significa que se busca que los estudiantes utilicen el espa√±ol en contextos aut√©nticos y cotidianos, lo que mejora su fluidez y confianza al hablar.

2. **Aprendizaje basado en proyectos**: Esta metodolog√≠a permite a los alumnos trabajar en proyectos que integre el uso del idioma en distintas √°reas, fomentando un aprendizaje m√°s significativo y contextual. Por ejemplo, pueden investigar sobre la cultura hispana, realizar presentaciones o crear contenidos multimedia en espa√±ol.

3. **Tecnolog√≠a educativa**: La incorporaci√≥n de herramientas digitales y recursos en l√≠nea ha cambiado la forma en que los estudiantes interact√∫an con la lengua. Plataformas de aprendizaje, aplicaciones de idiomas y foros en l√≠nea les ofrecen oportunidades de practicar el espa√±ol de manera interactiva y colaborativa.

4. **Diversidad e inclusi√≥n**: Se ha hecho un esfuerzo por incluir una variedad de dialectos y variantes del espa√±ol en el curr√≠culo, reconociendo que es una lengua diversa y rica. Esto no solo beneficia a estudiantes de diferentes or√≠genes, sino que tambi√©n enriquece la experiencia de aprendizaje.

5. **Fomento de la creatividad**: Se alienta a los estudiantes a utilizar su creatividad, por ejemplo, a trav√©s de la escritura de relatos, poes√≠a o la creaci√≥n de videos. Esto no solo mejora su habilidad ling√º√≠stica, sino tambi√©n su inter√©s y conexi√≥n emocional con el idioma.

En cuanto a la percepci√≥n del espa√±ol entre los j√≥venes, estos cambios han tendido a generar una relaci√≥n m√°s positiva y activa con la lengua. Muchos estudiantes sienten que el espa√±ol no solo es una materia escolar, sino una herramienta valiosa para la comunicaci√≥n y la identidad cultural. Adem√°s, el acceso a contenidos en espa√±ol a trav√©s de redes sociales, m√∫sica y cine ha fortalecido su inter√©s y motivaci√≥n por aprender.

Sin embargo, es importante considerar que todav√≠a existen retos, como la falta de recursos en algunas instituciones y la necesidad de formaci√≥n continua para los docentes en nuevas metodolog√≠as. En resumen, la ense√±anza del espa√±ol ha avanzado para ser m√°s din√°mica y relevante, afectando la manera en que los j√≥venes perciben y utilizan la lengua en su vida diaria.
"""

# Respuesta B a evaluar (texto completo)
RESPONSE_B = """
La ense√±anza de la lengua espa√±ola en las escuelas ha experimentado una serie de cambios significativos a lo largo de las √∫ltimas d√©cadas, adapt√°ndose a las necesidades cambiantes de la sociedad y a los avances en la investigaci√≥n ling√º√≠stica y educativa. Aqu√≠ te explico algunos de los cambios m√°s destacados en las metodolog√≠as y su impacto en la percepci√≥n del idioma entre los j√≥venes:

1. **Enfoque comunicativo**: Anteriormente, la ense√±anza del espa√±ol se centraba mucho en la gram√°tica y la literatura, a menudo de manera descontextualizada. Hoy, sin embargo, las metodolog√≠as se inclinan m√°s hacia un enfoque comunicativo, donde se da prioridad a la habilidad de comunicarse eficazmente en situaciones reales. Esto incluye actividades de conversaci√≥n, debates y proyectos que fomentan el uso pr√°ctico del idioma.

2. **Diversificaci√≥n de materiales**: Actualmente, se utilizan una variedad mucho m√°s amplia de materiales did√°cticos, incluidos recursos multimedia como videos, m√∫sica, podcasts y juegos interactivos. Estos recursos no solo hacen la clase m√°s din√°mica, sino que tambi√©n ayudan a los estudiantes a percibir el idioma como relevante y √∫til en contextos modernos.

3. **Aprendizaje basado en tareas**: Esta metodolog√≠a se centra en que los estudiantes adquieran el idioma al realizar tareas significativas que reflejen situaciones de la vida real. Este enfoque busca mejorar la fluidez y la competencia comunicativa de los alumnos, haci√©ndoles ver el idioma como una herramienta valiosa para lograr objetivos espec√≠ficos.

4. **Educaci√≥n biling√ºe y pluriling√ºismo**: En algunas regiones, la ense√±anza del espa√±ol se imparte junto con otras lenguas, promoviendo el pluriling√ºismo. Esta tendencia ayuda a los estudiantes a valorar el espa√±ol como parte de su identidad cultural y ling√º√≠stica, pero tambi√©n los prepara para interactuar en un mundo globalizado.

5. **Fomento de la creatividad y la cr√≠tica**: Las clases de espa√±ol hoy en d√≠a suelen integrar actividades que fomentan la creatividad, como la escritura de blogs, guiones o producci√≥n de medios. Adem√°s, se promueve el an√°lisis cr√≠tico de textos, lo cual ayuda a desarrollar una percepci√≥n m√°s profunda y cr√≠tica del idioma y su uso.

6. **Uso de tecnolog√≠as digitales**: Las plataformas digitales y las aplicaciones de aprendizaje de idiomas han transformado la ense√±anza del espa√±ol al ofrecer herramientas personalizadas y accesibles para el aprendizaje fuera del aula. Estas tecnolog√≠as permiten a los estudiantes interactuar con el idioma de formas innovadoras, lo que puede aumentar su motivaci√≥n y cambiar su percepci√≥n, haci√©ndoles ver el espa√±ol como un idioma moderno y accesible.

En conjunto, estas metodolog√≠as han ayudado a transformar la manera en que los j√≥venes perciben el idioma espa√±ol, haci√©ndolo m√°s relevante, accesible y √∫til para sus vidas cotidianas. Adem√°s, estos cambios han contribuido a generar un entorno de aprendizaje m√°s inclusivo y participativo, donde los estudiantes se sienten m√°s motivados y comprometidos.
"""

# Directorio donde se guardar√°n los resultados
OUTPUT_DIR = "results"

#####################################################################
#                   FIN DE LA CONFIGURACI√ìN                          #
#####################################################################

class CypherRLHFService:
    """
    Servicio unificado para la generaci√≥n de prompts y evaluaci√≥n de respuestas de modelos AI
    siguiendo los criterios del proyecto RLHF de Cypher.
    """

    def __init__(self, api_key: str = None, 
                 generator_model: str = "gpt-4o-mini", 
                 evaluator_model: str = "o3-mini",
                 output_dir: str = "results"):
        """
        Inicializa el servicio con los par√°metros necesarios.
        
        Args:
            api_key: Clave de API para OpenAI (puede estar como variable de entorno)
            generator_model: Modelo de OpenAI para generar prompts
            evaluator_model: Modelo de OpenAI para evaluar respuestas
            output_dir: Directorio donde se guardar√°n los resultados
        """
        # Primero intentamos obtener la clave API del par√°metro
        self.api_key = api_key 
        
        # Si no se proporcion√≥, intentamos obtenerla de la variable de entorno
        if not self.api_key:
            self.api_key = os.environ.get("OPENAI_API_KEY")
            
        # Si a√∫n no tenemos una clave API, lanzamos una excepci√≥n
        if not self.api_key:
            raise ValueError("Se requiere una clave API de OpenAI. Configure la variable de entorno OPENAI_API_KEY o p√°sela como par√°metro.")
        
        self.generator_model = generator_model
        self.evaluator_model = evaluator_model
        self.output_dir = output_dir
        
        # Crear el directorio de salida si no existe
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Inicializar los servicios individuales
        self.prompt_generator = PromptGenerator(api_key=self.api_key, model=self.generator_model)
        self.response_evaluator = ResponseEvaluator(api_key=self.api_key, model=self.evaluator_model)
        
        # Lista de categor√≠as de prompts disponibles
        self.prompt_categories = list(self.prompt_generator.prompt_categories.keys())
        
        # Lista de categor√≠as tem√°ticas disponibles
        self.topic_categories = self.prompt_generator.topic_categories
    
    def generate_prompt(self, category: str = None, topic: str = None) -> Dict:
        """
        Genera un prompt de una categor√≠a y tema espec√≠ficos o aleatorios.
        
        Args:
            category: Categor√≠a del prompt a generar (opcional)
            topic: Tema del prompt a generar (opcional)
            
        Returns:
            Un diccionario con los detalles del prompt generado
        """
        if category and category not in self.prompt_categories:
            categories_str = ", ".join(self.prompt_categories)
            raise ValueError(f"Categor√≠a '{category}' no v√°lida. Categor√≠as disponibles: {categories_str}")
        
        if topic and topic not in self.topic_categories:
            topics_str = ", ".join(self.topic_categories)
            raise ValueError(f"Tema '{topic}' no v√°lida. Temas disponibles: {topics_str}")
        
        # Generar el prompt
        generated_prompt = self.prompt_generator.generate_prompt(category=category, topic=topic)
        
        # Guardar el prompt generado
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_type = generated_prompt.get("prompt_type", "unknown").replace(" ", "_").lower()
        topic_name = generated_prompt.get("topic", "unknown").replace(" ", "_").replace("&", "and").lower()
        filename = f"{prompt_type}_{topic_name}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(generated_prompt, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Prompt generado y guardado en: {filepath}")
        return {
            "prompt_data": generated_prompt,
            "filepath": filepath
        }
    
    def evaluate_responses(self, prompt_data: Dict = None, 
                         prompt_file: str = None,
                         response_a: str = None, 
                         response_b: str = None,
                         response_a_file: str = None,
                         response_b_file: str = None) -> Dict:
        """
        Eval√∫a dos respuestas a un mismo prompt.
        
        Args:
            prompt_data: Diccionario con los datos del prompt (opcional)
            prompt_file: Ruta al archivo JSON del prompt (opcional)
            response_a: Texto de la primera respuesta (opcional)
            response_b: Texto de la segunda respuesta (opcional)
            response_a_file: Ruta al archivo con la primera respuesta (opcional)
            response_b_file: Ruta al archivo con la segunda respuesta (opcional)
            
        Returns:
            Un diccionario con los resultados de la evaluaci√≥n
        """
        # Verificar que tengamos un prompt, ya sea como datos o como archivo
        if not prompt_data and not prompt_file:
            raise ValueError("Se requiere o bien prompt_data o prompt_file")
        
        # Si se proporciona un archivo de prompt, cargarlo
        if prompt_file and not prompt_data:
            with open(prompt_file, "r", encoding="utf-8") as f:
                prompt_data = json.load(f)
        
        # Verificar que tengamos ambas respuestas, ya sea como texto o como archivos
        if not response_a and not response_a_file:
            raise ValueError("Se requiere o bien response_a o response_a_file")
        if not response_b and not response_b_file:
            raise ValueError("Se requiere o bien response_b o response_b_file")
        
        # Si se proporcionan archivos de respuesta, cargarlos
        if response_a_file and not response_a:
            with open(response_a_file, "r", encoding="utf-8") as f:
                response_a = f.read()
        if response_b_file and not response_b:
            with open(response_b_file, "r", encoding="utf-8") as f:
                response_b = f.read()
        
        # Evaluar las respuestas
        evaluation_results = self.response_evaluator.evaluate(prompt_data, response_a, response_b)
        
        # Guardar los resultados
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_type = prompt_data.get("prompt_type", "unknown").replace(" ", "_").lower()
        topic_name = prompt_data.get("topic", "unknown").replace(" ", "_").replace("&", "and").lower()
        filename = f"eval_{prompt_type}_{topic_name}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(evaluation_results, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Evaluaci√≥n completada y guardada en: {filepath}")
        return {
            "evaluation_results": evaluation_results,
            "filepath": filepath
        }
    
    def run_complete_workflow(self, category: str = None, topic: str = None, model_a: str = None, model_b: str = None) -> Dict:
        """
        Ejecuta el flujo completo: genera un prompt, obtiene respuestas de uno o dos modelos y las eval√∫a.
        Esta funcionalidad est√° pensada para implementarse m√°s adelante, cuando tengas acceso
        a los modelos para generar respuestas.
        
        Args:
            category: Categor√≠a del prompt a generar
            topic: Tema del prompt a generar
            model_a: Identificador del primer modelo para generar respuestas
            model_b: Identificador del segundo modelo para generar respuestas
            
        Returns:
            Un diccionario con los resultados del flujo completo
        """
        # Esta es una funci√≥n de placeholder para el flujo completo
        # que podr√≠as implementar m√°s adelante
        raise NotImplementedError("Esta funcionalidad ser√° implementada pr√≥ximamente")

def main():
    """Funci√≥n principal para ejecutar el servicio desde la l√≠nea de comandos"""
    # Si se proporcionan argumentos por l√≠nea de comandos, se usa el parser
    if len(os.sys.argv) > 1:
        parser = argparse.ArgumentParser(description='Servicio integrado de RLHF para Cypher')
        parser.add_argument('--api-key', type=str, help='Clave de API de OpenAI')
        parser.add_argument('--mode', choices=['generate', 'evaluate'], required=True,
                          help='Modo de operaci√≥n: generar prompts o evaluar respuestas')
        parser.add_argument('--category', type=str, help='Categor√≠a del prompt a generar (solo para modo "generate")')
        parser.add_argument('--topic', type=str, help='Tema del prompt a generar (solo para modo "generate")')
        parser.add_argument('--prompt-file', type=str, 
                          help='Archivo JSON con el prompt (solo para modo "evaluate")')
        parser.add_argument('--response-a', type=str,
                          help='Ruta al archivo con la primera respuesta (solo para modo "evaluate")')
        parser.add_argument('--response-b', type=str,
                          help='Ruta al archivo con la segunda respuesta (solo para modo "evaluate")')
        parser.add_argument('--output-dir', type=str, default='results',
                          help='Directorio donde se guardar√°n los resultados')
        parser.add_argument('--list-categories', action='store_true',
                          help='Mostrar las categor√≠as de prompts disponibles')
        parser.add_argument('--list-topics', action='store_true',
                          help='Mostrar los temas de prompts disponibles')
        
        args = parser.parse_args()
        
        try:
            # Inicializar el servicio
            service = CypherRLHFService(
                api_key=args.api_key,
                output_dir=args.output_dir
            )
            
            # Mostrar listas si se solicita
            if args.list_categories:
                print("Categor√≠as de prompts disponibles:")
                for category in service.prompt_categories:
                    print(f"- {category}")
                return
                
            if args.list_topics:
                print("Temas de prompts disponibles:")
                for topic in service.topic_categories:
                    print(f"- {topic}")
                return
            
            # Ejecutar el modo seleccionado
            if args.mode == 'generate':
                result = service.generate_prompt(category=args.category, topic=args.topic)
                print(f"Prompt generado:\n{json.dumps(result['prompt_data'], ensure_ascii=False, indent=2)}")
                
            elif args.mode == 'evaluate':
                if not args.prompt_file:
                    raise ValueError("Se requiere --prompt-file en modo 'evaluate'")
                if not args.response_a:
                    raise ValueError("Se requiere --response-a en modo 'evaluate'")
                if not args.response_b:
                    raise ValueError("Se requiere --response-b en modo 'evaluate'")
                    
                result = service.evaluate_responses(
                    prompt_file=args.prompt_file,
                    response_a_file=args.response_a,
                    response_b_file=args.response_b
                )
                
                print(f"Preferencia: {result['evaluation_results']['comparison']['preference_label']}")
                print(f"Justificaci√≥n: {result['evaluation_results']['comparison']['justification']}")
                
        except Exception as e:
            print(f"Error: {e}")
    
    # Si no hay argumentos, se usan las variables globales definidas al inicio del archivo
    else:
        try:
            # Inicializar el servicio con la configuraci√≥n global
            service = CypherRLHFService(
                api_key=API_KEY,
                output_dir=OUTPUT_DIR
            )
            
            # Ejecutar el modo seleccionado seg√∫n la configuraci√≥n global
            if SERVICE_MODE == 'generate':
                print(f"üöÄ Generando prompt de categor√≠a '{PROMPT_CATEGORY}' y tema '{PROMPT_TOPIC}'...")
                result = service.generate_prompt(category=PROMPT_CATEGORY, topic=PROMPT_TOPIC)
                print(f"Prompt generado:\n{json.dumps(result['prompt_data'], ensure_ascii=False, indent=2)}")
                
            elif SERVICE_MODE == 'evaluate':
                if not PROMPT_FILE:
                    raise ValueError("Se requiere definir PROMPT_FILE en la configuraci√≥n para el modo 'evaluate'")
                if not RESPONSE_A:
                    raise ValueError("Se requiere definir RESPONSE_A en la configuraci√≥n para el modo 'evaluate'")
                if not RESPONSE_B:
                    raise ValueError("Se requiere definir RESPONSE_B en la configuraci√≥n para el modo 'evaluate'")
                
                print(f"üîç Evaluando respuestas para el prompt en '{PROMPT_FILE}'...")
                
                # Crear archivos temporales para las respuestas
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                response_a_file = f"{OUTPUT_DIR}/temp_response_a_{timestamp}.txt"
                response_b_file = f"{OUTPUT_DIR}/temp_response_b_{timestamp}.txt"
                
                # Guardar las respuestas en archivos temporales
                with open(response_a_file, "w", encoding="utf-8") as f:
                    f.write(RESPONSE_A)
                
                with open(response_b_file, "w", encoding="utf-8") as f:
                    f.write(RESPONSE_B)
                
                # Evaluar las respuestas
                result = service.evaluate_responses(
                    prompt_file=PROMPT_FILE,
                    response_a=RESPONSE_A,
                    response_b=RESPONSE_B
                )
                
                print(f"\n‚úÖ Evaluaci√≥n completada")
                print(f"Preferencia: {result['evaluation_results']['comparison']['preference_label']}")
                print(f"Justificaci√≥n: {result['evaluation_results']['comparison']['justification']}")
                
                # Mostrar un resumen de las evaluaciones individuales
                print("\nüìä Resumen de Evaluaci√≥n de Respuesta A:")
                for dim, data in result['evaluation_results']['evaluation_a'].items():
                    rating = data['rating']
                    justification = data['justification'] if data['justification'] else "Sin problemas"
                    print(f"  - {dim}: {rating}/{'3' if dim not in ['response_length', 'overall_satisfaction'] else '5'} - {justification}")
                    
                print("\nüìä Resumen de Evaluaci√≥n de Respuesta B:")
                for dim, data in result['evaluation_results']['evaluation_b'].items():
                    rating = data['rating']
                    justification = data['justification'] if data['justification'] else "Sin problemas"
                    print(f"  - {dim}: {rating}/{'3' if dim not in ['response_length', 'overall_satisfaction'] else '5'} - {justification}")
                
                # Limpiar los archivos temporales
                try:
                    os.remove(response_a_file)
                    os.remove(response_b_file)
                except:
                    pass
                
            else:
                raise ValueError(f"Modo de servicio no v√°lido: {SERVICE_MODE}. Debe ser 'generate' o 'evaluate'")
                
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()